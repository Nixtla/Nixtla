{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch as t\n",
    "from fastcore.foundation import patch\n",
    "\n",
    "from nixtla.data.datasets.epf import EPF, EPFInfo\n",
    "from nixtla.data.tsdataset import TimeSeriesDataset, get_mask_df\n",
    "from nixtla.data.tsloader_fast import TimeSeriesLoader as TimeSeriesLoaderFast\n",
    "from nixtla.data.tsloader_pinche import TimeSeriesLoader as TimeSeriesLoaderPinche\n",
    "from nixtla.data.tsloader_general import TimeSeriesLoader as TimeSeriesLoaderGeneral\n",
    "from nixtla.models.nbeats.nbeats import Nbeats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ NORD POOL ELECTRICITY PRICE FORECASTING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df, X_df, _ = EPF.load(directory='data', group=EPFInfo.groups[0])\n",
    "X_df = X_df[['unique_id','ds','Exogenous1','Exogenous2']]\n",
    "mask_df = get_mask_df(Y_df=Y_df, n_timestamps=365*24)\n",
    "epf_dataset = TimeSeriesDataset(Y_df=Y_df, S_df=None, X_df=X_df, mask_df=mask_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN AND VALIDATION DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = TimeSeriesLoaderGeneral(ts_dataset=epf_dataset,\n",
    "                                       model='nbeats',\n",
    "                                       offset=0,\n",
    "                                       window_sampling_limit=365*4*24, \n",
    "                                       input_size=2*24,\n",
    "                                       output_size=24,\n",
    "                                       idx_to_sample_freq=1,\n",
    "                                       batch_size=1024,\n",
    "                                       complete_inputs=False,\n",
    "                                       complete_sample=False,\n",
    "                                       shuffle=False)\n",
    "\n",
    "val_loader = TimeSeriesLoaderGeneral(ts_dataset=epf_dataset,\n",
    "                                     model='nbeats',\n",
    "                                     offset=0,\n",
    "                                     window_sampling_limit=365*4*24, \n",
    "                                     input_size=2*24,\n",
    "                                     output_size=24,\n",
    "                                     idx_to_sample_freq=1,\n",
    "                                     batch_size=1024, \n",
    "                                     complete_inputs=False,\n",
    "                                     complete_sample=False,\n",
    "                                     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbeatsx = Nbeats(input_size_multiplier=2,\n",
    "                 output_size=24,\n",
    "                 shared_weights=False,\n",
    "                 activation='relu',\n",
    "                 initialization='lecun_normal',\n",
    "                 stack_types=2*['identity'],\n",
    "                 n_blocks=2*[1],\n",
    "                 n_layers=2*[2],\n",
    "                 n_hidden=2*[[256,256]],\n",
    "                 n_harmonics=1,\n",
    "                 n_polynomials=2,\n",
    "                 exogenous_n_channels=9,\n",
    "                 batch_normalization=False,\n",
    "                 dropout_prob_theta=0.01,\n",
    "                 dropout_prob_exogenous=0.01,\n",
    "                 x_s_n_hidden=0,\n",
    "                 learning_rate=0.0005,\n",
    "                 lr_decay=0.5,\n",
    "                 n_lr_decay_steps=3,\n",
    "                 weight_decay=0.0000001,\n",
    "                 l1_theta=0.0001,\n",
    "                 n_iterations=50,\n",
    "                 early_stopping=10,\n",
    "                 loss='MAE',\n",
    "                 loss_hypar=None,\n",
    "                 val_loss='MAE',\n",
    "                 frequency='H',\n",
    "                 random_seed=1,\n",
    "                 seasonality=24)\n",
    "\n",
    "nbeatsx.fit(train_ts_loader=train_loader, val_ts_loader=val_loader, verbose=True, eval_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = nbeatsx.predict(ts_loader=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ TURISM DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nixtla.data.datasets.tourism import Tourism, TourismInfo\n",
    "group = TourismInfo.groups[0]\n",
    "print(\"TourismInfo.groups[0]\", group)\n",
    "Y_df, _ = Tourism.load(directory='data', group=group)\n",
    "tourism_dataset = TimeSeriesDataset(Y_df=Y_df, S_df=None, X_df=None, ts_train_mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = TimeSeriesLoaderGeneral(ts_dataset=tourism_dataset,\n",
    "                                            model='nbeats',\n",
    "                                            offset=4,\n",
    "                                            window_sampling_limit=20*4, \n",
    "                                            input_size=7*4,\n",
    "                                            output_size=4,\n",
    "                                            idx_to_sample_freq=1,\n",
    "                                            batch_size= 1024,\n",
    "                                            n_series_per_batch=32,\n",
    "                                            is_train_loader=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbeatsx = Nbeats(input_size_multiplier=7,\n",
    "                 output_size=4,\n",
    "                 shared_weights=False,\n",
    "                 activation='relu',\n",
    "                 initialization='lecun_normal',\n",
    "                 stack_types=30*['identity'],\n",
    "                 n_blocks=30*[1],\n",
    "                 n_layers=30*[4],\n",
    "                 n_hidden=30*[[512,512,512,512]],\n",
    "                 n_harmonics=1,\n",
    "                 n_polynomials=2,\n",
    "                 exogenous_n_channels=9,\n",
    "                 batch_normalization=False,\n",
    "                 dropout_prob_theta=0.0,\n",
    "                 dropout_prob_exogenous=0.0,\n",
    "                 x_s_n_hidden=0,\n",
    "                 learning_rate=0.001,\n",
    "                 lr_decay=0.5,\n",
    "                 n_lr_decay_steps=3,\n",
    "                 weight_decay=0.0000000,\n",
    "                 l1_theta=0.0000,\n",
    "                 n_iterations=30,\n",
    "                 early_stopping=10,\n",
    "                 loss='MAPE',\n",
    "                 frequency='M',\n",
    "                 random_seed=1,\n",
    "                 seasonality=4)\n",
    "\n",
    "nbeatsx.fit(train_ts_loader=train_loader, val_ts_loader=None, verbose=True, eval_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = nbeatsx.predict(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_plot = Y_df[Y_df['unique_id']=='Y1']['y']\n",
    "y_hat_plot = y_hat[y_hat['unique_id']=='Y1']['y_hat']\n",
    "plt.plot(range(len(y_plot)), y_plot)\n",
    "plt.plot(range(len(y_plot), len(y_plot)+len(y_hat_plot)), y_hat_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Should be around 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = Y_df.groupby('unique_id').tail(4).reset_index(drop=True)\n",
    "np.mean(np.abs(y_test['y']-y_hat['y_hat'])/np.abs(y_test['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit ('nixtla': conda)",
   "metadata": {
    "interpreter": {
     "hash": "52b0028e7074a0058398558ea661882eddbb489e66a28504cc0449d2f54d6290"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}