{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/MyDrive/nixtlats\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "os.chdir('./drive/MyDrive/nixtlats')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp models.nbeats.nbeats_model_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pytorch-lightning\n",
    "# !pip install torchinfo\n",
    "# !pip install fastcore\n",
    "# !pip install s3fs\n",
    "# !pip install patool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.5) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Iterable, Union, List\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import pylab as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "from nixtla.models.nbeats.nbeats_model import NBEATS\n",
    "from nixtla.data.datasets.m4 import M4Info, M4, M4Evaluation\n",
    "from nixtla.data.tsdataset import TimeSeriesDataset\n",
    "from nixtla.data.tsloader import TimeSeriesLoader\n",
    "from nixtla.experiments.utils import create_datasets, get_mask_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _parameter_grid(grid):\n",
    "    specs_list = list(product(*list(grid.values())))\n",
    "    model_specs_df = pd.DataFrame(specs_list, columns=list(grid.keys()))\n",
    "    \n",
    "    return model_specs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "common_grid = {}\n",
    "\n",
    "# Architecture parameters\n",
    "common_grid['activation'] = ['ReLU'] # Oreshkin\n",
    "common_grid['n_x'] = [0] # No exogenous variables\n",
    "common_grid['n_s'] = [0] # No static variables\n",
    "common_grid['n_x_hidden'] = [0] # No exogenous variables\n",
    "common_grid['n_s_hidden'] = [0] # No static variables\n",
    "common_grid['stack_types'] = [['trend', 'seasonality']] # NBEATS-I original architecture\n",
    "common_grid['n_blocks'] = [[3, 3]] # Trend blocks, Seasonal blocks - Oreshkin\n",
    "common_grid['n_layers'] = [[4, 4]] # Trend-block layers, Seasonal-block - Oreshkin\n",
    "common_grid['shared_weights'] = [True] # Oreshkin\n",
    "common_grid['n_harmonics'] = [1] # Oreshkin\n",
    "common_grid['n_polynomials'] = [2] # Trend polynomial degree\n",
    "common_grid['n_theta_hidden'] = [[common_grid['n_layers'][0][0] * [256],\n",
    "                                  common_grid['n_layers'][0][1] * [2048]]] # Oreshkin\n",
    "common_grid['initialization'] = ['lecun_normal'] # Arbitrary\n",
    "\n",
    "# Optimization parameters\n",
    "common_grid['learning_rate'] = [0.001] # Oreshkin\n",
    "common_grid['lr_decay'] = [0] # No lr_decay in the original implementation\n",
    "common_grid['lr_decay_step_size'] = [1_000] # No lr_decay in the original implementation\n",
    "common_grid['loss_train'] = ['MAPE', 'SMAPE'] # MASE not available. Oreshkin\n",
    "common_grid['loss_hypar'] = [0.5] # ???\n",
    "# common_grid['loss_valid'] = common_grid['loss_train'] # Oreskin NOT INCLUDED TO AVOID DUPLICITY\n",
    "common_grid['dropout_prob_theta'] = [0] # No dropout in the original implementation\n",
    "common_grid['weight_decay'] = [0] # # No weight_decay in the original implementation\n",
    "common_grid['batch_size'] = [1024] # Oreshkin\n",
    "common_grid['batch_normalization'] = [False] # No batch_normalization in the original implementation\n",
    "\n",
    "common_grid['max_steps'] = [1_000] # Oreshkin\n",
    "common_grid['random_seed'] = list(range(1)) # Change to range(10). Oreshkin\n",
    "\n",
    "# Data Parameters\n",
    "common_grid['complete_inputs'] = [True] # ???\n",
    "common_grid['mode'] = ['simple'] # Step = 1 window\n",
    "lookbacks = list(range(2, 3)) # Change to range(2, 8). Oreshkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Yearly:\n",
    "    group = M4Info['Yearly']\n",
    "\n",
    "    grid_freq = {}\n",
    "    grid_freq['max_epochs'] = [1] # In combination with max_n_steps, it trains max_n_epochs*max_n_steps\n",
    "    grid_freq['n_time_in'] = [M4Info['Yearly'].horizon * i for i in lookbacks]\n",
    "    grid_freq['n_time_out'] = [group.horizon]\n",
    "    grid_freq['idx_to_sample_freq'] = [1] # ???\n",
    "    grid_freq['val_idx_to_sample_freq'] = [1] # ???\n",
    "    grid_freq['frequency'] = ['Q'] # ???\n",
    "    grid_freq['seasonality'] = [4] # ???\n",
    "    grid_freq['l_h'] = [1.5]\n",
    "\n",
    "    grid = {**common_grid,\n",
    "            **grid_freq}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Quarterly:\n",
    "    group = M4Info['Quarterly']\n",
    "\n",
    "    grid_freq = {}\n",
    "    grid_freq['max_epochs'] = [1] # In combination with max_n_steps, it trains max_n_epochs*max_n_steps\n",
    "    grid_freq['n_time_in'] = [M4Info['Quarterly'].horizon * i for i in lookbacks]\n",
    "    grid_freq['n_time_out'] = [group.horizon]\n",
    "    grid_freq['idx_to_sample_freq'] = [1] # ???\n",
    "    grid_freq['val_idx_to_sample_freq'] = [1] # ???\n",
    "    grid_freq['frequency'] = ['Y'] # ???\n",
    "    grid_freq['seasonality'] = [1] # ???\n",
    "    grid_freq['l_h'] = [1.5]\n",
    "\n",
    "    grid = {**common_grid,\n",
    "            **grid_freq}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly grid (# of different model configurations=2):\n",
      "===========================================================================\n",
      "activation                                                           [ReLU]\n",
      "n_x                                                                     [0]\n",
      "n_s                                                                     [0]\n",
      "n_x_hidden                                                              [0]\n",
      "n_s_hidden                                                              [0]\n",
      "stack_types                                          [[trend, seasonality]]\n",
      "n_blocks                                                           [[3, 3]]\n",
      "n_layers                                                           [[4, 4]]\n",
      "shared_weights                                                       [True]\n",
      "n_harmonics                                                             [1]\n",
      "n_polynomials                                                           [2]\n",
      "n_theta_hidden            [[[256, 256, 256, 256], [2048, 2048, 2048, 204...\n",
      "initialization                                               [lecun_normal]\n",
      "learning_rate                                                       [0.001]\n",
      "lr_decay                                                                [0]\n",
      "lr_decay_step_size                                                   [1000]\n",
      "loss_train                                                    [MAPE, SMAPE]\n",
      "loss_hypar                                                            [0.5]\n",
      "dropout_prob_theta                                                      [0]\n",
      "weight_decay                                                            [0]\n",
      "batch_size                                                           [1024]\n",
      "batch_normalization                                                 [False]\n",
      "max_steps                                                            [1000]\n",
      "random_seed                                                             [0]\n",
      "complete_inputs                                                      [True]\n",
      "mode                                                               [simple]\n",
      "max_epochs                                                              [1]\n",
      "n_time_in                                                              [12]\n",
      "n_time_out                                                              [6]\n",
      "idx_to_sample_freq                                                      [1]\n",
      "val_idx_to_sample_freq                                                  [1]\n",
      "frequency                                                               [Q]\n",
      "seasonality                                                             [4]\n",
      "l_h                                                                   [1.5]\n",
      "dtype: object\n",
      "===========================================================================\n",
      "\n",
      "Quarterly grid (# of different model configurations=2):\n",
      "===========================================================================\n",
      "activation                                                           [ReLU]\n",
      "n_x                                                                     [0]\n",
      "n_s                                                                     [0]\n",
      "n_x_hidden                                                              [0]\n",
      "n_s_hidden                                                              [0]\n",
      "stack_types                                          [[trend, seasonality]]\n",
      "n_blocks                                                           [[3, 3]]\n",
      "n_layers                                                           [[4, 4]]\n",
      "shared_weights                                                       [True]\n",
      "n_harmonics                                                             [1]\n",
      "n_polynomials                                                           [2]\n",
      "n_theta_hidden            [[[256, 256, 256, 256], [2048, 2048, 2048, 204...\n",
      "initialization                                               [lecun_normal]\n",
      "learning_rate                                                       [0.001]\n",
      "lr_decay                                                                [0]\n",
      "lr_decay_step_size                                                   [1000]\n",
      "loss_train                                                    [MAPE, SMAPE]\n",
      "loss_hypar                                                            [0.5]\n",
      "dropout_prob_theta                                                      [0]\n",
      "weight_decay                                                            [0]\n",
      "batch_size                                                           [1024]\n",
      "batch_normalization                                                 [False]\n",
      "max_steps                                                            [1000]\n",
      "random_seed                                                             [0]\n",
      "complete_inputs                                                      [True]\n",
      "mode                                                               [simple]\n",
      "max_epochs                                                              [1]\n",
      "n_time_in                                                              [16]\n",
      "n_time_out                                                              [8]\n",
      "idx_to_sample_freq                                                      [1]\n",
      "val_idx_to_sample_freq                                                  [1]\n",
      "frequency                                                               [Y]\n",
      "seasonality                                                             [1]\n",
      "l_h                                                                   [1.5]\n",
      "dtype: object\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f'Yearly grid (# of different model configurations={len(_parameter_grid(Yearly.grid))}):')\n",
    "print(75*'=')\n",
    "print(pd.Series(Yearly.grid))\n",
    "print(75*'=')\n",
    "print()\n",
    "print(f'Quarterly grid (# of different model configurations={len(_parameter_grid(Quarterly.grid))}):')\n",
    "print(75*'=')\n",
    "print(pd.Series(Quarterly.grid))\n",
    "print(75*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq = Yearly\n",
    "# Y_df, _, S_df = M4.load(directory='data', group=freq.group.name)\n",
    "\n",
    "# freq_grid = _parameter_grid(freq.grid)\n",
    "# row_ensemble = freq_grid.iloc[0]\n",
    "# hparams = row_ensemble.to_dict()\n",
    "\n",
    "# train_dataset = TimeSeriesDataset(Y_df=Y_df, S_df=S_df,\n",
    "#                                 ds_in_test=freq.group.horizon,\n",
    "#                                 mode=hparams['mode'],\n",
    "#                                 window_sampling_limit=hparams['window_sampling_limit'], # To limit backprop time\n",
    "#                                 input_size=hparams['n_time_in'],\n",
    "#                                 output_size=hparams['n_time_out'],\n",
    "#                                 idx_to_sample_freq=hparams['idx_to_sample_freq'],\n",
    "#                                 complete_inputs=hparams['complete_inputs'], \n",
    "#                                 skip_nonsamplable=True)\n",
    "\n",
    "# train_loader = TimeSeriesLoader(dataset=train_dataset,\n",
    "#                                             batch_size=int(hparams['batch_size']),\n",
    "#                                             eq_batch_size=True,\n",
    "#                                             num_workers=4,\n",
    "#                                             shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(train_loader))\n",
    "# print(batch['S'].shape)\n",
    "# print(batch['Y'].shape)\n",
    "# print(batch['X'].shape)\n",
    "# print(batch['available_mask'].shape)\n",
    "\n",
    "# display(pd.Series(hparams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchinfo import summary\n",
    "\n",
    "# model = NBEATS(n_time_in=int(hparams['n_time_in']),\n",
    "#                                n_time_out=int(hparams['n_time_out']),\n",
    "#                                n_x=hparams['n_x'],\n",
    "#                                n_s=hparams['n_s'],\n",
    "#                                n_s_hidden=int(hparams['n_s_hidden']),\n",
    "#                                n_x_hidden=int(hparams['n_x_hidden']),\n",
    "#                                shared_weights=hparams['shared_weights'],\n",
    "#                                initialization=hparams['initialization'],\n",
    "#                                activation=hparams['activation'],\n",
    "#                                stack_types=hparams['stack_types'],\n",
    "#                                n_blocks=hparams['n_blocks'],\n",
    "#                                n_layers=hparams['n_layers'],\n",
    "#                                n_theta_hidden=hparams['n_theta_hidden'],\n",
    "#                                n_harmonics=int(hparams['n_harmonics']),\n",
    "#                                n_polynomials=int(hparams['n_polynomials']),\n",
    "#                                batch_normalization = hparams['batch_normalization'],\n",
    "#                                dropout_prob_theta=hparams['dropout_prob_theta'],\n",
    "#                                learning_rate=float(hparams['learning_rate']),\n",
    "#                                lr_decay=float(hparams['lr_decay']),\n",
    "#                                lr_decay_step_size=float(hparams['lr_decay_step_size']),\n",
    "#                                weight_decay=hparams['weight_decay'],\n",
    "#                                loss_train=hparams['loss_train'],\n",
    "#                                loss_hypar=float(hparams['loss_hypar']),\n",
    "#                                loss_valid='SMAPE',\n",
    "#                                frequency=hparams['frequency'],\n",
    "#                                seasonality=int(hparams['seasonality']),\n",
    "#                                random_seed=int(hparams['random_seed']))\n",
    "\n",
    "# print(model)\n",
    "# # summary(model.model, input_size=[(1024, 1), (1024, 18), (1024, 1, 18), (1024, 18)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EnsembleNBEATS:\n",
    "    # TODO: Update test TimeSeriesDataset instantiation wit parameter last_samplable_window\n",
    "    def __init__(self,\n",
    "                 frequencies: List[type],\n",
    "                 loader: callable,\n",
    "                 num_workers: int):\n",
    "        self.frequencies = frequencies\n",
    "        self.loader = loader\n",
    "        \n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def fit(self):\n",
    "        results = {}\n",
    "\n",
    "        for freq in self.frequencies:\n",
    "            print(f'\\n{freq.group.name}')\n",
    "            Y_df, _, S_df = M4.load(directory='data', group=freq.group.name)\n",
    "            freq_grid = _parameter_grid(freq.grid)\n",
    "\n",
    "            forecasts = []\n",
    "\n",
    "            for idx_ensemble, row_ensemble in tqdm(freq_grid.iterrows(), position=0, leave=True):\n",
    "                hparams = row_ensemble.to_dict()\n",
    "                print(hparams['n_time_in'] + \\\n",
    "                                        int(hparams['n_time_out'] * hparams['l_h']))\n",
    "                train_dataset = \\\n",
    "                    TimeSeriesDataset(Y_df=Y_df, S_df=S_df,\n",
    "                                      ds_in_test=freq.group.horizon,\n",
    "                                      mode=hparams['mode'],\n",
    "                                      window_sampling_limit=\\\n",
    "                                        hparams['n_time_in'] + \\\n",
    "                                        int(hparams['n_time_out'] * hparams['l_h']), # To limit backprop time \n",
    "                                      input_size=hparams['n_time_in'],\n",
    "                                      output_size=hparams['n_time_out'],\n",
    "                                      idx_to_sample_freq=hparams['idx_to_sample_freq'],\n",
    "                                      complete_inputs=hparams['complete_inputs'], \n",
    "                                      skip_nonsamplable=True)\n",
    "                    \n",
    "                train_loader = TimeSeriesLoader(dataset=train_dataset,\n",
    "                                                batch_size=hparams['batch_size'],\n",
    "                                                eq_batch_size=True,\n",
    "                                                num_workers=self.num_workers,\n",
    "                                                shuffle=False)\n",
    "                    \n",
    "                test_dataset = \\\n",
    "                    TimeSeriesDataset(Y_df=Y_df, S_df=S_df,\n",
    "                                      ds_in_test=0,\n",
    "                                    #   mode=hparams['mode'],\n",
    "                                      mode='full',\n",
    "                                      window_sampling_limit=\\\n",
    "                                        hparams['n_time_out'] + hparams['n_time_in'], # To limit backprop time \n",
    "                                      input_size=hparams['n_time_in'],\n",
    "                                      output_size=hparams['n_time_out'],\n",
    "                                    #   idx_to_sample_freq=hparams['idx_to_sample_freq'],\n",
    "                                      idx_to_sample_freq=1,\n",
    "                                    #   complete_inputs=hparams['complete_inputs'],\n",
    "                                      complete_inputs=True, \n",
    "                                      complete_outputs=True,\n",
    "                                    #   last_samplable_window=True,\n",
    "                                      skip_nonsamplable=False)\n",
    "                    \n",
    "                test_loader = TimeSeriesLoader(dataset=test_dataset,\n",
    "                                               batch_size=1024,\n",
    "                                               eq_batch_size=False,\n",
    "                                               num_workers=self.num_workers,\n",
    "                                               shuffle=False)\n",
    "\n",
    "                model = NBEATS(n_time_in=int(hparams['n_time_in']),\n",
    "                               n_time_out=int(hparams['n_time_out']),\n",
    "                               n_x=hparams['n_x'],\n",
    "                               n_s=hparams['n_s'],\n",
    "                               n_s_hidden=int(hparams['n_s_hidden']),\n",
    "                               n_x_hidden=int(hparams['n_x_hidden']),\n",
    "                               shared_weights=hparams['shared_weights'],\n",
    "                               initialization=hparams['initialization'],\n",
    "                               activation=hparams['activation'],\n",
    "                               stack_types=hparams['stack_types'],\n",
    "                               n_blocks=hparams['n_blocks'],\n",
    "                               n_layers=hparams['n_layers'],\n",
    "                               n_theta_hidden=hparams['n_theta_hidden'],\n",
    "                               n_harmonics=int(hparams['n_harmonics']),\n",
    "                               n_polynomials=int(hparams['n_polynomials']),\n",
    "                               batch_normalization = hparams['batch_normalization'],\n",
    "                               dropout_prob_theta=hparams['dropout_prob_theta'],\n",
    "                               learning_rate=float(hparams['learning_rate']),\n",
    "                               lr_decay=float(hparams['lr_decay']),\n",
    "                               lr_decay_step_size=float(hparams['lr_decay_step_size']),\n",
    "                               weight_decay=hparams['weight_decay'],\n",
    "                               loss_train=hparams['loss_train'],\n",
    "                               loss_hypar=float(hparams['loss_hypar']),\n",
    "                               loss_valid='SMAPE',\n",
    "                               frequency=hparams['frequency'],\n",
    "                               seasonality=int(hparams['seasonality']),\n",
    "                               random_seed=int(hparams['random_seed']))\n",
    "                \n",
    "                print(f'\\nModel distinctive attributes: loss: {model.loss_train}, random_seeds: {model.random_seed}')\n",
    "                \n",
    "                trainer = pl.Trainer(max_epochs=hparams['max_epochs'], \n",
    "                                     max_steps=hparams['max_steps'],\n",
    "                                     gradient_clip_val=0,\n",
    "                                     progress_bar_refresh_rate=1, \n",
    "                                     log_every_n_steps=100, \n",
    "                                    #  val_check_interval=0,\n",
    "                                    #  check_val_every_n_epoch=hparams['max_epochs'],\n",
    "                                     gpus=-1,\n",
    "                                     auto_select_gpus=True)\n",
    "                \n",
    "                trainer.fit(model, train_loader)\n",
    "\n",
    "                outputs = trainer.predict(model, test_loader)\n",
    "\n",
    "                forecasts.append(outputs)             \n",
    "\n",
    "            results[freq.group.name] = forecasts\n",
    "            \n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Yearly\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: you defined a validation_step but have no val_dataloader. Skipping val loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | _NBEATS | 12.8 M\n",
      "----------------------------------\n",
      "12.8 M    Trainable params\n",
      "162       Non-trainable params\n",
      "12.8 M    Total params\n",
      "51.371    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model distinctive attributes: loss: MAPE, random_seeds: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9872174eb071451e89c7d696fb6b8616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227a945a38db4fc98076cafda348a9f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RecursionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-4b7c83d76f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                           \u001b[0mloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTimeSeriesLoader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                           num_workers=4)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mforecasts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-77-6a5b5bf45c5c>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m                                      auto_select_gpus=True)\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    456\u001b[0m         )\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    867\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m                     \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0mis_last_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_last_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    482\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_last_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_last_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/profiler/profilers.py\u001b[0m in \u001b[0;36mprofile_iterable\u001b[0;34m(self, iterable, action_name)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/supporters.py\u001b[0m in \u001b[0;36mprefetch_iterator\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;31m# the iterator may be empty from the beginning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/supporters.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \"\"\"\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/supporters.py\u001b[0m in \u001b[0;36mrequest_next_batch\u001b[0;34m(loader_iters)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m         \"\"\"\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, *args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# Breaking condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwrong_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Recursively apply to collection items\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRecursionError\u001b[0m: Caught RecursionError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/content/drive/MyDrive/nixtlats/nixtla/data/tsdataset.py\", line 514, in __getitem__\n    return self[idx]\n  File \"/content/drive/MyDrive/nixtlats/nixtla/data/tsdataset.py\", line 514, in __getitem__\n    return self[idx]\n  File \"/content/drive/MyDrive/nixtlats/nixtla/data/tsdataset.py\", line 514, in __getitem__\n    return self[idx]\n  [Previous line repeated 923 more times]\n  File \"/content/drive/MyDrive/nixtlats/nixtla/data/tsdataset.py\", line 508, in __getitem__\n    windows, s_matrix, ts_idxs = self._create_windows_tensor(idx=idx)\n  File \"/content/drive/MyDrive/nixtlats/nixtla/data/tsdataset.py\", line 392, in _create_windows_tensor\n    padder = t.nn.ConstantPad1d(padding=self.padding, value=0)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/padding.py\", line 76, in __init__\n    self.padding = _pair(padding)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/utils.py\", line 10, in parse\n    if isinstance(x, container_abcs.Iterable):\n  File \"/usr/lib/python3.7/abc.py\", line 139, in __instancecheck__\n    return _abc_instancecheck(cls, instance)\nRecursionError: maximum recursion depth exceeded in comparison\n"
     ]
    }
   ],
   "source": [
    "ensemble = EnsembleNBEATS(frequencies=[Yearly, Quarterly],\n",
    "                          loader=TimeSeriesLoader,\n",
    "                          num_workers=4)\n",
    "forecasts = ensemble.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6951, 6])\n"
     ]
    }
   ],
   "source": [
    "y_hat_yearly = forecasts['Yearly']\n",
    "print(y_hat_yearly[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
