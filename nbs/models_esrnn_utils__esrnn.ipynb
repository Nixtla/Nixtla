{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.esrnn.utils.esrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESRNN utils esrnn\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from nixtla.models.esrnn.utils.drnn import DRNN\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-63cf24e71b2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0m_ES\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "#export\n",
    "class _ES(nn.Module):\n",
    "    def __init__(self, mc):\n",
    "        super(_ES, self).__init__()\n",
    "        self.mc = mc\n",
    "        self.n_series = self.mc.n_series\n",
    "        self.output_size = self.mc.output_size\n",
    "        assert len(self.mc.seasonality) in [0, 1, 2]\n",
    "\n",
    "    def gaussian_noise(self, input_data, std=0.2):\n",
    "        size = input_data.size()\n",
    "        noise = torch.autograd.Variable(input_data.data.new(size).normal_(0, std))\n",
    "        return input_data + noise\n",
    "\n",
    "    #@jit.script_method\n",
    "    def compute_levels_seasons(self, y, idxs):\n",
    "        pass\n",
    "\n",
    "    def normalize(self, y, level, seasonalities):\n",
    "        pass\n",
    "\n",
    "    def predict(self, trend, levels, seasonalities):\n",
    "        pass\n",
    "\n",
    "    def forward(self, ts_object):\n",
    "        # parse mc\n",
    "        input_size = self.mc.input_size\n",
    "        output_size = self.mc.output_size\n",
    "        exogenous_size = self.mc.exogenous_size\n",
    "        noise_std = self.mc.noise_std\n",
    "        seasonality = self.mc.seasonality\n",
    "        batch_size = len(ts_object.idxs)\n",
    "\n",
    "        # Parse ts_object\n",
    "        y = ts_object.y\n",
    "        idxs = ts_object.idxs\n",
    "        n_series, n_time = y.shape\n",
    "        if self.training:\n",
    "            windows_end = n_time-input_size-output_size+1\n",
    "            windows_range = range(windows_end)\n",
    "        else:\n",
    "            windows_start = n_time-input_size-output_size+1\n",
    "            windows_end = n_time-input_size+1\n",
    "\n",
    "            windows_range = range(windows_start, windows_end)\n",
    "        n_windows = len(windows_range)\n",
    "        assert n_windows>0\n",
    "\n",
    "        # Initialize windows, levels and seasonalities\n",
    "        levels, seasonalities = self.compute_levels_seasons(y, idxs)\n",
    "        windows_y_hat = torch.zeros((n_windows, batch_size, input_size+exogenous_size),\n",
    "                                                                device=self.mc.device)\n",
    "        windows_y = torch.zeros((n_windows, batch_size, output_size),\n",
    "                                                        device=self.mc.device)\n",
    "\n",
    "        for i, window in enumerate(windows_range):\n",
    "            # Windows yhat\n",
    "            y_hat_start = window\n",
    "            y_hat_end = input_size + window\n",
    "\n",
    "            # Y_hat deseasonalization and normalization\n",
    "            window_y_hat = self.normalize(y=y[:, y_hat_start:y_hat_end],\n",
    "                                          level=levels[:, [y_hat_end-1]],\n",
    "                                          seasonalities=seasonalities,\n",
    "                                          start=y_hat_start, end=y_hat_end)\n",
    "\n",
    "            if self.training:\n",
    "                window_y_hat = self.gaussian_noise(window_y_hat, std=noise_std)\n",
    "\n",
    "            # Concatenate categories\n",
    "            if exogenous_size>0:\n",
    "                window_y_hat = torch.cat((window_y_hat, ts_object.categories), 1)\n",
    "\n",
    "            windows_y_hat[i, :, :] += window_y_hat\n",
    "\n",
    "            # Windows y (for loss during train)\n",
    "            if self.training:\n",
    "                y_start = y_hat_end\n",
    "                y_end = y_start+output_size\n",
    "                # Y deseasonalization and normalization\n",
    "                window_y = self.normalize(y=y[:, y_start:y_end],\n",
    "                                          level=levels[:, [y_start]],\n",
    "                                          seasonalities=seasonalities,\n",
    "                                          start=y_start, end=y_end)\n",
    "                windows_y[i, :, :] += window_y\n",
    "\n",
    "        return windows_y_hat, windows_y, levels, seasonalities\n",
    "\n",
    "class _ESM(_ES):\n",
    "    def __init__(self, mc):\n",
    "        super(_ESM, self).__init__(mc)\n",
    "        # Level and Seasonality Smoothing parameters\n",
    "        # 1 level, S seasonalities, S init_seas\n",
    "        embeds_size = 1 + len(self.mc.seasonality) + sum(self.mc.seasonality)\n",
    "        init_embeds = torch.ones((self.n_series, embeds_size)) * 0.5\n",
    "        self.embeds = nn.Embedding(self.n_series, embeds_size)\n",
    "        self.embeds.weight.data.copy_(init_embeds)\n",
    "        self.register_buffer('seasonality', torch.LongTensor(self.mc.seasonality))\n",
    "\n",
    "    #@jit.script_method\n",
    "    def compute_levels_seasons(self, y, idxs):\n",
    "        \"\"\"\n",
    "        Computes levels and seasons\n",
    "        \"\"\"\n",
    "        # Lookup parameters per serie\n",
    "        #seasonality = self.seasonality\n",
    "        embeds = self.embeds(idxs)\n",
    "        lev_sms = torch.sigmoid(embeds[:, 0])\n",
    "\n",
    "        # Initialize seasonalities\n",
    "        seas_prod = torch.ones(len(y[:,0])).to(y.device)\n",
    "        #seasonalities1 = torch.jit.annotate(List[Tensor], [])\n",
    "        #seasonalities2 = torch.jit.annotate(List[Tensor], [])\n",
    "        seasonalities1 = []\n",
    "        seasonalities2 = []\n",
    "        seas_sms1 = torch.ones(1).to(y.device)\n",
    "        seas_sms2 = torch.ones(1).to(y.device)\n",
    "\n",
    "        if len(self.seasonality)>0:\n",
    "            seas_sms1 = torch.sigmoid(embeds[:, 1])\n",
    "            init_seas1 = torch.exp(embeds[:, 2:(2+self.seasonality[0])]).unbind(1)\n",
    "            assert len(init_seas1) == self.seasonality[0]\n",
    "\n",
    "            for i in range(len(init_seas1)):\n",
    "                seasonalities1 += [init_seas1[i]]\n",
    "            seasonalities1 += [init_seas1[0]]\n",
    "            seas_prod = seas_prod * init_seas1[0]\n",
    "\n",
    "        if len(self.seasonality)==2:\n",
    "            seas_sms2 = torch.sigmoid(embeds[:, 2+self.seasonality[0]])\n",
    "            init_seas2 = torch.exp(embeds[:, 3+self.seasonality[0]:]).unbind(1)\n",
    "            assert len(init_seas2) == self.seasonality[1]\n",
    "\n",
    "            for i in range(len(init_seas2)):\n",
    "                seasonalities2 += [init_seas2[i]]\n",
    "            seasonalities2 += [init_seas2[0]]\n",
    "            seas_prod = seas_prod * init_seas2[0]\n",
    "\n",
    "        # Initialize levels\n",
    "        #levels = torch.jit.annotate(List[Tensor], [])\n",
    "        levels = []\n",
    "        levels += [y[:,0]/seas_prod]\n",
    "\n",
    "        # Recursive seasonalities and levels\n",
    "        ys = y.unbind(1)\n",
    "        n_time = len(ys)\n",
    "        for t in range(1, n_time):\n",
    "\n",
    "            seas_prod_t = torch.ones(len(y[:,t])).to(y.device)\n",
    "            if len(self.seasonality)>0:\n",
    "                seas_prod_t = seas_prod_t * seasonalities1[t]\n",
    "            if len(self.seasonality)==2:\n",
    "                seas_prod_t = seas_prod_t * seasonalities2[t]\n",
    "\n",
    "            newlev = lev_sms * (ys[t] / seas_prod_t) + (1-lev_sms) * levels[t-1]\n",
    "            levels += [newlev]\n",
    "\n",
    "            if len(self.seasonality)==1:\n",
    "                newseason1 = seas_sms1 * (ys[t] / newlev) + (1-seas_sms1) * seasonalities1[t]\n",
    "                seasonalities1 += [newseason1]\n",
    "\n",
    "            if len(self.seasonality)==2:\n",
    "                newseason1 = seas_sms1 * (ys[t] / (newlev * seasonalities2[t])) + \\\n",
    "                                         (1-seas_sms1) * seasonalities1[t]\n",
    "                seasonalities1 += [newseason1]\n",
    "                newseason2 = seas_sms2 * (ys[t] / (newlev * seasonalities1[t])) + \\\n",
    "                                         (1-seas_sms2) * seasonalities2[t]\n",
    "                seasonalities2 += [newseason2]\n",
    "\n",
    "        levels = torch.stack(levels).transpose(1,0)\n",
    "\n",
    "        #seasonalities = torch.jit.annotate(List[Tensor], [])\n",
    "        seasonalities = []\n",
    "\n",
    "        if len(self.seasonality)>0:\n",
    "            seasonalities += [torch.stack(seasonalities1).transpose(1,0)]\n",
    "\n",
    "        if len(self.seasonality)==2:\n",
    "            seasonalities += [torch.stack(seasonalities2).transpose(1,0)]\n",
    "\n",
    "        return levels, seasonalities\n",
    "\n",
    "    def normalize(self, y, level, seasonalities, start, end):\n",
    "        # Deseasonalization and normalization\n",
    "        y_n = y / level\n",
    "        for s in range(len(self.seasonality)):\n",
    "            y_n /= seasonalities[s][:, start:end]\n",
    "        y_n = torch.log(y_n)\n",
    "        return y_n\n",
    "\n",
    "    def predict(self, trend, levels, seasonalities):\n",
    "        output_size = self.mc.output_size\n",
    "        seasonality = self.mc.seasonality\n",
    "        n_time = levels.shape[1]\n",
    "\n",
    "        # Denormalize\n",
    "        trend = torch.exp(trend)\n",
    "\n",
    "        # Completion of seasonalities if prediction horizon is larger than seasonality\n",
    "        # Naive2 like prediction, to avoid recursive forecasting\n",
    "        for s in range(len(seasonality)):\n",
    "            if output_size > seasonality[s]:\n",
    "                repetitions = int(np.ceil(output_size/seasonality[s]))-1\n",
    "                last_season = seasonalities[s][:, -seasonality[s]:]\n",
    "                extra_seasonality = last_season.repeat((1, repetitions))\n",
    "                seasonalities[s] = torch.cat((seasonalities[s], extra_seasonality), 1)\n",
    "\n",
    "        # Deseasonalization and normalization (inverse)\n",
    "        y_hat = trend * levels[:,[n_time-1]]\n",
    "        for s in range(len(seasonality)):\n",
    "            y_hat *= seasonalities[s][:, n_time:(n_time+output_size)]\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "class _RNN(nn.Module):\n",
    "    def __init__(self, mc):\n",
    "        super(_RNN, self).__init__()\n",
    "        self.mc = mc\n",
    "        self.layers = len(mc.dilations)\n",
    "\n",
    "        layers = []\n",
    "        for grp_num in range(len(mc.dilations)):\n",
    "            if grp_num == 0:\n",
    "                input_size = mc.input_size + mc.exogenous_size\n",
    "            else:\n",
    "                input_size = mc.state_hsize\n",
    "            layer = DRNN(input_size,\n",
    "                                     mc.state_hsize,\n",
    "                                     n_layers=len(mc.dilations[grp_num]),\n",
    "                                     dilations=mc.dilations[grp_num],\n",
    "                                     cell_type=mc.cell_type)\n",
    "            layers.append(layer)\n",
    "\n",
    "        self.rnn_stack = nn.Sequential(*layers)\n",
    "\n",
    "        if self.mc.add_nl_layer:\n",
    "            self.MLPW  = nn.Linear(mc.state_hsize, mc.state_hsize)\n",
    "\n",
    "        self.adapterW  = nn.Linear(mc.state_hsize, mc.output_size)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        for layer_num in range(len(self.rnn_stack)):\n",
    "            residual = input_data\n",
    "            output, _ = self.rnn_stack[layer_num](input_data)\n",
    "            if layer_num > 0:\n",
    "                output += residual\n",
    "            input_data = output\n",
    "\n",
    "        if self.mc.add_nl_layer:\n",
    "            input_data = self.MLPW(input_data)\n",
    "            input_data = torch.tanh(input_data)\n",
    "\n",
    "        input_data = self.adapterW(input_data)\n",
    "        return input_data\n",
    "\n",
    "\n",
    "class _ESRNN(nn.Module):\n",
    "    def __init__(self, mc):\n",
    "        super(_ESRNN, self).__init__()\n",
    "        self.mc = mc\n",
    "        self.es = _ESM(mc).to(self.mc.device)\n",
    "        self.rnn = _RNN(mc).to(self.mc.device)\n",
    "\n",
    "    def forward(self, ts_object):\n",
    "        # ES Forward\n",
    "        windows_y_hat, windows_y, levels, seasonalities = self.es(ts_object)\n",
    "\n",
    "        # RNN Forward\n",
    "        windows_y_hat = self.rnn(windows_y_hat)\n",
    "\n",
    "        return windows_y, windows_y_hat, levels\n",
    "\n",
    "    def predict(self, ts_object):\n",
    "        # ES Forward\n",
    "        windows_y_hat, _, levels, seasonalities = self.es(ts_object)\n",
    "\n",
    "        # RNN Forward\n",
    "        windows_y_hat = self.rnn(windows_y_hat)\n",
    "        trend = windows_y_hat[-1,:,:] # Last observation prediction\n",
    "\n",
    "        y_hat = self.es.predict(trend, levels, seasonalities)\n",
    "        return y_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
