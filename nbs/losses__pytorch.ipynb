{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp losses.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch as t\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def divide_no_nan(a, b):\n",
    "    \"\"\"\n",
    "    Auxiliary funtion to handle divide by 0\n",
    "    \"\"\"\n",
    "    div = a / b\n",
    "    div[div != div] = 0.0\n",
    "    div[div == float('inf')] = 0.0\n",
    "    return div\n",
    "\n",
    "#############################################################################\n",
    "# FORECASTING LOSSES\n",
    "#############################################################################\n",
    "\n",
    "def MAPELoss(y, y_hat, mask=None):\n",
    "    \"\"\"MAPE Loss\n",
    "\n",
    "    Calculates Mean Absolute Percentage Error between\n",
    "    y and y_hat. MAPE measures the relative prediction\n",
    "    accuracy of a forecasting method by calculating the\n",
    "    percentual deviation of the prediction and the true\n",
    "    value at a given time and averages these devations\n",
    "    over the length of the series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: tensor (batch_size, output_size)\n",
    "        actual values in torch tensor.\n",
    "    y_hat: tensor (batch_size, output_size)\n",
    "        predicted values in torch tensor.\n",
    "    mask: tensor (batch_size, output_size)\n",
    "        specifies date stamps per serie\n",
    "        to consider in loss\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mape:\n",
    "    Mean absolute percentage error.\n",
    "    \"\"\"\n",
    "    mask = divide_no_nan(mask, t.abs(y))\n",
    "    mape = t.abs(y - y_hat) * mask\n",
    "    mape = t.mean(mape)\n",
    "    return mape\n",
    "\n",
    "# def MAPELoss(forecast: t.Tensor, target: t.Tensor, mask: t.Tensor):\n",
    "#     \"\"\"\n",
    "#     MAPE loss as defined in: https://en.wikipedia.org/wiki/Mean_absolute_percentage_error\n",
    "\n",
    "#     :param forecast: Forecast values. Shape: batch, time\n",
    "#     :param target: Target values. Shape: batch, time\n",
    "#     :param mask: 0/1 mask. Shape: batch, time\n",
    "#     :return: Loss value\n",
    "#     \"\"\"\n",
    "#     weights = divide_no_nan(mask, target)\n",
    "#     return t.mean(t.abs((forecast - target) * weights))\n",
    "\n",
    "def MSELoss(y, y_hat, mask=None):\n",
    "    \"\"\"MSE Loss\n",
    "\n",
    "    Calculates Mean Squared Error between\n",
    "    y and y_hat. MAPE measures the relative prediction\n",
    "    accuracy of a forecasting method by calculating the\n",
    "    percentual deviation of the prediction and the true\n",
    "    value at a given time and averages these devations\n",
    "    over the length of the series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: tensor (batch_size, output_size)\n",
    "        actual values in torch tensor.\n",
    "    y_hat: tensor (batch_size, output_size)\n",
    "        predicted values in torch tensor.\n",
    "    mask: tensor (batch_size, output_size)\n",
    "        specifies date stamps per serie\n",
    "        to consider in loss\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mse:\n",
    "    Mean Squared Error.\n",
    "    \"\"\"\n",
    "    mse = (y - y_hat)**2\n",
    "    mse = mask * mse\n",
    "    mse = t.mean(mse)\n",
    "    return mse\n",
    "\n",
    "def RMSELoss(y, y_hat, mask=None):\n",
    "    \"\"\"RMSE Loss\n",
    "\n",
    "    Calculates Mean Squared Error between\n",
    "    y and y_hat. MAPE measures the relative prediction\n",
    "    accuracy of a forecasting method by calculating the\n",
    "    percentual deviation of the prediction and the true\n",
    "    value at a given time and averages these devations\n",
    "    over the length of the series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: tensor (batch_size, output_size)\n",
    "        actual values in torch tensor.\n",
    "    y_hat: tensor (batch_size, output_size)\n",
    "        predicted values in torch tensor.\n",
    "    mask: tensor (batch_size, output_size)\n",
    "        specifies date stamps per serie\n",
    "        to consider in loss\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rmse:\n",
    "    Root Mean Squared Error.\n",
    "    \"\"\"\n",
    "    rmse = (y - y_hat)**2\n",
    "    rmse = mask * rmse\n",
    "    rmse = t.sqrt(t.mean(rmse))\n",
    "    return rmse\n",
    "\n",
    "def SMAPELoss(y, y_hat, mask=None):\n",
    "    \"\"\"SMAPE2 Loss\n",
    "\n",
    "    Calculates Symmetric Mean Absolute Percentage Error.\n",
    "    SMAPE measures the relative prediction accuracy of a\n",
    "    forecasting method by calculating the relative deviation\n",
    "    of the prediction and the true value scaled by the sum of the\n",
    "    absolute values for the prediction and true value at a\n",
    "    given time, then averages these devations over the length\n",
    "    of the series. This allows the SMAPE to have bounds between\n",
    "    0% and 200% which is desireble compared to normal MAPE that\n",
    "    may be undetermined.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: tensor (batch_size, output_size)\n",
    "        actual values in torch tensor.\n",
    "    y_hat: tensor (batch_size, output_size)\n",
    "        predicted values in torch tensor.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    smape:\n",
    "        symmetric mean absolute percentage error\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [1] https://robjhyndman.com/hyndsight/smape/ (Makridakis 1993)\n",
    "    \"\"\"\n",
    "    if mask is None:\n",
    "        mask = t.ones(y_hat.size())\n",
    "    delta_y = t.abs((y - y_hat))\n",
    "    scale = t.abs(y) + t.abs(y_hat)\n",
    "    smape = divide_no_nan(delta_y, scale)\n",
    "    smape = smape * mask\n",
    "    smape = 2 * t.mean(smape)\n",
    "    return smape\n",
    "\n",
    "\n",
    "def MASELoss(y, y_hat, y_insample, seasonality, mask=None) :\n",
    "    \"\"\" Calculates the M4 Mean Absolute Scaled Error.\n",
    "\n",
    "    MASE measures the relative prediction accuracy of a\n",
    "    forecasting method by comparinng the mean absolute errors\n",
    "    of the prediction and the true value against the mean\n",
    "    absolute errors of the seasonal naive model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seasonality: int\n",
    "        main frequency of the time series\n",
    "        Hourly 24,  Daily 7, Weekly 52,\n",
    "        Monthly 12, Quarterly 4, Yearly 1\n",
    "    y: tensor (batch_size, output_size)\n",
    "        actual test values\n",
    "    y_hat: tensor (batch_size, output_size)\n",
    "        predicted values\n",
    "    y_train: tensor (batch_size, input_size)\n",
    "        actual insample values for Seasonal Naive predictions\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mase:\n",
    "        mean absolute scaled error\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    [1] https://robjhyndman.com/papers/mase.pdf\n",
    "    \"\"\"\n",
    "    if mask is None:\n",
    "        mask = t.ones(y_hat.size())\n",
    "    delta_y = t.abs(y - y_hat)\n",
    "    scale = t.mean(t.abs(y_insample[:, seasonality:] - \\\n",
    "                            y_insample[:, :-seasonality]), axis=1)\n",
    "    mase = divide_no_nan(delta_y, scale[:, None])\n",
    "    mase = mase * mask\n",
    "    mase = t.mean(mase)\n",
    "    return mase\n",
    "\n",
    "def MAELoss(y, y_hat, mask=None):\n",
    "    \"\"\"MAE Loss\n",
    "\n",
    "    Calculates Mean Absolute Error between\n",
    "    y and y_hat. MAE measures the relative prediction\n",
    "    accuracy of a forecasting method by calculating the\n",
    "    deviation of the prediction and the true\n",
    "    value at a given time and averages these devations\n",
    "    over the length of the series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: tensor (batch_size, output_size)\n",
    "        actual values in torch tensor.\n",
    "    y_hat: tensor (batch_size, output_size)\n",
    "        predicted values in torch tensor.\n",
    "    mask: tensor (batch_size, output_size)\n",
    "        specifies date stamps per serie\n",
    "        to consider in loss\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mae:\n",
    "    Mean absolute error.\n",
    "    \"\"\"\n",
    "    mae = t.abs(y - y_hat) * mask\n",
    "    mae = t.mean(mae)\n",
    "    return mae\n",
    "\n",
    "def PinballLoss(y, y_hat, mask=None, tau=0.5):\n",
    "    \"\"\"Pinball Loss\n",
    "    Computes the pinball loss between y and y_hat.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: tensor (batch_size, output_size)\n",
    "        actual values in torch tensor.\n",
    "    y_hat: tensor (batch_size, output_size)\n",
    "        predicted values in torch tensor.\n",
    "    tau: float, between 0 and 1\n",
    "        the slope of the pinball loss, in the context of\n",
    "        quantile regression, the value of tau determines the\n",
    "        conditional quantile level.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pinball:\n",
    "        average accuracy for the predicted quantile\n",
    "    \"\"\"\n",
    "    if mask is None:\n",
    "        mask = t.ones(y_hat.size())\n",
    "    delta_y = t.sub(y, y_hat)\n",
    "    pinball = t.max(t.mul(tau, delta_y), t.mul((tau - 1), delta_y))\n",
    "    pinball = pinball * mask\n",
    "    pinball = t.mean(pinball)\n",
    "    return pinball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def QuadraticBarrierLoss(z, tau):\n",
    "    \"\"\"\n",
    "    Quadratic penalty as substitition to inequality constraints\n",
    "    Learning to play in a day: Faster deep reinforcement learning by optimality tightening.\n",
    "    \"\"\"\n",
    "    barrier = tau * t.max(t.zeros_like(z), z)**2\n",
    "    loss = barrier.mean()\n",
    "    return loss\n",
    "\n",
    "# def LogbarrierLoss(z, t):\n",
    "#     \"\"\"\n",
    "#     https://www.groundai.com/project/log-barrier-constrained-cnns/1\n",
    "#     https://github.com/AnonymousICCVSubmission/extended_log_barrier/blob/master/losses.py\n",
    "#     \"\"\"\n",
    "#     assert z.shape == ()\n",
    "\n",
    "#     if z <= - 1 / t**2:\n",
    "#         return - torch.log(-z) / t\n",
    "#     else:\n",
    "#         return t * z + -np.log(1 / (t**2)) / t + 1 / t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-quantile Loss\n",
    "\n",
    "MQLoss definition and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def MQLoss(y, y_hat, quantiles, mask=None): \n",
    "    \"\"\"MQLoss\n",
    "\n",
    "    Calculates Average Multi-quantile Loss function, for\n",
    "    a given set of quantiles, based on the absolute \n",
    "    difference between predicted and true values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: tensor (batch_size) actual values in torch tensor.\n",
    "    y_hat: tensor (batch_size, n_quantiles) predicted values in torch tensor.\n",
    "    mask: tensor (batch_size, n_quantiles) specifies date stamps per serie\n",
    "          to consider in loss\n",
    "    quantiles: tensor(n_quantiles) quantiles to estimate from the distribution of y.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lq: tensor(n_quantiles) average multi-quantile loss.\n",
    "    \"\"\"    \n",
    "    \n",
    "    if mask == None: mask = t.ones_like(y_hat)\n",
    "\n",
    "    error = y_hat - y.unsqueeze(1)\n",
    "    sq = t.maximum(-error, t.zeros_like(error))\n",
    "    s1_q = t.maximum(error, t.zeros_like(error))\n",
    "    loss = (quantiles * sq + (1 - quantiles) * s1_q) * mask\n",
    "    return t.mean(t.sum(loss, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MQTestModel(nn.Module):  \n",
    "\n",
    "    def __init__(self, n_quantiles):\n",
    "        super(MQTestModel, self).__init__()\n",
    "        self.linear_layer = nn.Linear(in_features=1, out_features=n_quantiles, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_hat = self.linear_layer(x)\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTraining(Dataset):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, y, x):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.len = y.shape[0]\n",
    "\n",
    "    # Getter\n",
    "    def __getitem__(self, index):          \n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from scipy.stats import hmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters and sample data parameters\n",
    "\n",
    "t.cuda.manual_seed(7)\n",
    "\n",
    "# Sample data\n",
    "n_obs = 10000\n",
    "mean = 0.0 # to generate random numbers from N(mean, std)\n",
    "std = 7.0 # to generate random numbers from N(mean, std)\n",
    "start = 0.05 # First quantile\n",
    "end = 0.95 # Last quantiles\n",
    "steps = 4 # Number of quantiles\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 500\n",
    "lr = 0.08\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantiles:\n",
      "tensor([0.0500, 0.3500, 0.6500, 0.9500])\n",
      "\n",
      "y.shape: torch.Size([10000]), x.shape: torch.Size([10000, 1])\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "\n",
    "quantiles = t.linspace(start=start, end=end, steps=steps) \n",
    "print(f'quantiles:\\n{quantiles}')\n",
    "y = t.normal(mean=mean, std=std, size=(n_obs,))\n",
    "x = t.ones(size=(len(y), 1))\n",
    "print(f'\\ny.shape: {y.shape}, x.shape: {x.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training \n",
    "\n",
    "model = MQTestModel(n_quantiles=len(quantiles))\n",
    "dataset = DataTraining(x=x, y=y)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=batch_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def train_model(model, epochs, print_progress=False):\n",
    "\n",
    "    start = time.time()\n",
    "    i = 0 \n",
    "    training_trajectory = [list(), list()]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for x, y in dataloader:\n",
    "            \n",
    "            i += 1\n",
    "            y_hat = model(x)\n",
    "            training_loss = MQLoss(y=y, y_hat=y_hat, quantiles=quantiles)\n",
    "            if i % ((epochs * (n_obs / batch_size)) / 100) == 0: \n",
    "                training_trajectory[0].append(i)\n",
    "                training_trajectory[1].append(training_loss.detach().numpy())\n",
    "            optimizer.zero_grad()\n",
    "            training_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            display_string = 'Step: {}, Time: {:03.3f}, Insample {}: {:.5f}'.format(i, \n",
    "                                                                                    time.time()-start, \n",
    "                                                                                    \"MQLoss\", \n",
    "                                                                                    training_loss.cpu().data.numpy())\n",
    "            if print_progress: print(display_string)\n",
    "\n",
    "    return model, training_trajectory\n",
    "\n",
    "trained_model = train_model(model=model, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trained_model[1][0], trained_model[1][1])\n",
    "plt.xlabel('# iteration')\n",
    "plt.ylabel('MQLoss')\n",
    "plt.title('MQLoss v. Iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantiles:\n",
      "tensor([0.0500, 0.3500, 0.6500, 0.9500])\n",
      "\n",
      "q_hat:\n",
      "[0.0499 0.3505 0.6491 0.95  ]\n",
      "\n",
      "absolute errors:\n",
      "[[1.00000745e-04 5.00005960e-04 8.99976158e-04 1.19209289e-08]]\n",
      "\n",
      "average absolute error: 0.0000000477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "\n",
    "def absolute_error(quantiles, y, y_hat):\n",
    "    \"\"\"accuracy\n",
    "\n",
    "    Calculates the accuracy of the quantiles\n",
    "    estimated by the MQTestModel\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    quantiles: tensor(n_quantiles) quantiles to estimate from the distribution of y.\n",
    "    y: tensor (n_obs) actual values in torch tensor.\n",
    "    y_hat: tensor(n_obs, n_quantiles) predicted values in torch tensor.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    accuracy: np.array(n_quantiles) absolute error (in pp) between the true and estimated quantiles\n",
    "    \"\"\"\n",
    "    \n",
    "    quantiles = np.reshape(quantiles.unsqueeze(1).cpu().data.numpy(), newshape=(1, quantiles.shape[0]))\n",
    "    y = y.unsqueeze(1).cpu().data.numpy()\n",
    "    y_hat = np.unique(y_hat.unsqueeze(1).cpu().data.numpy()) \n",
    "    \n",
    "    q_hat = (y <= y_hat).sum(axis=0) / len(y)\n",
    "    abs_error = np.absolute(quantiles - q_hat)\n",
    "    av_abs_error = hmean(abs_error, axis=None)\n",
    "\n",
    "    return q_hat, abs_error, av_abs_error\n",
    "    \n",
    "mq_error = absolute_error(quantiles=quantiles, y=y, y_hat=trained_model[0](x))\n",
    "print(f'quantiles:\\n{quantiles}\\n')\n",
    "print(f'q_hat:\\n{mq_error[0]}\\n')\n",
    "print(f'absolute errors:\\n{mq_error[1]}\\n')\n",
    "print(f'average absolute error: {mq_error[2]:.10f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mqloss(y, y_hat, quantiles, mask=None): \n",
    "    \"\"\"mqloss\n",
    "\n",
    "    Calculates Average Multi-quantile Loss function, for\n",
    "    a given set of quantiles, based on the absolute \n",
    "    difference between predicted and true values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y: np.array (batch_size) actual values in torch tensor.\n",
    "    y_hat: np.array (batch_size, n_quantiles) predicted values in torch tensor.\n",
    "    mask: np.array (batch_size, n_quantiles) specifies date stamps per serie\n",
    "          to consider in loss\n",
    "    quantiles: np.array(n_quantiles) quantiles to estimate from the distribution of y.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lq: np.array(n_quantiles) average multi-quantile loss.\n",
    "    \"\"\"    \n",
    "    \n",
    "    if mask == None: mask = np.ones_like(y_hat)\n",
    "\n",
    "    error = y_hat - np.expand_dims(y, axis=1)\n",
    "    sq = np.maximum(-error, np.zeros_like(error))\n",
    "    s1_q = np.maximum(error, np.zeros_like(error)) \n",
    "    loss = (quantiles * sq + (1 - quantiles) * s1_q) * mask\n",
    "    return np.mean(np.sum(loss, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with the PyTorch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_pytorch: 1.603600025177002\n",
      "loss_numpy: 1.603600025177002\n",
      "Difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "y_tensor = t.normal(mean=mean, std=std, size=(n_obs,)); \n",
    "y_numpy = y_tensor.cpu().numpy()\n",
    "y_hat_tensor = (y_tensor + t.normal(mean=0, std=1, size=(n_obs,))).view(-1,1).repeat(1, quantiles.shape[0])\n",
    "y_hat_numpy = y_hat_tensor.cpu().numpy()\n",
    "quantiles_tensor = quantiles\n",
    "quantiles_numpy = quantiles_tensor.cpu().numpy()\n",
    "\n",
    "loss_pytorch = MQLoss(y_tensor, y_hat_tensor, quantiles_tensor)\n",
    "loss_numpy = mqloss(y_numpy, y_hat_numpy, quantiles_numpy)\n",
    "\n",
    "print(f'loss_pytorch: {loss_pytorch}')\n",
    "print(f'loss_numpy: {loss_numpy}')\n",
    "print(f'Difference: {abs(loss_pytorch - loss_numpy)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
