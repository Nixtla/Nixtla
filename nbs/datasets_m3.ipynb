{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.datasets.m3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M3 dataset\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nixtla.data.datasets.utils import download_file, Info, TimeSeriesDataclass\n",
    "from nixtla.data.ts_dataset import TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "SOURCE_URL = 'https://forecasters.org/data/m3comp/M3C.xls'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tourism meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Yearly:\n",
    "    seasonality: int = 1\n",
    "    horizon: int = 6\n",
    "    freq: str = 'Y'\n",
    "    sheet_name: str = 'M3Year'\n",
    "    name: str = 'Yearly'\n",
    "    n_ts: int = 645\n",
    "\n",
    "@dataclass\n",
    "class Quarterly:\n",
    "    seasonality: int = 4\n",
    "    horizon: int = 8\n",
    "    freq: str = 'Q'\n",
    "    sheet_name: str = 'M3Quart'\n",
    "    name: str = 'Quarterly'\n",
    "    n_ts: int = 756\n",
    "\n",
    "@dataclass\n",
    "class Monthly:\n",
    "    seasonality: int = 12\n",
    "    horizon: int = 18\n",
    "    freq: str = 'M'\n",
    "    sheet_name: str = 'M3Month'\n",
    "    name: str = 'Monthly'\n",
    "    n_ts: int = 1428\n",
    "\n",
    "@dataclass\n",
    "class Other:\n",
    "    seasonality: int = 1\n",
    "    horizon: int = 8\n",
    "    freq: str = 'D'\n",
    "    sheet_name: str = 'M3Other'\n",
    "    name: str = 'Other'\n",
    "    n_ts: int = 174"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "M3Info = Info(groups=('Yearly', 'Quarterly', 'Monthly', 'Other'),\n",
    "              class_groups=(Yearly, Quarterly, Monthly, Other))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _return_year(ts):\n",
    "    year = ts.iloc[0]\n",
    "    year = year if year != 0 else 1970\n",
    "\n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class M3(TimeSeriesDataclass):\n",
    "\n",
    "    @staticmethod\n",
    "    def load(directory: str,\n",
    "             group: str,\n",
    "             return_tensor: bool = True) -> Union[TimeSeriesDataset, TimeSeriesDataclass]:\n",
    "        \"\"\"\n",
    "        Downloads and loads M3 data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Yearly', 'Quarterly', 'Monthly', 'Other'.\n",
    "        return_tensor: bool\n",
    "            Wheter return TimeSeriesDataset (tensors, True) or\n",
    "            TimeSeriesDataclass (dataframes)\n",
    "            \n",
    "        Notes\n",
    "        -----\n",
    "        [1] Returns train+test sets.\n",
    "        [2] There are monthly time series without start year. \n",
    "            This time series will start with 1970.\n",
    "        [3] Other time series have no start date.\n",
    "            This time series will start with 1970.\n",
    "        \"\"\"\n",
    "        path = Path(directory) / 'm3' / 'datasets'\n",
    "\n",
    "        M3.download(directory)\n",
    "\n",
    "        class_group = M3Info.get_group(group)\n",
    "\n",
    "        df = pd.read_excel(path / 'M3C.xls', sheet_name=class_group.sheet_name)\n",
    "\n",
    "        df = df.rename(columns={'Series': 'unique_id',\n",
    "                                'Category': 'category',\n",
    "                                'Starting Year': 'year',\n",
    "                                'Starting Month': 'month'})\n",
    "\n",
    "        df['unique_id'] = [class_group.name[0] + str(i + 1) for i in range(len(df))]\n",
    "        S = df.filter(items=['unique_id', 'category'])\n",
    "\n",
    "        id_vars = list(df.columns[:6])\n",
    "        df = pd.melt(df, id_vars=id_vars, var_name='ds', value_name='y')\n",
    "        df = df.dropna().sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "\n",
    "        freq = pd.tseries.frequencies.to_offset(class_group.freq)\n",
    "\n",
    "        if group == 'Other':\n",
    "            df['year'] = 1970\n",
    "\n",
    "        df['ds'] = df.groupby('unique_id')['year'] \\\n",
    "                     .transform(lambda df: pd.date_range(f'{_return_year(df)}-01-01',\n",
    "                                                         periods=df.shape[0],\n",
    "                                                         freq=freq))\n",
    "\n",
    "        df = df.filter(items=['unique_id', 'ds', 'y'])\n",
    "        \n",
    "        if return_tensor:\n",
    "            S['category'] = S['category'].astype('category').cat.codes\n",
    "            return TimeSeriesDataset(y_df=df, X_s_df=S, X_t_df=None)\n",
    "        else:\n",
    "            return TimeSeriesDataclass(Y=df, S=S, X=None, idx_categorical_static=[0], group=group)\n",
    "\n",
    "    @staticmethod\n",
    "    def download(directory: Path) -> None:\n",
    "        \"\"\"Download M3 Dataset.\"\"\"\n",
    "        path = Path(directory) / 'm3' / 'datasets'\n",
    "        if not path.exists():\n",
    "            download_file(path, SOURCE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly\n",
      "Processing dataframes ...\n",
      "Creating ts tensor ...\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.8519e+03,\n",
      "          8.4078e+03, 9.1560e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.4720e+03,\n",
      "          3.1870e+03, 3.0580e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.4630e+03,\n",
      "          3.5390e+03, 4.1670e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.5124e+03,\n",
      "          4.4194e+03, 4.5070e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.1350e+03,\n",
      "          1.8010e+03, 1.7100e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.7814e+03,\n",
      "          2.3793e+03, 2.7230e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]]])\n",
      "Quarterly\n",
      "Processing dataframes ...\n",
      "Creating ts tensor ...\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.7070e+03,\n",
      "          5.6618e+03, 6.1766e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.8938e+03,\n",
      "          8.2239e+03, 8.9043e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.0200e+03,\n",
      "          5.1480e+03, 5.5640e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.1953e+03,\n",
      "          8.1836e+03, 8.9038e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.5039e+03,\n",
      "          6.6030e+03, 7.7200e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.0464e+03,\n",
      "          5.5958e+03, 9.1155e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]]])\n",
      "Monthly\n",
      "Processing dataframes ...\n",
      "Creating ts tensor ...\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.8000e+02,\n",
      "          2.0400e+03, 1.4400e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.8000e+03,\n",
      "          3.6400e+03, 4.1000e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.8600e+03,\n",
      "          5.0500e+03, 4.3600e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.9375e+03,\n",
      "          4.9930e+03, 5.1290e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.1065e+03,\n",
      "          6.1510e+03, 6.2035e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.1866e+03,\n",
      "          5.1434e+03, 5.1526e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]]])\n",
      "Other\n",
      "Processing dataframes ...\n",
      "Creating ts tensor ...\n",
      "tensor([[[3.0604e+03, 3.0212e+03, 3.3011e+03,  ..., 4.2854e+03,\n",
      "          4.2607e+03, 4.2496e+03],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[6.1538e+03, 6.1257e+03, 6.1414e+03,  ..., 5.8335e+03,\n",
      "          5.8448e+03, 5.8691e+03],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.9960e+03,\n",
      "          1.9800e+03, 2.0070e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.6530e+03,\n",
      "          2.6480e+03, 2.6280e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.8740e+03,\n",
      "          1.8710e+03, 1.8240e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.6714e+04,\n",
      "          2.6407e+04, 2.6265e+04],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "for group in M3Info.groups:\n",
    "    print(group)\n",
    "    m3_dataset = M3.load(directory='data', group=group)\n",
    "    print(m3_dataset.ts_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in M3Info.class_groups:\n",
    "    data = M3.load(directory='data', group=group.name, return_tensor=False).Y\n",
    "    unique_elements = data.groupby(['unique_id', 'ds']).size()\n",
    "    unique_ts = data.groupby('unique_id').size()\n",
    "\n",
    "    assert (unique_elements != 1).sum() == 0, f'Duplicated records found: {group.name}'\n",
    "    assert unique_ts.shape[0] == group.n_ts, f'Number of time series not match: {group.name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
