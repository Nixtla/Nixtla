{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.tsloader_general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch as t\n",
    "import copy\n",
    "from fastcore.foundation import patch\n",
    "from nixtla.data.tsdataset import TimeSeriesDataset\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# TODO: Check if the saturday zero protection is still in place\n",
    "class TimeSeriesLoader(object):\n",
    "    def __init__(self,\n",
    "                 ts_dataset: TimeSeriesDataset,\n",
    "                 model: str,\n",
    "                 offset: int,\n",
    "                 window_sampling_limit: int, \n",
    "                 input_size: int,\n",
    "                 output_size: int,\n",
    "                 idx_to_sample_freq: int,\n",
    "                 batch_size: int,\n",
    "                 complete_inputs: bool,\n",
    "                 complete_sample: bool,\n",
    "                 shuffle: bool,\n",
    "                 n_series_per_batch: int=None,\n",
    "                 verbose: bool=False):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        # Dataloader attributes\n",
    "        self.model = model\n",
    "        self.window_sampling_limit = window_sampling_limit\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.batch_size = batch_size\n",
    "        self.complete_inputs = complete_inputs\n",
    "        self.complete_sample = complete_sample\n",
    "        self.idx_to_sample_freq = idx_to_sample_freq\n",
    "        self.offset = offset\n",
    "        self.ts_dataset = ts_dataset\n",
    "        self.t_cols = self.ts_dataset.t_cols\n",
    "        if n_series_per_batch is not None:\n",
    "            self.n_series_per_batch = n_series_per_batch \n",
    "        else:\n",
    "            self.n_series_per_batch = min(batch_size, self.ts_dataset.n_series)\n",
    "        self.windows_per_serie = self.batch_size // self.n_series_per_batch\n",
    "        self.shuffle = shuffle\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        assert offset==0, 'sample_mask and offset interaction not implemented'\n",
    "        # assert window_sampling_limit==self.ts_dataset.max_len, \\\n",
    "        #     'sample_mask and window_samplig_limit interaction not implemented'        \n",
    "\n",
    "        # Dataloader protections\n",
    "        assert self.batch_size % self.n_series_per_batch == 0, \\\n",
    "                        f'batch_size {self.batch_size} must be multiple of n_series_per_batch {self.n_series_per_batch}'\n",
    "        assert self.n_series_per_batch <= self.ts_dataset.n_series, \\\n",
    "                        f'n_series_per_batch {n_series_per_batch} needs to be smaller than n_series {self.ts_dataset.n_series}'\n",
    "        assert offset < self.ts_dataset.max_len, \\\n",
    "            f'Offset {offset} must be smaller than max_len {self.ts_dataset.max_len}'\n",
    "    \n",
    "    def _get_sampleable_windows_idxs(self, ts_windows_flatten):\n",
    "        if not self.complete_sample:\n",
    "            #print(\"\\n\")\n",
    "            #print(\"INTENTO RARO DE LIMPIEZA8\")\n",
    "            sample_condition = t.sum(ts_windows_flatten[:, self.t_cols.index('sample_mask'), -self.output_size:], axis=1)\n",
    "            available_condition = t.sum(ts_windows_flatten[:, self.t_cols.index('available_mask'), :self.input_size], axis=1)\n",
    "            if self.complete_inputs:\n",
    "                completely_available_condition = (available_condition == (self.input_size)) * 1\n",
    "                sampling_idx = t.nonzero(completely_available_condition * sample_condition > 0)\n",
    "            else:\n",
    "                sampling_idx = t.nonzero(available_condition * sample_condition > 0)\n",
    "        else:\n",
    "            sample_condition = t.sum(self.ts_windows[:, self.t_cols.index('sample_mask'), -self.output_size:], axis=1)\n",
    "            sampling_idx = t.nonzero(sample_condition)\n",
    "\n",
    "        sampling_idx = list(sampling_idx.flatten().numpy())\n",
    "        assert len(sampling_idx)>0, 'Check the data and masks as sample_idxs are empty'\n",
    "        return sampling_idx\n",
    "\n",
    "    def _create_windows_tensor(self, ts_idxs=None):\n",
    "        \"\"\"\n",
    "        Comment here\n",
    "        TODO: Cuando creemos el otro dataloader, si es compatible lo hacemos funcion transform en utils\n",
    "        \"\"\"\n",
    "        # Filter function is used to define train tensor and validation tensor with the offset\n",
    "        # Default ts_idxs=ts_idxs sends all the data, otherwise filters series      \n",
    "        tensor, right_padding = self.ts_dataset.get_filtered_ts_tensor(offset=self.offset, output_size=self.output_size,\n",
    "                                                                       window_sampling_limit=self.window_sampling_limit,\n",
    "                                                                       ts_idxs=ts_idxs)\n",
    "        tensor = t.Tensor(tensor)\n",
    "\n",
    "        padder = t.nn.ConstantPad1d(padding=(self.input_size, right_padding), value=0)\n",
    "        tensor = padder(tensor)\n",
    "\n",
    "        # Creating rolling windows and 'flattens' them\n",
    "        windows = tensor.unfold(dimension=-1, size=self.input_size + self.output_size, step=self.idx_to_sample_freq)\n",
    "        # n_serie, n_channel, n_time, window_size -> n_serie, n_time, n_channel, window_size\n",
    "        #print(f'n_serie, n_channel, n_time, window_size = {windows.shape}')\n",
    "        windows = windows.permute(0,2,1,3)\n",
    "        #print(f'n_serie, n_time, n_channel, window_size = {windows.shape}')\n",
    "        windows = windows.reshape(-1, self.ts_dataset.n_channels, self.input_size + self.output_size)\n",
    "\n",
    "        # Broadcast s_matrix: This works because unfold in windows_tensor, orders: serie, time\n",
    "        s_matrix = self.ts_dataset.s_matrix[ts_idxs]\n",
    "        windows_per_serie = len(windows)//len(ts_idxs)\n",
    "        s_matrix = s_matrix.repeat(repeats=windows_per_serie, axis=0)\n",
    "\n",
    "        return windows, s_matrix\n",
    "\n",
    "    def __iter__(self):\n",
    "        n_series = self.ts_dataset.n_series\n",
    "        # Shuffle idx before epoch if self._is_train\n",
    "        if self.shuffle:\n",
    "            sample_idxs = np.random.choice(a=range(n_series), size=n_series, replace=False)\n",
    "        else:\n",
    "            sample_idxs = np.array(range(n_series))\n",
    "\n",
    "        n_batches = int(np.ceil(n_series / self.n_series_per_batch)) # Must be multiple of batch_size for paralel gpu\n",
    "\n",
    "        for idx in range(n_batches):\n",
    "            ts_idxs = sample_idxs[(idx * self.n_series_per_batch) : (idx + 1) * self.n_series_per_batch]\n",
    "            batch = self.__get_item__(index=ts_idxs)\n",
    "            yield batch\n",
    "\n",
    "    def __get_item__(self, index):\n",
    "        if (self.model == 'nbeats') or (self.model == 'tcn'):\n",
    "            return self._windows_batch(index)\n",
    "        elif self.model in ['esrnn','rnn']:\n",
    "            return self._full_series_batch(index)\n",
    "        else:\n",
    "            assert 1<0, 'error'\n",
    "\n",
    "    def _windows_batch(self, index):\n",
    "        \"\"\" NBEATS, TCN models \"\"\"\n",
    "\n",
    "        # Create windows for each sampled ts and sample random unmasked windows from each ts\n",
    "        windows, s_matrix = self._create_windows_tensor(ts_idxs=index)\n",
    "        sampleable_windows = self._get_sampleable_windows_idxs(ts_windows_flatten=windows)\n",
    "        self.sampleable_windows = sampleable_windows\n",
    "\n",
    "        # Get sample windows_idxs of batch\n",
    "        if self.shuffle:\n",
    "            windows_idxs = np.random.choice(sampleable_windows, self.batch_size, replace=True)\n",
    "        else:\n",
    "            windows_idxs = sampleable_windows\n",
    "        \n",
    "        # Index the windows and s_matrix tensors of batch\n",
    "        windows = windows[windows_idxs]\n",
    "        s_matrix = s_matrix[windows_idxs]\n",
    "\n",
    "        # Parse windows to elements of batch\n",
    "        insample_y = windows[:, self.t_cols.index('y'), :self.input_size]\n",
    "        insample_x = windows[:, (self.t_cols.index('y')+1):self.t_cols.index('available_mask'), :self.input_size]\n",
    "        available_mask = windows[:, self.t_cols.index('available_mask'), :self.input_size]\n",
    "\n",
    "        outsample_y = windows[:, self.t_cols.index('y'), self.input_size:]\n",
    "        outsample_x = windows[:, (self.t_cols.index('y')+1):self.t_cols.index('available_mask'), self.input_size:]\n",
    "        sample_mask = windows[:, self.t_cols.index('sample_mask'), self.input_size:]\n",
    "\n",
    "        batch = {'s_matrix': s_matrix,\n",
    "                 'insample_y': insample_y, 'insample_x':insample_x, 'insample_mask':available_mask,\n",
    "                 'outsample_y': outsample_y, 'outsample_x':outsample_x, 'outsample_mask':sample_mask}\n",
    "        return batch\n",
    "\n",
    "    def _full_series_batch(self, index):\n",
    "        \"\"\" ESRNN, RNN models \"\"\"\n",
    "        #TODO: think masks, do they make sense for ESRNN and RNN??\n",
    "        #TODO: window_sampling_limit no es dinamico por el offset no usado!!\n",
    "        #TODO: padding preventivo\n",
    "        ts_tensor, _ = self.ts_dataset.get_filtered_ts_tensor(offset=self.offset, output_size=self.output_size,\n",
    "                                                              window_sampling_limit=self.window_sampling_limit,\n",
    "                                                              ts_idxs=index)\n",
    "        ts_tensor = t.Tensor(ts_tensor)\n",
    "        # Trim batch to shorter time series TO AVOID ZERO PADDING, remove non sampleable ts\n",
    "        # shorter time series is driven by the last ts_idx which is available\n",
    "        # non-sampleable ts is driver by the first ts_idx which stops beeing sampleable\n",
    "        available_mask_tensor = ts_tensor[:, self.t_cols.index('available_mask'), :]\n",
    "        min_time_stamp = int(t.nonzero(t.min(available_mask_tensor, axis=0).values).min())\n",
    "        sample_mask_tensor = ts_tensor[:, self.t_cols.index('sample_mask'), :]\n",
    "        max_time_stamp = int(t.nonzero(t.min(sample_mask_tensor, axis=0).values).max())\n",
    "\n",
    "        available_ts = max_time_stamp - min_time_stamp\n",
    "        assert available_ts >= self.input_size + self.output_size, \\\n",
    "               f'Time series too short for given input size {self.input_size} and output size {self.output_size}.'\n",
    "\n",
    "        insample_y = ts_tensor[:, self.t_cols.index('y'), :]\n",
    "        insample_y = insample_y[:, min_time_stamp:max_time_stamp+1] #+1 because is not inclusive\n",
    "\n",
    "        insample_x = ts_tensor[:, self.t_cols.index('y')+1:self.t_cols.index('available_mask'), :]\n",
    "        insample_x = insample_x[:, min_time_stamp:max_time_stamp+1] #+1 because is not inclusive\n",
    "\n",
    "        s_matrix = self.ts_dataset.s_matrix[index]\n",
    "\n",
    "        batch = {'insample_y': insample_y, 'idxs': index, 'insample_x': insample_x, 's_matrix': s_matrix}\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def update_offset(self, offset):\n",
    "        if offset == self.offset:\n",
    "            return # Avoid extra computation\n",
    "        self.offset = offset\n",
    "\n",
    "    def get_meta_data_col(self, col):\n",
    "        return self.ts_dataset.get_meta_data_col(col)\n",
    "\n",
    "    def get_n_variables(self):\n",
    "        return self.ts_dataset.n_x, self.ts_dataset.n_s\n",
    "\n",
    "    def get_n_series(self):\n",
    "        return self.ts_dataset.n_series\n",
    "\n",
    "    def get_max_len(self):\n",
    "        return self.ts_dataset.max_len\n",
    "\n",
    "    def get_n_channels(self):\n",
    "        return self.ts_dataset.n_channels\n",
    "\n",
    "    def get_X_cols(self):\n",
    "        return self.ts_dataset.X_cols\n",
    "\n",
    "    def get_frequency(self):\n",
    "        return self.ts_dataset.frequency\n",
    "\n",
    "    def train(self):\n",
    "        self._is_train = True\n",
    "\n",
    "    def eval(self):\n",
    "        self._is_train = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nixtla.data.datasets.m4 import M4, M4Info\n",
    "print(M4Info.groups[0])\n",
    "Y_df, *_ = M4.load(directory='../data', group=M4Info.groups[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Validation splits\n",
      "                       ds    \n",
      "                      min max\n",
      "unique_id sample_mask        \n",
      "Y1        0.0          32  37\n",
      "          1.0           1  31\n",
      "Y10       0.0          20  25\n",
      "          1.0           1  19\n",
      "Y100      0.0          55  60\n",
      "...                    ..  ..\n",
      "Y9997     1.0           1  24\n",
      "Y9998     0.0          25  30\n",
      "          1.0           1  24\n",
      "Y9999     0.0          25  30\n",
      "          1.0           1  24\n",
      "\n",
      "[46000 rows x 2 columns]\n",
      "Total data \t\t\t858458 time stamps\n",
      "Available percentage=100.0, \t858458 time stamps\n",
      "Train percentage=83.92, \t720458.0 time stamps\n",
      "Outsample percentage=16.08, \t138000.0 time stamps\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m4_dataset = TimeSeriesDataset(Y_df=Y_df, mask_df=None, ts_in_test=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23000, 3, 841)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m4_dataset.ts_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = TimeSeriesLoader(ts_dataset=m4_dataset,\n",
    "                                model='nbeats',\n",
    "                                offset=0,\n",
    "                                window_sampling_limit=m4_dataset.max_len, \n",
    "                                input_size=int(5*6),\n",
    "                                output_size=int(6),\n",
    "                                idx_to_sample_freq=int(1),\n",
    "                                batch_size=int(1024),\n",
    "                                complete_inputs=False,\n",
    "                                complete_sample=False,\n",
    "                                shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 30\n",
    "output_size = 6\n",
    "\n",
    "# For shuffle bool testing purpose\n",
    "tensor,right_padding = m4_dataset.get_filtered_ts_tensor(offset=0, output_size=output_size,\n",
    "                                                         window_sampling_limit=m4_dataset.max_len,\n",
    "                                                         ts_idxs=np.array(range(23000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insample_y.shape torch.Size([30352, 30])\n",
      "outsample_y.shape torch.Size([30352, 6])\n",
      "tensor.shape (23000, 3, 841)\n"
     ]
    }
   ],
   "source": [
    "dataloader = iter(train_loader)\n",
    "batch = next(dataloader)\n",
    "insample_y = batch['insample_y']\n",
    "insample_x_t = batch['insample_x']\n",
    "insample_mask = batch['insample_mask']\n",
    "outsample_y = batch['outsample_y']\n",
    "outsample_x = batch['outsample_x']\n",
    "outsample_mask = batch['outsample_mask']\n",
    "\n",
    "print(\"insample_y.shape\", insample_y.shape)\n",
    "print(\"outsample_y.shape\", outsample_y.shape)\n",
    "print(\"tensor.shape\", tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0.0000,    0.0000,    0.0000,  ...,    0.0000,    0.0000,\n",
       "         5172.1001],\n",
       "        [   0.0000,    0.0000,    0.0000,  ...,    0.0000, 5172.1001,\n",
       "         5133.5000],\n",
       "        [   0.0000,    0.0000,    0.0000,  ..., 5172.1001, 5133.5000,\n",
       "         5186.8999],\n",
       "        ...,\n",
       "        [1870.0000, 2130.0000, 2030.0000,  ..., 4838.0000, 4901.0000,\n",
       "         4976.0000],\n",
       "        [2130.0000, 2030.0000, 2108.0000,  ..., 4901.0000, 4976.0000,\n",
       "         5080.0000],\n",
       "        [2030.0000, 2108.0000, 2265.0000,  ..., 4976.0000, 5080.0000,\n",
       "         5073.0000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5133.5000, 5186.8999, 5084.6001, 5182.0000, 5414.2998, 5576.2002],\n",
       "        [5186.8999, 5084.6001, 5182.0000, 5414.2998, 5576.2002, 5752.8999],\n",
       "        [5084.6001, 5182.0000, 5414.2998, 5576.2002, 5752.8999, 5955.2002],\n",
       "        ...,\n",
       "        [5080.0000, 5073.0000, 5116.0000, 4937.0000, 4994.0000, 4897.0000],\n",
       "        [5073.0000, 5116.0000, 4937.0000, 4994.0000, 4897.0000, 4916.0000],\n",
       "        [5116.0000, 4937.0000, 4994.0000, 4897.0000, 4916.0000, 4813.0000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outsample_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking order for unshuffled validation\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZMElEQVR4nO3df4xV553f8feHGYMBGwNmIHgGB5KOssWu4thTysZS2i7xQprdgLSyRKSs6daraS26TdKqK1ipjaoK1a1WqxSpRkJO1mNtNnTWmwiUXdJQslG3EjIeO85ijAmTYMOEMYwJvwczgL/94zzgk+HOzB3KuffMvZ+XdHXO/Z7z3Hvmkfnex9/z41FEYGZmzWFavQ/AzMxqx0nfzKyJOOmbmTURJ30zsybipG9m1kRa630AE1mwYEEsXbq03odhZjalvPrqq+9FRNvoeOmT/tKlS+nr66v3YZiZTSmS3qkUd3nHzKyJVJX0JX1V0kFJb0j6tqS7Jc2XtEfSkbScl9t/s6R+SYclrc7FH5N0IG3bKklF/FFmZlbZhElfUjvwb4CuiHgYaAHWA5uAvRHRCexN75G0PG1/CFgDPCepJX3cNqAb6EyvNXf0rzEzs3FVW95pBWZKagVmASeAtUBP2t4DrEvra4EdEXElIo4C/cAKSYuBORGxL7JnP7yYa2NmZjUwYdKPiF8AfwwcAwaBcxHxA2BRRAymfQaBhalJO3A89xEDKdae1kfHbyGpW1KfpL6hoaHJ/UVmZjamaso788hG78uAB4DZkr40XpMKsRgnfmswYntEdEVEV1vbLVccmZnZbaqmvPNZ4GhEDEXEVeA7wKeBk6lkQ1qeSvsPAEty7TvIykEDaX103MzMaqSapH8MWClpVrraZhVwCNgFbEj7bAB2pvVdwHpJMyQtIzthuz+VgC5IWpk+56lcGzMzS155+5ds3XuEyyPX7/hnV1PTfxl4CXgNOJDabAeeBZ6QdAR4Ir0nIg4CvcCbwPeBjRFx48ifAZ4nO7n7M2D3nfxjzMwawd/+dIiv/++f0tpy569qr+qO3Ij4GvC1UeErZKP+SvtvAbZUiPcBD0/yGM3MmsrAmcssvm8md7Xc+ftnfUeumVnJDJy5TPu8mYV8tpO+mVkJvH/1+s0a/vEzw3Q46ZuZNa7Pb/1bVv6XvYxc+4B3z7/PknmzCvme0j9l08ysGfxs6BIAR9+7RAQe6ZuZNapLV67dXP+fr2QPNPhY2z2FfJeTvplZnZ08//7N9Z59b9M6TTz0wJxCvstJ38yszk5fGrm5fv2DYPHcu7n7rpZxWtw+J30zszo7ffHKr7z/yJy7C/suJ30zszp772I20p81PRvdf+S+Yk7igpO+mVld/fCtk/zV3w3SOk03r9h54L7iRvq+ZNPMrE4ign/xQh8AH71/FsPp5qylC2YX9p0e6ZuZ1cn5yx9eqnlXyzQGzlwGsh+Aojjpm5nVycDZ4Zvrn/74/Xzu4Y8A8OiD8wr7Tpd3zMzq5O33sqT/r/7xx/nqE51EwLO/80Fhl2uCk76ZWd0cGjxPyzTxlc92MqM1S/RFJnxwecfMrG4ODZ7n422zC0/0edVMjP4JSa/nXuclfUXSfEl7JB1Jy3m5Npsl9Us6LGl1Lv6YpANp29Y0baKZWVM6NHieX/tIMY9bGEs10yUejohHIuIR4DFgGPgusAnYGxGdwN70HknLgfXAQ8Aa4DlJN37GtgHdZPPmdqbtZmZN5/2r1zlx7n3+3sJiHqw2lsmWd1YBP4uId4C1QE+K9wDr0vpaYEdEXImIo2Tz4a6QtBiYExH7IiKAF3NtzMyaytCF7NELi+bMqOn3Tjbprwe+ndYXRcQgQFouTPF24HiuzUCKtaf10fFbSOqW1Cepb2hoaJKHaGZWfqdS0l94b3F331ZSddKXNB34AvAXE+1aIRbjxG8NRmyPiK6I6Gpra6v2EM3MpoyhC9njlNvuLe9I/3PAaxFxMr0/mUo2pOWpFB8AluTadQAnUryjQtzMrOm8czq7Rr+oaRHHMpmk/0U+LO0A7AI2pPUNwM5cfL2kGZKWkZ2w3Z9KQBckrUxX7TyVa2Nm1lT6T11kwT0zuG/WXTX93qpuzpI0C3gC+Je58LNAr6SngWPAkwARcVBSL/AmcA3YGBHXU5tngBeAmcDu9DIzazq/OHu50GfsjKWqpB8Rw8D9o2Knya7mqbT/FmBLhXgf8PDkD9PMrLGcHb7KA3NrexIXfEeumVldnLt8lftmTq/59zrpm5nVwdnhEebWuJ4PTvpmZjU3cu0DLo1cZ+5MJ30zs4Z37vJVAI/0zcyawbnL2UTo981yTd/MrOGdHU4jfZd3zMwa382k7/KOmVnjO3ujpu9LNs3MGt+p9LC1ebM90jcza3gHBs7x4PxZ3Hu3k76ZWUM7df59dr/xLv+g/b66fL+TvplZDT31zf0AzJ9d+3o+OOmbmdXUW+9eAGo/TeINVT1l08zM7oz7Z09n2jTR/ZmP1+X7PdI3M6uR6x8Evxwe4Yv/cAnTW+uTfp30zcxq5MzwCBFw/z31Ke1AlUlf0lxJL0l6S9IhSb8uab6kPZKOpOW83P6bJfVLOixpdS7+mKQDadvWNG2imVlTOH0xe+bOgrInfeC/A9+PiF8DPgkcAjYBeyOiE9ib3iNpObAeeAhYAzwnqSV9zjagm2ze3M603cysKbx38QoA999Tnyt3oIqkL2kO8BngGwARMRIRZ4G1QE/arQdYl9bXAjsi4kpEHAX6gRWSFgNzImJfRATwYq6NmVnDu5H0F5Q56QMfA4aAP5X0Y0nPS5oNLIqIQYC0XJj2bweO59oPpFh7Wh8dv4Wkbkl9kvqGhoYm9QeZmZXVjfLO/bPLXd5pBR4FtkXEp4BLpFLOGCrV6WOc+K3BiO0R0RURXW1tbVUcoplZ+Z2+dIWWaeK+OjxS+YZqkv4AMBARL6f3L5H9CJxMJRvS8lRu/yW59h3AiRTvqBA3M2sKpy+OMD9dp18vEyb9iHgXOC7pEym0CngT2AVsSLENwM60vgtYL2mGpGVkJ2z3pxLQBUkr01U7T+XamJk1vPcujtT1yh2o/o7cPwC+JWk68HPg98h+MHolPQ0cA54EiIiDknrJfhiuARsj4nr6nGeAF4CZwO70MjNrCqcvXanrSVyoMulHxOtAV4VNq8bYfwuwpUK8D3h4EsdnZtYw3rt4hY/On1XXY/AduWZmNXL64khd78YFJ30zs5oYHrnG8Mj1ut6YBU76ZmY1cfMRDHW8Rh+c9M3MauL0pXRjlkf6ZmaN7/TNRzB4pG9m1vBujPTrNU3iDU76ZmY1cG74KgBzZ9XvEQzgpG9mVhNnhkdonSbumVHfWWqd9M3MauDM8FXmzrqLes8d5aRvZlYD5y6PMHdWfev54KRvZlYTZy5dZW4dH6l8g5O+mVkNnBn2SN/MrGmcu3y17lfugJO+mVlNnBkeYZ6TvplZY/vF2cs8+p/38P7VD1zeMTNrdP/+L37CL9PduIvm3F3no6ky6Ut6W9IBSa9L6kux+ZL2SDqSlvNy+2+W1C/psKTVufhj6XP6JW1VvS9YNTMrWMe8mTfXly2YXccjyUxmpP9PI+KRiLgxg9YmYG9EdAJ703skLQfWAw8Ba4DnJLWkNtuAbrJ5czvTdjOzhtV274cPWJtqSX+0tUBPWu8B1uXiOyLiSkQcBfqBFZIWA3MiYl9EBPBiro2ZWUOKgGmC1/7DE3V/2BpUn/QD+IGkVyV1p9iiiBgESMuFKd4OHM+1HUix9rQ+Om5m1rACaJmmUiR8qHJidODxiDghaSGwR9Jb4+xbqU4f48Rv/YDsh6Ub4MEHH6zyEM3MyicCVDH91UdVI/2IOJGWp4DvAiuAk6lkQ1qeSrsPAEtyzTuAEyneUSFe6fu2R0RXRHS1tbVV/9eYmZVReXL+xElf0mxJ995YB34TeAPYBWxIu20Adqb1XcB6STMkLSM7Ybs/lYAuSFqZrtp5KtfGzKwhReWCRt1UU95ZBHw3XV3ZCvx5RHxf0itAr6SngWPAkwARcVBSL/AmcA3YGBHX02c9A7wAzAR2p5eZWeOKUg30J076EfFz4JMV4qeBVWO02QJsqRDvAx6e/GGamU1dZbojyXfkmpkVqFzFHSd9M7NCRcTUu3rHzMxuT4TLO2ZmTaVEOd9J38ysSK7pm5k1kay8U56xvpO+mVnBypPynfTNzApVtjtynfTNzAoUYz1usk6c9M3MClainO+kb2ZWNJ/INTNrEtlEgeXhpG9mVqDAd+SamTWVEuV8J30zsyKVrLrjpG9mVqQgfCLXzKyZlCflTyLpS2qR9GNJ30vv50vaI+lIWs7L7btZUr+kw5JW5+KPSTqQtm1VmX7+zMwKMJUfrfxl4FDu/SZgb0R0AnvTeyQtB9YDDwFrgOcktaQ224BussnSO9N2M7OGVbKSfnVJX1IH8Hng+Vx4LdCT1nuAdbn4joi4EhFHgX5ghaTFwJyI2BfZhasv5tqYmTWk7ERueYb61Y70vw78IfBBLrYoIgYB0nJhircDx3P7DaRYe1ofHb+FpG5JfZL6hoaGqjxEM7NymlLlHUm/BZyKiFer/MxKf95Yjxyq+H8+EbE9Iroioqutra3KrzUzK6NyFXhaq9jnceALkv4ZcDcwR9KfASclLY6IwVS6OZX2HwCW5Np3ACdSvKNC3MysYUWUqbhTxUg/IjZHREdELCU7QfvDiPgSsAvYkHbbAOxM67uA9ZJmSFpGdsJ2fyoBXZC0Ml2181SujZlZwypTeaeakf5YngV6JT0NHAOeBIiIg5J6gTeBa8DGiLie2jwDvADMBHanl5lZw8pG+uXJ+pNK+hHxI+BHaf00sGqM/bYAWyrE+4CHJ3uQZmZTlWfOMjNrIlP55iwzM7sNJcr5TvpmZkUqV3HHSd/MrFBZeac8Y30nfTOzJuKkb2ZWoOx5+vU+ig856ZuZFalkRX0nfTOzgnmkb2bWJLKnTZYn6zvpm5kVKEo2M7qTvplZgQKXd8zMmkqJcr6TvplZkUpW3XHSNzMrUlbeKc9Y30nfzKxg5Un5TvpmZoWKks2XWM3E6HdL2i/pJ5IOSvpPKT5f0h5JR9JyXq7NZkn9kg5LWp2LPybpQNq2VWX6fx4zswKUrKRf1Uj/CvAbEfFJ4BFgjaSVwCZgb0R0AnvTeyQtJ5tL9yFgDfCcpJb0WduAbrJ5czvTdjOzxlWugX5VE6NHRFxMb+9KrwDWAj0p3gOsS+trgR0RcSUijgL9wApJi4E5EbEvsrsVXsy1MTNrWGUqalRV05fUIul14BSwJyJeBhZFxCBAWi5Mu7cDx3PNB1KsPa2Pjlf6vm5JfZL6hoaGJvHnmJmVy5ScIzcirkfEI0AH2ah9vMnNK/2kxTjxSt+3PSK6IqKrra2tmkM0Myulkp3HndzVOxFxFvgRWS3+ZCrZkJan0m4DwJJcsw7gRIp3VIibmTW0ElV3qrp6p03S3LQ+E/gs8BawC9iQdtsA7Ezru4D1kmZIWkZ2wnZ/KgFdkLQyXbXzVK6NmVlDykb65cn6rVXssxjoSVfgTAN6I+J7kvYBvZKeBo4BTwJExEFJvcCbwDVgY0RcT5/1DPACMBPYnV5mZg2rbDX9CZN+RPwd8KkK8dPAqjHabAG2VIj3AeOdDzAzayjZxOj1PooP+Y5cM7Mm4qRvZlagchV3nPTNzAqVlXfKU99x0jczK1h5Ur6TvplZwcIncs3MmoVnzjIzazIe6ZuZNYnswWPlyfpO+mZmBYqS1Xec9M3MCpRNjF7vo/iQk76ZWcFKlPOd9M3MihQlG+o76ZuZFahcFX0nfTOzwpVnnO+kb2ZWqAjfkWtmZnVSzXSJSyT9jaRDkg5K+nKKz5e0R9KRtJyXa7NZUr+kw5JW5+KPSTqQtm1VmR49Z2ZWgKk4Mfo14N9FxN8HVgIbJS0HNgF7I6IT2Jvek7atBx4im0D9uTTVIsA2oJts3tzOtN3MrKGVaXw7YdKPiMGIeC2tXwAOAe3AWqAn7dYDrEvra4EdEXElIo4C/cAKSYuBORGxL7Jb1F7MtTEza0hBTLmR/k2SlpLNl/sysCgiBiH7YQAWpt3ageO5ZgMp1p7WR8crfU+3pD5JfUNDQ5M5RDOzUinZUxiqT/qS7gH+EvhKRJwfb9cKsRgnfmswYntEdEVEV1tbW7WHaGZWSiWq7lSX9CXdRZbwvxUR30nhk6lkQ1qeSvEBYEmueQdwIsU7KsTNzBpWdiK3PFm/mqt3BHwDOBQRf5LbtAvYkNY3ADtz8fWSZkhaRnbCdn8qAV2QtDJ95lO5NmZmDSlKdk9uaxX7PA78LnBA0usp9kfAs0CvpKeBY8CTABFxUFIv8CbZlT8bI+J6avcM8AIwE9idXmZmDSvGKm7XyYRJPyL+L2Mf8qox2mwBtlSI9wEPT+YAzcymuhLlfN+Ra2ZWpJI9ZNNJ38ysUOUq6Tvpm5kVbUpdvWNmZrcv8FM2zcyaxpS9I9fMzG6PR/pmZk0iu0y/PFnfSd/MrECeOcvMrImUrKTvpG9m1kyc9M3MChQxxWbOMjOz2+fyjplZkynPON9J38ysWL56x8ysebi8Y2bWRLLpEsujmukSvynplKQ3crH5kvZIOpKW83LbNkvql3RY0upc/DFJB9K2rSrT6WwzswKVKd1VM9J/AVgzKrYJ2BsRncDe9B5Jy4H1wEOpzXOSWlKbbUA32Zy5nRU+08ys4QQxtUb6EfF/gF+OCq8FetJ6D7AuF98REVci4ijQD6yQtBiYExH7IiKAF3NtzMwaVqM8ZXNRRAwCpOXCFG8Hjuf2G0ix9rQ+Om5m1vBKVN254ydyK/1pY80FP+bvn6RuSX2S+oaGhu7YwZmZ1Vo20i9P1r/dpH8ylWxIy1MpPgAsye3XAZxI8Y4K8YoiYntEdEVEV1tb220eoplZ/ZWsunPbSX8XsCGtbwB25uLrJc2QtIzshO3+VAK6IGllumrnqVwbM7OGVbZHK7dOtIOkbwP/BFggaQD4GvAs0CvpaeAY8CRARByU1Au8CVwDNkbE9fRRz5BdCTQT2J1eZmYNr0Q5f+KkHxFfHGPTqjH23wJsqRDvAx6e1NGZmTWAMo30fUeumVmBGuWSTTMzq5LnyDUzaxJBuU7kOumbmRXI5R0zsybjkb6ZWZPIHklQnqzvpG9mVqAo2QP1nfTNzApUspK+k76ZWdFKNNB30jczK1RMvZmzzMzsNrm8Y2bWZMozznfSNzMrVNkereykb2ZWoLGmDqwXJ30zswL5MQxmZk3GV++YmTWJIJq7vCNpjaTDkvolbar195uZ1VJTl3cktQD/A/gcsBz4oqTltTwGM7OaK9FQf8I5cu+wFUB/RPwcQNIOYC3ZROp31O/3vMI7p4fv9MeamU3Ku+feL9VTNmud9NuB47n3A8A/Gr2TpG6gG+DBBx+8rS96cP5sprf6lIWZ1Vfnonv4nUfb630YN9U66Vf6ubul4hUR24HtAF1dXbdVEfuPv+2qkZnZaLUeCg8AS3LvO4ATNT4GM7OmVeuk/wrQKWmZpOnAemBXjY/BzKxp1bS8ExHXJP1r4H8BLcA3I+JgLY/BzKyZ1bqmT0T8NfDXtf5eMzPzHblmZk3FSd/MrIk46ZuZNREnfTOzJqIo29OARpE0BLxzm80XAO/dwcNpNO6fibmPxuf+mVi9+uijEdE2Olj6pP//Q1JfRHTV+zjKyv0zMffR+Nw/EytbH7m8Y2bWRJz0zcyaSKMn/e31PoCSc/9MzH00PvfPxErVRw1d0zczs1/V6CN9MzPLcdI3M2siDZn0Pfl6RtISSX8j6ZCkg5K+nOLzJe2RdCQt5+XabE79dljS6vodfe1IapH0Y0nfS+/dPzmS5kp6SdJb6b+lX3cffUjSV9O/rzckfVvS3aXun4hoqBfZI5t/BnwMmA78BFhe7+OqU18sBh5N6/cCPyWbkP6/AZtSfBPwX9P68tRfM4BlqR9b6v131KCf/i3w58D30nv3z6/2Tw/w+2l9OjDXfXSzb9qBo8DM9L4X+Odl7p9GHOnfnHw9IkaAG5OvN52IGIyI19L6BeAQ2X+ka8n+IZOW69L6WmBHRFyJiKNAP1l/NixJHcDngedzYfdPImkO8BngGwARMRIRZ3Ef5bUCMyW1ArPIZgMsbf80YtKvNPl6eWYlrhNJS4FPAS8DiyJiELIfBmBh2q0Z++7rwB8CH+Ri7p8PfQwYAv40lcCelzQb9xEAEfEL4I+BY8AgcC4ifkCJ+6cRk35Vk683E0n3AH8JfCUizo+3a4VYw/adpN8CTkXEq9U2qRBr2P5JWoFHgW0R8SngElm5YixN1UepVr+WrFTzADBb0pfGa1IhVtP+acSk78nXcyTdRZbwvxUR30nhk5IWp+2LgVMp3mx99zjwBUlvk5UBf0PSn+H+yRsABiLi5fT+JbIfAfdR5rPA0YgYioirwHeAT1Pi/mnEpO/J1xNJIqvFHoqIP8lt2gVsSOsbgJ25+HpJMyQtAzqB/bU63lqLiM0R0RERS8n+O/lhRHwJ989NEfEucFzSJ1JoFfAm7qMbjgErJc1K/95WkZ07K23/1HyO3KKFJ1/Pexz4XeCApNdT7I+AZ4FeSU+T/Uf7JEBEHJTUS/aP+hqwMSKu1/yo68/986v+APhWGkT9HPg9sgFj0/dRRLws6SXgNbK/98dkj124h5L2jx/DYGbWRBqxvGNmZmNw0jczayJO+mZmTcRJ38ysiTjpm5k1ESd9M7Mm4qRvZtZE/h+wRN7BlZTsRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loader.shuffle = False\n",
    "dataloader = iter(train_loader)\n",
    "batch = next(dataloader)\n",
    "insample_y = batch['insample_y']\n",
    "\n",
    "print(\"Checking order for unshuffled validation\")\n",
    "plt.plot(insample_y[0,:])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(tensor[0,0,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOY EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "n_weeks = 2\n",
    "\n",
    "Y = np.concatenate([np.array(range(168*2)), 10*np.array(range(168*2))])\n",
    "X1 = -np.concatenate([np.array(range(168*2)), 10*np.array(range(168*2))])\n",
    "X2 = 1/(np.concatenate([np.array(range(168*2)), 10*np.array(range(168*2))])+1)\n",
    "\n",
    "unique_id = np.array(['u1']*168*2 + ['u2']*168*2)\n",
    "ds = pd.date_range(start='1/1/2018', end='1/15/2018', freq='H')[:-1].to_list() + \\\n",
    "     pd.date_range(start='1/1/2018', end='1/15/2018', freq='H')[:-1].to_list()\n",
    "\n",
    "X_df = pd.DataFrame({'unique_id': unique_id, 'ds': ds, 'X1': X1, 'X2': X2})\n",
    "Y_df = pd.DataFrame({'unique_id': unique_id, 'ds': ds, 'y': Y})\n",
    "S_df = Y_df.drop_duplicates('unique_id')[['unique_id']].reset_index(drop=True)\n",
    "S_df['s_0'] = [1,0]\n",
    "S_df['s_1'] = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u1</td>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u1</td>\n",
       "      <td>2018-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u1</td>\n",
       "      <td>2018-01-01 02:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u1</td>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u1</td>\n",
       "      <td>2018-01-01 04:00:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>u2</td>\n",
       "      <td>2018-01-14 19:00:00</td>\n",
       "      <td>3310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>u2</td>\n",
       "      <td>2018-01-14 20:00:00</td>\n",
       "      <td>3320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>u2</td>\n",
       "      <td>2018-01-14 21:00:00</td>\n",
       "      <td>3330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>u2</td>\n",
       "      <td>2018-01-14 22:00:00</td>\n",
       "      <td>3340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>u2</td>\n",
       "      <td>2018-01-14 23:00:00</td>\n",
       "      <td>3350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    unique_id                  ds     y\n",
       "0          u1 2018-01-01 00:00:00     0\n",
       "1          u1 2018-01-01 01:00:00     1\n",
       "2          u1 2018-01-01 02:00:00     2\n",
       "3          u1 2018-01-01 03:00:00     3\n",
       "4          u1 2018-01-01 04:00:00     4\n",
       "..        ...                 ...   ...\n",
       "667        u2 2018-01-14 19:00:00  3310\n",
       "668        u2 2018-01-14 20:00:00  3320\n",
       "669        u2 2018-01-14 21:00:00  3330\n",
       "670        u2 2018-01-14 22:00:00  3340\n",
       "671        u2 2018-01-14 23:00:00  3350\n",
       "\n",
       "[672 rows x 3 columns]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Validation splits\n",
      "                                       ds                    \n",
      "                                      min                 max\n",
      "unique_id sample_mask                                        \n",
      "u1        0.0         2018-01-14 19:00:00 2018-01-14 23:00:00\n",
      "          1.0         2018-01-01 00:00:00 2018-01-14 18:00:00\n",
      "u2        0.0         2018-01-14 19:00:00 2018-01-14 23:00:00\n",
      "          1.0         2018-01-01 00:00:00 2018-01-14 18:00:00\n",
      "Total data \t\t\t672 time stamps\n",
      "Available percentage=100.0, \t672 time stamps\n",
      "Train percentage=98.51, \t662.0 time stamps\n",
      "Outsample percentage=1.49, \t10.0 time stamps\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toy_dataset = TimeSeriesDataset(Y_df=Y_df, X_df=X_df, S_df=S_df, mask_df=None, ts_in_test=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_loader = TimeSeriesLoader(ts_dataset=toy_dataset,\n",
    "                             model='nbeats',\n",
    "                             offset=0,\n",
    "                             window_sampling_limit=toy_dataset.max_len,\n",
    "                             input_size=5,\n",
    "                             output_size=5,\n",
    "                             idx_to_sample_freq=24,\n",
    "                             batch_size=256,\n",
    "                             complete_inputs=False,\n",
    "                             complete_sample=False,\n",
    "                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m4_dataset.t_cols ['y', 'available_mask', 'sample_mask']\n",
      "ts_loader.input_size 5\n",
      "ts_loader.output_size 5\n",
      "insample_y.shape torch.Size([26, 5])\n",
      "outsample_y.shape torch.Size([26, 5])\n",
      "s_matrix.shape (26, 2)\n"
     ]
    }
   ],
   "source": [
    "dataloader = iter(ts_loader)\n",
    "batch = next(dataloader)\n",
    "insample_y = batch['insample_y']\n",
    "insample_x_t = batch['insample_x']\n",
    "insample_mask = batch['insample_mask']\n",
    "outsample_y = batch['outsample_y']\n",
    "outsample_x = batch['outsample_x']\n",
    "outsample_mask = batch['outsample_mask']\n",
    "s_matrix = batch['s_matrix']\n",
    "\n",
    "print(\"m4_dataset.t_cols\", m4_dataset.t_cols)\n",
    "print(\"ts_loader.input_size\", ts_loader.input_size)\n",
    "print(\"ts_loader.output_size\", ts_loader.output_size)\n",
    "print(\"insample_y.shape\", insample_y.shape)\n",
    "print(\"outsample_y.shape\", outsample_y.shape)\n",
    "print(\"s_matrix.shape\", s_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  19.,   20.,   21.,   22.,   23.],\n",
       "        [  43.,   44.,   45.,   46.,   47.],\n",
       "        [  67.,   68.,   69.,   70.,   71.],\n",
       "        [  91.,   92.,   93.,   94.,   95.],\n",
       "        [ 115.,  116.,  117.,  118.,  119.],\n",
       "        [ 139.,  140.,  141.,  142.,  143.],\n",
       "        [ 163.,  164.,  165.,  166.,  167.],\n",
       "        [ 187.,  188.,  189.,  190.,  191.],\n",
       "        [ 211.,  212.,  213.,  214.,  215.],\n",
       "        [ 235.,  236.,  237.,  238.,  239.],\n",
       "        [ 259.,  260.,  261.,  262.,  263.],\n",
       "        [ 283.,  284.,  285.,  286.,  287.],\n",
       "        [ 307.,  308.,  309.,  310.,  311.],\n",
       "        [ 190.,  200.,  210.,  220.,  230.],\n",
       "        [ 430.,  440.,  450.,  460.,  470.],\n",
       "        [ 670.,  680.,  690.,  700.,  710.],\n",
       "        [ 910.,  920.,  930.,  940.,  950.],\n",
       "        [1150., 1160., 1170., 1180., 1190.],\n",
       "        [1390., 1400., 1410., 1420., 1430.],\n",
       "        [1630., 1640., 1650., 1660., 1670.],\n",
       "        [1870., 1880., 1890., 1900., 1910.],\n",
       "        [2110., 2120., 2130., 2140., 2150.],\n",
       "        [2350., 2360., 2370., 2380., 2390.],\n",
       "        [2590., 2600., 2610., 2620., 2630.],\n",
       "        [2830., 2840., 2850., 2860., 2870.],\n",
       "        [3070., 3080., 3090., 3100., 3110.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insample_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  24.,   25.,   26.,   27.,   28.],\n",
       "        [  48.,   49.,   50.,   51.,   52.],\n",
       "        [  72.,   73.,   74.,   75.,   76.],\n",
       "        [  96.,   97.,   98.,   99.,  100.],\n",
       "        [ 120.,  121.,  122.,  123.,  124.],\n",
       "        [ 144.,  145.,  146.,  147.,  148.],\n",
       "        [ 168.,  169.,  170.,  171.,  172.],\n",
       "        [ 192.,  193.,  194.,  195.,  196.],\n",
       "        [ 216.,  217.,  218.,  219.,  220.],\n",
       "        [ 240.,  241.,  242.,  243.,  244.],\n",
       "        [ 264.,  265.,  266.,  267.,  268.],\n",
       "        [ 288.,  289.,  290.,  291.,  292.],\n",
       "        [ 312.,  313.,  314.,  315.,  316.],\n",
       "        [ 240.,  250.,  260.,  270.,  280.],\n",
       "        [ 480.,  490.,  500.,  510.,  520.],\n",
       "        [ 720.,  730.,  740.,  750.,  760.],\n",
       "        [ 960.,  970.,  980.,  990., 1000.],\n",
       "        [1200., 1210., 1220., 1230., 1240.],\n",
       "        [1440., 1450., 1460., 1470., 1480.],\n",
       "        [1680., 1690., 1700., 1710., 1720.],\n",
       "        [1920., 1930., 1940., 1950., 1960.],\n",
       "        [2160., 2170., 2180., 2190., 2200.],\n",
       "        [2400., 2410., 2420., 2430., 2440.],\n",
       "        [2640., 2650., 2660., 2670., 2680.],\n",
       "        [2880., 2890., 2900., 2910., 2920.],\n",
       "        [3120., 3130., 3140., 3150., 3160.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outsample_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
