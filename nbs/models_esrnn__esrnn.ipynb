{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.esrnn.esrnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESRNN model\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TODO: validation loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "from nixtla.models.esrnn.esrnn_model import _ESRNN\n",
    "from nixtla.losses.pytorch import MAPELoss, MASELoss, SMAPELoss, MSELoss, MAELoss, SmylLoss, PinballLoss\n",
    "from nixtla.losses.numpy import mae, mse, mape, smape, rmse, pinball_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#TODO: eval_mode=False\n",
    "#TODO: cambiar por similar a Nbeats\n",
    "#TODO: hacer que todo el modelo opere con mascaras: loss, forward, loader. deshackear sample mask, filtro de forward\n",
    "class ESRNN(object):\n",
    "    \"\"\" Exponential Smoothing Recurrent Neural Network\n",
    "\n",
    "    Pytorch Implementation of the M4 time series forecasting competition winner.\n",
    "    Proposed by Smyl. The model uses a hybrid approach of Machine Learning and\n",
    "    statistical methods by combining recurrent neural networks to model a common\n",
    "    trend with shared parameters across series, and multiplicative Holt-Winter\n",
    "    exponential smoothing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_epochs: int\n",
    "        maximum number of complete passes to train data during fit\n",
    "    learning_rate: float\n",
    "        size of the stochastic gradient descent steps\n",
    "    lr_scheduler_step_size: int\n",
    "        this step_size is the period for each learning rate decay\n",
    "    per_series_lr_multip: float\n",
    "        multiplier for per-series parameters smoothing and initial\n",
    "        seasonalities learning rate (default 1.0)\n",
    "    gradient_eps: float\n",
    "        term added to the Adam optimizer denominator to improve\n",
    "        numerical stability (default: 1e-8)\n",
    "    gradient_clipping_threshold: float\n",
    "        max norm of gradient vector, with all parameters treated\n",
    "        as a single vector\n",
    "    rnn_weight_decay: float\n",
    "        parameter to control classic L2/Tikhonov regularization\n",
    "        of the rnn parameters\n",
    "    noise_std: float\n",
    "        standard deviation of white noise added to input during\n",
    "        fit to avoid the model from memorizing the train data\n",
    "    level_variability_penalty: float\n",
    "        this parameter controls the strength of the penalization\n",
    "        to the wigglines of the level vector, induces smoothness\n",
    "        in the output\n",
    "    testing_percentile: float\n",
    "        This value is only for diagnostic evaluation.\n",
    "        In case of percentile predictions this parameter controls\n",
    "        for the value predicted, when forecasting point value,\n",
    "        the forecast is the median, so percentile=50.\n",
    "    training_percentile: float\n",
    "        To reduce the model's tendency to over estimate, the\n",
    "        training_percentile can be set to fit a smaller value\n",
    "        through the Pinball Loss.\n",
    "    seasonality: int list\n",
    "        list of seasonalities of the time series\n",
    "        Hourly [24, 168], Daily [7], Weekly [52], Monthly [12],\n",
    "        Quarterly [4], Yearly [].\n",
    "    input_size: int\n",
    "        input size of the recurrent neural network, usually a\n",
    "        multiple of seasonality\n",
    "    output_size: int\n",
    "        output_size or forecast horizon of the recurrent neural\n",
    "        network, usually multiple of seasonality\n",
    "    random_seed: int\n",
    "        random_seed for pseudo random pytorch initializer and\n",
    "        numpy random generator\n",
    "    min_inp_seq_length: int\n",
    "        description\n",
    "    cell_type: str\n",
    "        Type of RNN cell, available GRU, LSTM, RNN, ResidualLSTM.\n",
    "    state_hsize: int\n",
    "        dimension of hidden state of the recurrent neural network\n",
    "    dilations: int list\n",
    "        each list represents one chunk of Dilated LSTMS, connected in\n",
    "        standard ResNet fashion\n",
    "    add_nl_layer: bool\n",
    "        whether to insert a tanh() layer between the RNN stack and the\n",
    "        linear adaptor (output) layers\n",
    "    device: str\n",
    "        pytorch device either 'cpu' or 'cuda'\n",
    "    Notes\n",
    "    -----\n",
    "    **References:**\n",
    "    `M4 Competition Conclusions\n",
    "    <https://rpubs.com/fotpetr/m4competition>`__\n",
    "    `Original Dynet Implementation of ESRNN\n",
    "    <https://github.com/M4Competition/M4-methods/tree/master/118%20-%20slaweks17>`__\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 output_size,\n",
    "                 es_component,\n",
    "                 cell_type,\n",
    "                 state_hsize,\n",
    "                 dilations,\n",
    "                 add_nl_layer,\n",
    "                 seasonality,\n",
    "                 learning_rate,\n",
    "                 lr_scheduler_step_size,\n",
    "                 lr_decay,\n",
    "                 per_series_lr_multip,\n",
    "                 gradient_eps,\n",
    "                 gradient_clipping_threshold,\n",
    "                 rnn_weight_decay,\n",
    "                 n_iterations,\n",
    "                 early_stopping,\n",
    "                 noise_std,\n",
    "                 level_variability_penalty,\n",
    "                 testing_percentile,\n",
    "                 training_percentile,\n",
    "                 loss,\n",
    "                 val_loss,\n",
    "                 random_seed,\n",
    "                 device=None,\n",
    "                 root_dir='./'):\n",
    "        super(ESRNN, self).__init__()\n",
    "        \n",
    "        #------------------------ Model Attributes ------------------------#\n",
    "        # Architecture parameters\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.es_component = es_component\n",
    "        self.cell_type = cell_type\n",
    "        self.state_hsize = state_hsize\n",
    "        self.dilations = dilations\n",
    "        self.add_nl_layer = add_nl_layer\n",
    "        self.seasonality = seasonality\n",
    "\n",
    "        # Regularization and optimization parameters\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lr_scheduler_step_size = lr_scheduler_step_size\n",
    "        self.lr_decay = lr_decay\n",
    "        self.per_series_lr_multip = per_series_lr_multip\n",
    "        self.gradient_eps = gradient_eps\n",
    "        self.gradient_clipping_threshold = gradient_clipping_threshold\n",
    "        self.rnn_weight_decay = rnn_weight_decay\n",
    "        self.noise_std = noise_std\n",
    "        self.level_variability_penalty = level_variability_penalty\n",
    "        self.testing_percentile = testing_percentile\n",
    "        self.training_percentile = training_percentile\n",
    "        self.loss = loss\n",
    "        self.val_loss = val_loss\n",
    "        self.n_iterations = n_iterations\n",
    "        self.early_stopping = early_stopping        \n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        if device is None:\n",
    "            device = 'cuda' if t.cuda.is_available() else 'cpu'\n",
    "        self.device = device\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self._fitted = False\n",
    "\n",
    "    def to_tensor(self, x: np.ndarray, dtype = t.float32) -> t.Tensor:\n",
    "        tensor = t.as_tensor(x, dtype=dtype).to(self.device)\n",
    "        return tensor\n",
    "\n",
    "    def __loss_fn(self, loss_name: str):\n",
    "        #TODO: replace with kwargs\n",
    "        def loss(x, forecast, target, mask, levels):\n",
    "            if loss_name == 'SMYL':\n",
    "                return SmylLoss(y=target, y_hat=forecast, levels=levels, mask=mask,\n",
    "                                tau=(self.training_percentile / 100),\n",
    "                                level_variability_penalty=self.level_variability_penalty)\n",
    "            elif loss_name == 'MAPE':\n",
    "                return MAPELoss(y=target, y_hat=forecast, mask=mask)\n",
    "            elif loss_name == 'MASE':\n",
    "                return MASELoss(y=target, y_hat=forecast, y_insample=x, seasonality=loss_hypar, mask=mask)\n",
    "            elif loss_name == 'SMAPE':\n",
    "                return SMAPELoss(y=target, y_hat=forecast, mask=mask)\n",
    "            elif loss_name == 'MSE':\n",
    "                return MSELoss(y=target, y_hat=forecast, mask=mask)\n",
    "            elif loss_name == 'MAE':\n",
    "                return MAELoss(y=target, y_hat=forecast, mask=mask)\n",
    "            elif loss_name == 'PINBALL':\n",
    "                return PinballLoss(y=target, y_hat=forecast, mask=mask, \n",
    "                                   tau=(self.training_percentile/100))\n",
    "            else:\n",
    "                raise Exception(f'Unknown loss function: {loss_name}')\n",
    "        return loss\n",
    "    \n",
    "    def __val_loss_fn(self, loss_name='MAE'):\n",
    "        def loss(forecast, target, weights):\n",
    "            if loss_name == 'MAPE':\n",
    "                return mape(y=target, y_hat=forecast, weights=weights)\n",
    "            elif loss_name == 'SMAPE':\n",
    "                return smape(y=target, y_hat=forecast, weights=weights)\n",
    "            elif loss_name == 'MSE':\n",
    "                return mse(y=target, y_hat=forecast, weights=weights)\n",
    "            elif loss_name == 'RMSE':\n",
    "                return rmse(y=target, y_hat=forecast, weights=weights)\n",
    "            elif loss_name == 'MAE':\n",
    "                return mae(y=target, y_hat=forecast, weights=weights)\n",
    "            elif loss_name == 'PINBALL':\n",
    "                return pinball_loss(y=target, y_hat=forecast, weights=weights, \n",
    "                                    tau=(self.testing_percentile/100))\n",
    "            else:\n",
    "                raise Exception(f'Unknown loss function: {loss_name}')\n",
    "\n",
    "        return loss\n",
    "            \n",
    "\n",
    "    def fit(self, train_ts_loader, val_ts_loader=None, n_iterations=None, verbose=True, eval_freq=1):\n",
    "        \"\"\"\n",
    "        Fit ESRNN model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self.\n",
    "        \"\"\"\n",
    "\n",
    "        # Random Seeds (model initialization)\n",
    "        t.manual_seed(self.random_seed)\n",
    "        np.random.seed(self.random_seed)\n",
    "        random.seed(self.random_seed) #TODO: interaccion rara con window_sampling de validacion\n",
    "\n",
    "        # Exogenous variables\n",
    "        self.n_x_t, self.n_x_s = train_ts_loader.get_n_variables()\n",
    "        self.frequency = train_ts_loader.get_frequency()\n",
    "        \n",
    "        #if verbose: print(\"Infered frequency: {}\".format(self.frequency))\n",
    "\n",
    "        # Initialize model\n",
    "        self.n_series = train_ts_loader.get_n_series()\n",
    "        self.model = _ESRNN(n_series=self.n_series, input_size=self.input_size,\n",
    "                            output_size=self.output_size, n_t=self.n_x_t, n_s=self.n_x_s,\n",
    "                            es_component=self.es_component, seasonality=self.seasonality,\n",
    "                            noise_std=self.noise_std, cell_type=self.cell_type,\n",
    "                            dilations=self.dilations, state_hsize=self.state_hsize,\n",
    "                            add_nl_layer=self.add_nl_layer, device=self.device).to(self.device)\n",
    "\n",
    "        # Train model\n",
    "        self._fitted = True\n",
    "\n",
    "        # Optimizers\n",
    "        self.es_optimizer = optim.Adam(params=self.model.es.parameters(),\n",
    "                                        lr=self.learning_rate*self.per_series_lr_multip,\n",
    "                                        betas=(0.9, 0.999), eps=self.gradient_eps)\n",
    "\n",
    "        self.es_scheduler = StepLR(optimizer=self.es_optimizer,\n",
    "                                    step_size=self.lr_scheduler_step_size,\n",
    "                                    gamma=0.9)\n",
    "\n",
    "        self.rnn_optimizer = optim.Adam(params=self.model.rnn.parameters(),\n",
    "                                        lr=self.learning_rate,\n",
    "                                        betas=(0.9, 0.999), eps=self.gradient_eps,\n",
    "                                        weight_decay=self.rnn_weight_decay)\n",
    "\n",
    "        self.rnn_scheduler = StepLR(optimizer=self.rnn_optimizer,\n",
    "                                    step_size=self.lr_scheduler_step_size,\n",
    "                                    gamma=self.lr_decay)\n",
    "\n",
    "        # Loss Functions\n",
    "        training_loss_fn = self.__loss_fn(self.loss)\n",
    "        validation_loss_fn = self.__val_loss_fn(self.val_loss) #Uses numpy losses\n",
    "                \n",
    "        if verbose:\n",
    "            print('\\n')\n",
    "            print('='*30+' Start fitting '+'='*30)\n",
    "\n",
    "        # Overwrite n_iterations and train datasets\n",
    "        if n_iterations is None:\n",
    "            n_iterations = self.n_iterations\n",
    "\n",
    "        start = time.time()\n",
    "        self.trajectories = {'iteration':[], 'train_loss':[], 'val_loss':[]}\n",
    "\n",
    "        # Training Loop\n",
    "        early_stopping_counter = 0\n",
    "        best_val_loss = np.inf\n",
    "        best_state_dict = deepcopy(self.model.state_dict())\n",
    "        break_flag = False\n",
    "        iteration = 0\n",
    "        epoch = 0\n",
    "        while (iteration < n_iterations) and (not break_flag):\n",
    "            epoch +=1\n",
    "            for batch in iter(train_ts_loader):\n",
    "                iteration += 1\n",
    "                if (iteration > n_iterations) or (break_flag):\n",
    "                    continue\n",
    "                \n",
    "                self.model.train()\n",
    "                self.es_optimizer.zero_grad()\n",
    "                self.rnn_optimizer.zero_grad()\n",
    "                \n",
    "                insample_y  = self.to_tensor(x=batch['insample_y'])\n",
    "                insample_x  = self.to_tensor(x=batch['insample_x'])\n",
    "                s_matrix    = self.to_tensor(x=batch['s_matrix'])\n",
    "                idxs        = self.to_tensor(x=batch['idxs'], dtype=t.long)\n",
    "                \n",
    "                #print(\"insample_y.shape\", insample_y.shape)\n",
    "\n",
    "                outsample_y, forecast, levels = self.model(insample_y=insample_y,\n",
    "                                                           insample_x=insample_x,\n",
    "                                                           s_matrix=s_matrix,\n",
    "                                                           step_size=train_ts_loader.idx_to_sample_freq,\n",
    "                                                           idxs=idxs)\n",
    "                \n",
    "                #print(\"outsample_y.shape\", outsample_y.shape)\n",
    "                #print(\"forecast.shape\", forecast.shape)\n",
    "                \n",
    "                mask        = self.to_tensor(t.ones(forecast.shape))\n",
    "                \n",
    "                # train loss on normalized values\n",
    "                training_loss = training_loss_fn(forecast=forecast, target=outsample_y,\n",
    "                                                 x=insample_y, mask=mask, levels=levels)\n",
    "                \n",
    "                # Protection to exploding gradients\n",
    "                #print(\"step\")\n",
    "                training_loss.backward()\n",
    "                t.nn.utils.clip_grad_norm_(parameters=self.model.rnn.parameters(),\n",
    "                                           max_norm=self.gradient_clipping_threshold)\n",
    "                t.nn.utils.clip_grad_norm_(parameters=self.model.es.parameters(),\n",
    "                                           max_norm=self.gradient_clipping_threshold)\n",
    "                self.rnn_optimizer.step()\n",
    "                self.es_optimizer.step()\n",
    "\n",
    "            # Decay learning rate\n",
    "            self.es_scheduler.step()\n",
    "            self.rnn_scheduler.step()\n",
    "\n",
    "            # Evaluation\n",
    "            if (iteration % eval_freq == 0):\n",
    "                #print(\"EVALUATION\")\n",
    "                display_string = 'Step: {}, Time: {:03.3f}, Insample {}: {:.5f}'.format(iteration,\n",
    "                                                                                        time.time()-start,\n",
    "                                                                                        self.loss,\n",
    "                                                                                        training_loss.cpu().data.numpy())\n",
    "                self.trajectories['iteration'].append(iteration)\n",
    "                self.trajectories['train_loss'].append(float(training_loss.cpu().data.numpy()))\n",
    "\n",
    "                if val_ts_loader is not None:\n",
    "                    loss = self.evaluate_performance(ts_loader=val_ts_loader, \n",
    "                                                     validation_loss_fn=validation_loss_fn)\n",
    "                    display_string += \", Outsample {}: {:.5f}\".format(self.val_loss, loss)\n",
    "                    self.trajectories['val_loss'].append(loss)\n",
    "\n",
    "                    if self.early_stopping:\n",
    "                        if loss < best_val_loss:\n",
    "                            # Save current model if improves outsample loss\n",
    "                            best_state_dict = deepcopy(self.model.state_dict())\n",
    "                            best_insample_loss = training_loss.cpu().data.numpy()\n",
    "                            early_stopping_counter = 0\n",
    "                            best_val_loss = loss\n",
    "                        else:\n",
    "                            early_stopping_counter += 1\n",
    "                        if early_stopping_counter >= self.early_stopping:\n",
    "                            break_flag = True\n",
    "\n",
    "                print(display_string)\n",
    "        \n",
    "                if break_flag:\n",
    "                    print('\\n')\n",
    "                    print(19*'-',' Stopped training by early stopping', 19*'-')\n",
    "                    self.model.load_state_dict(best_state_dict)\n",
    "                    break\n",
    "\n",
    "        #End of fitting\n",
    "        if n_iterations > 0:\n",
    "            # This is batch loss!\n",
    "            self.final_insample_loss = float(training_loss.cpu().data.numpy()) if not break_flag else best_insample_loss \n",
    "            string = 'Step: {}, Time: {:03.3f}, Insample {}: {:.5f}'.format(iteration,\n",
    "                                                                            time.time()-start,\n",
    "                                                                            self.loss,\n",
    "                                                                            self.final_insample_loss)\n",
    "            if val_ts_loader is not None:\n",
    "                self.final_outsample_loss = self.evaluate_performance(ts_loader=val_ts_loader, \n",
    "                                                                      validation_loss_fn=validation_loss_fn)\n",
    "                string += \", Outsample {}: {:.5f}\".format(self.val_loss, self.final_outsample_loss)\n",
    "            print(string)\n",
    "            print('='*30+'  End fitting  '+'='*30)\n",
    "            print('\\n')\n",
    "\n",
    "    def predict(self, ts_loader, n_fcds=None, return_decomposition=False):\n",
    "        assert self._fitted, \"Model not fitted yet\"\n",
    "        self.model.eval()\n",
    "        assert not ts_loader.shuffle, 'ts_loader must have shuffle as False.'\n",
    "\n",
    "        forecasts = []\n",
    "        outsample_ys = []\n",
    "\n",
    "        with t.no_grad():\n",
    "            outsample_ys = []\n",
    "            forecasts = []\n",
    "            for batch in iter(ts_loader):\n",
    "                insample_y  = self.to_tensor(x=batch['insample_y'])\n",
    "                insample_x  = self.to_tensor(x=batch['insample_x'])\n",
    "                s_matrix    = self.to_tensor(x=batch['s_matrix'])\n",
    "                idxs        = self.to_tensor(x=batch['idxs'], dtype=t.long)\n",
    "                \n",
    "                #print(\"insample_y.shape\", insample_y.shape)\n",
    "                \n",
    "                outsample_y, forecast = self.model.predict(insample_y=insample_y, \n",
    "                                                           insample_x=insample_x,\n",
    "                                                           s_matrix=s_matrix,\n",
    "                                                           idxs=idxs,\n",
    "                                                           step_size=ts_loader.idx_to_sample_freq)\n",
    "                \n",
    "                #print(\"outsample_y.shape\", outsample_y.shape)\n",
    "                #print(\"forecast.shape\", forecast.shape)\n",
    "                \n",
    "                # Correction needed, TODO: move to loader/dataset\n",
    "                if n_fcds is not None:\n",
    "                    outsample_y = outsample_y[:, -n_fcds:, :]\n",
    "                    forecast = forecast[:, -n_fcds:, :]\n",
    "                \n",
    "                outsample_ys.append(outsample_y.cpu().data.numpy())\n",
    "                forecasts.append(forecast.cpu().data.numpy())\n",
    "        \n",
    "        forecasts = np.vstack(forecasts)\n",
    "        outsample_ys = np.vstack(outsample_ys)\n",
    "        outsample_masks = np.ones(outsample_ys.shape)\n",
    "        \n",
    "        self.model.train()\n",
    "\n",
    "        if return_decomposition:\n",
    "            return #TODO\n",
    "        else:\n",
    "            return outsample_ys, forecasts, outsample_masks\n",
    "    \n",
    "    def evaluate_performance(self, ts_loader, validation_loss_fn):\n",
    "        self.model.eval()\n",
    "\n",
    "        target, forecast, outsample_mask = self.predict(ts_loader=ts_loader)\n",
    "\n",
    "        complete_loss = validation_loss_fn(target=target, forecast=forecast, weights=outsample_mask)\n",
    "\n",
    "        self.model.train()\n",
    "\n",
    "        return complete_loss    \n",
    "\n",
    "    def save(self, model_dir=None, copy=None):\n",
    "        \"\"\"Auxiliary function to save ESRNN model\"\"\"\n",
    "        if copy is not None:\n",
    "                self.copy = copy\n",
    "\n",
    "        if not model_dir:\n",
    "            assert self.root_dir\n",
    "            model_dir = self.get_dir_name()\n",
    "\n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "\n",
    "        rnn_filepath = os.path.join(model_dir, \"rnn.model\")\n",
    "        es_filepath = os.path.join(model_dir, \"es.model\")\n",
    "\n",
    "        print('Saving model to:\\n {}'.format(model_dir)+'\\n')\n",
    "        t.save({'model_state_dict': self.es.state_dict()}, es_filepath)\n",
    "        t.save({'model_state_dict': self.rnn.state_dict()}, rnn_filepath)\n",
    "\n",
    "    def load(self, model_dir=None, copy=None):\n",
    "        \"\"\"Auxiliary function to load ESRNN model\"\"\"\n",
    "        if copy is not None:\n",
    "            self.copy = copy\n",
    "\n",
    "        if not model_dir:\n",
    "            assert self.root_dir\n",
    "            model_dir = self.get_dir_name()\n",
    "\n",
    "        rnn_filepath = os.path.join(model_dir, \"rnn.model\")\n",
    "        es_filepath = os.path.join(model_dir, \"es.model\")\n",
    "        path = Path(es_filepath)\n",
    "\n",
    "        if path.is_file():\n",
    "            print('Loading model from:\\n {}'.format(model_dir)+'\\n')\n",
    "\n",
    "            checkpoint = t.load(es_filepath, map_location=self.device)\n",
    "            self.es.load_state_dict(checkpoint['model_state_dict'])\n",
    "            self.es.to(self.device)\n",
    "\n",
    "            checkpoint = t.load(rnn_filepath, map_location=self.device)\n",
    "            self.rnn.load_state_dict(checkpoint['model_state_dict'])\n",
    "            self.rnn.to(self.device)\n",
    "        else:\n",
    "            print('Model path {} does not exist'.format(path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EPF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nixtla.data.datasets.epf import EPF, EPFInfo\n",
    "from nixtla.data.tsdataset import TimeSeriesDataset\n",
    "from nixtla.data.tsloader_general import TimeSeriesLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Validation splits\n",
      "                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0.0         2016-12-27 2018-12-24 23:00:00\n",
      "          1.0         2013-01-01 2016-12-26 23:00:00\n",
      "Total data \t\t\t52416 time stamps\n",
      "Available percentage=100.0, \t52416 time stamps\n",
      "Insample  percentage=66.67, \t34944.0 time stamps\n",
      "Outsample percentage=33.33, \t17472.0 time stamps\n",
      "\n",
      "\n",
      "Train Validation splits\n",
      "                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0.0         2013-01-01 2016-12-26 23:00:00\n",
      "          1.0         2016-12-27 2018-12-24 23:00:00\n",
      "Total data \t\t\t52416 time stamps\n",
      "Available percentage=100.0, \t52416 time stamps\n",
      "Insample  percentage=33.33, \t17472.0 time stamps\n",
      "Outsample percentage=66.67, \t34944.0 time stamps\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_df, X_df, _ = EPF.load(directory='../data', group=EPFInfo.groups[0])\n",
    "\n",
    "X_df = X_df[['unique_id', 'ds', 'Exogenous1', 'Exogenous2', 'week_day']]\n",
    "\n",
    "train_ts_dataset = TimeSeriesDataset(Y_df=Y_df, S_df=None, X_df=X_df, \n",
    "                                     ds_in_test=728*24, verbose=True)\n",
    "\n",
    "outsample_ts_dataset = TimeSeriesDataset(Y_df=Y_df, S_df=None, X_df=X_df, \n",
    "                                         ds_in_test=728*24, is_test=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts_loader = TimeSeriesLoader(ts_dataset=train_ts_dataset,\n",
    "                                   #model='esrnn',\n",
    "                                   model='new_rnn',\n",
    "                                   offset=0,\n",
    "                                   #model='esrnn',\n",
    "                                   #window_sampling_limit= 28*24,\n",
    "                                   window_sampling_limit= 500_000, # To limit backprop time\n",
    "                                   input_size=7*24,\n",
    "                                   output_size=24,\n",
    "                                   idx_to_sample_freq=24,\n",
    "                                   len_sample_chunks=4*7*24,\n",
    "                                   complete_inputs=True,\n",
    "                                   complete_sample=False,\n",
    "                                   batch_size=32,\n",
    "                                   shuffle=True)\n",
    "\n",
    "val_ts_loader = TimeSeriesLoader(ts_dataset=outsample_ts_dataset,\n",
    "                                 model='new_rnn',\n",
    "                                 offset=0,\n",
    "                                 #model='esrnn',\n",
    "                                 window_sampling_limit= 500_000, \n",
    "                                 input_size=7*24,\n",
    "                                 output_size=24,\n",
    "                                 idx_to_sample_freq=24,\n",
    "                                 len_sample_chunks=4*7*24,\n",
    "                                 complete_inputs=False,\n",
    "                                 complete_sample=True,\n",
    "                                 batch_size=1,\n",
    "                                 shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ESRNN(input_size=7*24,\n",
    "              output_size=24,\n",
    "              learning_rate=1e-3,\n",
    "              lr_scheduler_step_size=30,\n",
    "              lr_decay=0.9,\n",
    "              per_series_lr_multip=1.0,\n",
    "              gradient_eps=1e-8,\n",
    "              gradient_clipping_threshold=20,\n",
    "              rnn_weight_decay=0,\n",
    "              n_iterations=10,\n",
    "              early_stopping=10,\n",
    "              noise_std=0.001,\n",
    "              level_variability_penalty=200,\n",
    "              testing_percentile=50,\n",
    "              training_percentile=50,\n",
    "              es_component='multiplicative',\n",
    "              cell_type='LSTM',\n",
    "              state_hsize=500,\n",
    "              dilations=[[1, 2], [4, 8]],\n",
    "              add_nl_layer=False,\n",
    "              #loss='SMYL',\n",
    "              loss='PINBALL',\n",
    "              val_loss='MAE',\n",
    "              seasonality=[24, 168],\n",
    "              random_seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================== Start fitting ==============================\n",
      "Step: 10, Time: 11.899, Insample PINBALL: 0.04532, Outsample MAE: 3.36349\n",
      "Step: 10, Time: 12.336, Insample PINBALL: 0.04532, Outsample MAE: 3.36349\n",
      "==============================  End fitting  ==============================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ts_loader=train_ts_loader, \n",
    "          val_ts_loader=val_ts_loader, \n",
    "          #val_ts_loader=val_ts_loader, \n",
    "          eval_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_hat, y_mask = model.predict(ts_loader=val_ts_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat.shape (728, 21, 24)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(349440,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"y_hat.shape\", y_hat.shape)\n",
    "y_hat_flatten = y_hat[:,-20:,:].flatten()\n",
    "y_hat_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f71b8eb8d10>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_plot = Y_df['y'][-20*24:]\n",
    "plt.plot(range(len(y_plot)), y_plot, label='true')\n",
    "plt.plot(range(len(y_plot)-len(y_true[0,-1,:]),len(y_plot)), y_true[0,-1,:], label='reconstructed')\n",
    "plt.plot(range(len(y_hat_flatten)), y_hat_flatten, label='y_hat')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
