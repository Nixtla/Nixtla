{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.datasets.tourism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tourism dataset\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "\n",
    "from nixtla.data.datasets.utils import download_file, Info, TimeSeriesDataclass\n",
    "from nixtla.data.ts_dataset import TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "SOURCE_URL = 'https://robjhyndman.com/data/27-3-Athanasopoulos1.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tourism meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Yearly:\n",
    "    seasonality: int = 1\n",
    "    horizon: int = 4\n",
    "    freq: str = 'Y'\n",
    "    rows: int = 2\n",
    "    name: str = 'Yearly'\n",
    "    n_ts: int = 518\n",
    "\n",
    "@dataclass\n",
    "class Quarterly:\n",
    "    seasonality: int = 4\n",
    "    horizon: int = 8\n",
    "    freq: str = 'Q'\n",
    "    rows: int = 3\n",
    "    name: str = 'Quarterly'\n",
    "    n_ts: int = 427\n",
    "\n",
    "@dataclass\n",
    "class Monthly:\n",
    "    seasonality: int = 12\n",
    "    horizon: int = 24\n",
    "    freq: str = 'M'\n",
    "    rows: int = 3\n",
    "    name: str = 'Monthly'\n",
    "    n_ts: int = 366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "TourismInfo = Info(groups=('Yearly', 'Quarterly', 'Monthly'),\n",
    "                   class_groups=(Yearly, Quarterly, Monthly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Tourism(TimeSeriesDataclass):\n",
    "\n",
    "    @staticmethod\n",
    "    def load(directory: str,\n",
    "             group: str,\n",
    "             return_tensor: bool = True): #-> Union[TimeSeriesDataset, TimeSeriesDataclass]:\n",
    "        \"\"\"\n",
    "        Downloads and loads Tourism data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Yearly', 'Quarterly', 'Monthly'.\n",
    "        return_tensor: bool\n",
    "            Wheter return TimeSeriesDataset (tensors, True) or\n",
    "            TimeSeriesDataclass (dataframes)\n",
    "            \n",
    "        Notes\n",
    "        -----\n",
    "        [1] Returns train+test sets.\n",
    "        \"\"\"\n",
    "        path = Path(directory) / 'tourism' / 'datasets'\n",
    "\n",
    "        Tourism.download(directory)\n",
    "\n",
    "        class_group = TourismInfo.get_group(group)\n",
    "\n",
    "        train_file = path / f'{class_group.name.lower()}_in.csv'\n",
    "        test_file = path / f'{class_group.name.lower()}_oos.csv'\n",
    "        \n",
    "        train, test = pd.read_csv(train_file), pd.read_csv(test_file)\n",
    "\n",
    "        dfs = []\n",
    "        freq = to_offset(class_group.freq)\n",
    "        for col in train.columns:\n",
    "            df_appended = []\n",
    "            for df, training in zip([train, test], [True, False]):\n",
    "                df_col = df[col]\n",
    "                length, year = df_col[:2].astype(int)\n",
    "                skip_rows = class_group.rows\n",
    "                start_date = pd.to_datetime(f'{year}-01-01')\n",
    "                if group != 'Yearly':\n",
    "                    n_offsets = df_col[2].astype(int)\n",
    "                    start_date += n_offsets * freq\n",
    "                elif col == 'Y18' and not training: # viene mal en el archivo esta serie\n",
    "                    start_date += 2 * freq\n",
    "                df_col = df_col[skip_rows:length + skip_rows]\n",
    "                df_col = df_col.rename('y').to_frame()\n",
    "                df_col['unique_id'] = col\n",
    "                df_col['ds'] = pd.date_range(start_date, periods=length, freq=freq)\n",
    "                df_appended.append(df_col)\n",
    "            df_appended = pd.concat(df_appended)\n",
    "            dfs.append(df_appended)\n",
    "\n",
    "        df = pd.concat(dfs)\n",
    "\n",
    "        df = df.reset_index().filter(items=['unique_id', 'ds', 'y'])\n",
    "        df = df.sort_values(['unique_id', 'ds'])\n",
    "        \n",
    "        #if return_tensor:\n",
    "        #    return TimeSeriesDataset(y_df=df, X_s_df=None, X_t_df=None, output_size=class_group.horizon)\n",
    "        #else:\n",
    "        #    return TimeSeriesDataclass(Y=df, S=None, X=None, group=group)\n",
    "        return df, None\n",
    "\n",
    "    @staticmethod\n",
    "    def download(directory: str) -> None:\n",
    "        \"\"\"Downloads Tourism Dataset.\"\"\"\n",
    "        path = Path(directory) / 'tourism' / 'datasets'\n",
    "        if not path.exists():\n",
    "            download_file(path, SOURCE_URL, decompress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly\n",
      "Processing dataframes ...\n",
      "Creating ts tensor ...\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.7386e+04,\n",
      "          3.8432e+04, 4.0345e+04],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.9105e+05,\n",
      "          4.5404e+05, 5.5294e+05],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.8051e+03,\n",
      "          2.1386e+03, 2.6821e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.8804e+00,\n",
      "          5.3868e+00, 5.7406e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3240e+01,\n",
      "          2.5290e+01, 2.7336e+01],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.3312e+06,\n",
      "          1.0200e+07, 1.1703e+07],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]]])\n",
      "Quarterly\n",
      "Processing dataframes ...\n",
      "Creating ts tensor ...\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.4073e+03,\n",
      "          1.0330e+04, 6.9950e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3603e+05,\n",
      "          9.5582e+04, 1.2321e+05],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.0744e+04,\n",
      "          3.6207e+04, 2.9173e+04],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.5216e+05,\n",
      "          1.2300e+05, 5.2078e+04],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.1358e+04,\n",
      "          2.8420e+04, 1.4354e+04],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.9443e+04,\n",
      "          7.6657e+04, 3.8661e+04],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]]])\n",
      "Monthly\n",
      "Processing dataframes ...\n",
      "Creating ts tensor ...\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.6718e+03,\n",
      "          3.8068e+03, 6.9950e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.0353e+04,\n",
      "          3.8108e+04, 4.4751e+04],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.4180e+03,\n",
      "          2.5240e+03, 2.8080e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.1900e+02,\n",
      "          6.8200e+02, 6.5600e+02],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.4790e+03,\n",
      "          1.7290e+03, 1.5190e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.3340e+03,\n",
      "          2.7290e+03, 3.1100e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "for group in TourismInfo.groups:\n",
    "    print(group)\n",
    "    tourism_dataset = Tourism.load(directory='data', group=group)\n",
    "    print(tourism_dataset.ts_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in TourismInfo.class_groups:\n",
    "    data = Tourism.load(directory='data', group=group.name, return_tensor=False).Y\n",
    "    unique_elements = data.groupby(['unique_id', 'ds']).size()\n",
    "    unique_ts = data.groupby('unique_id').size()\n",
    "\n",
    "    assert (unique_elements != 1).sum() == 0, f'Duplicated records found: {group.name}'\n",
    "    assert unique_ts.shape[0] == group.n_ts, f'Number of time series not match: {group.name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}