{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.datasets.tourism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tourism dataset\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "\n",
    "from nixtla.data.datasets.utils import download_file, Info, TimeSeriesDataclass\n",
    "from nixtla.data.ts_dataset import TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "SOURCE_URL = 'https://robjhyndman.com/data/27-3-Athanasopoulos1.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tourism meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class Yearly:\n",
    "    seasonality: int = 1\n",
    "    horizon: int = 4\n",
    "    freq: str = 'Y'\n",
    "    rows: int = 2\n",
    "    name: str = 'Yearly'\n",
    "\n",
    "@dataclass\n",
    "class Quarterly:\n",
    "    seasonality: int = 4\n",
    "    horizon: int = 8\n",
    "    freq: str = 'Q'\n",
    "    rows: int = 3\n",
    "    name: str = 'Quarterly'\n",
    "\n",
    "@dataclass\n",
    "class Monthly:\n",
    "    seasonality: int = 12\n",
    "    horizon: int = 24\n",
    "    freq: str = 'M'\n",
    "    rows: int = 3\n",
    "    name: str = 'Monthly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "TourismInfo = Info(groups=('Yearly', 'Quarterly', 'Monthly'),\n",
    "                   class_groups=(Yearly, Quarterly, Monthly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Tourism(TimeSeriesDataclass):\n",
    "\n",
    "    @staticmethod\n",
    "    def load(directory: str,\n",
    "             group: str,\n",
    "             training: bool = True,\n",
    "             return_tensor: bool = True) -> Union[TimeSeriesDataset, TimeSeriesDataclass]:\n",
    "        \"\"\"\n",
    "        Downloads and loads Tourism data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'Yearly', 'Quarterly', 'Monthly'.\n",
    "        training: bool\n",
    "            Wheter return training or testing data. Default True.\n",
    "        return_tensor: bool\n",
    "            Wheter return TimeSeriesDataset (tensors, True) or\n",
    "            TimeSeriesDataclass (dataframes)\n",
    "        \"\"\"\n",
    "        path = Path(directory) / 'tourism' / 'datasets'\n",
    "\n",
    "        Tourism.download(directory)\n",
    "\n",
    "        class_group = TourismInfo.get_group(group)\n",
    "\n",
    "        if training:\n",
    "            file = path / f'{class_group.name.lower()}_in.csv'\n",
    "        else:\n",
    "            file = path / f'{class_group.name.lower()}_oos.csv'\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        dfs = []\n",
    "        freq = to_offset(class_group.freq)\n",
    "        for col in df.columns:\n",
    "            df_col = df[col]\n",
    "            length, year = df_col[:2].astype(int)\n",
    "            skip_rows = class_group.rows\n",
    "            start_date = pd.to_datetime(f'{year}-01-01')\n",
    "            if group != 'Yearly':\n",
    "                n_offsets = df_col[2].astype(int)\n",
    "                start_date += n_offsets * freq\n",
    "            elif col == 'Y18' and not training: # viene mal en el archivo esta serie\n",
    "                start_date += 2 * freq\n",
    "            df_col = df_col[skip_rows:length + skip_rows]\n",
    "            df_col = df_col.rename('y').to_frame()\n",
    "            df_col['unique_id'] = col\n",
    "            df_col['ds'] = pd.date_range(start_date, periods=length, freq=freq)\n",
    "\n",
    "            dfs.append(df_col)\n",
    "\n",
    "        df = pd.concat(dfs)\n",
    "\n",
    "        df = df.reset_index().filter(items=['unique_id', 'ds', 'y'])\n",
    "        df = df.sort_values(['unique_id', 'ds'])\n",
    "        \n",
    "        if return_tensor:\n",
    "            return TimeSeriesDataset(y_df=df, X_s_df=None, X_t_df=None)\n",
    "        else:\n",
    "            return TimeSeriesDataclass(Y=df, S=None, X=None, group=group)\n",
    "\n",
    "    @staticmethod\n",
    "    def download(directory: str) -> None:\n",
    "        \"\"\"Downloads Tourism Dataset.\"\"\"\n",
    "        path = Path(directory) / 'tourism' / 'datasets'\n",
    "        if not path.exists():\n",
    "            download_file(path, SOURCE_URL, decompress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly\n",
      "Processing dataframes ...\n",
      "Creating ts tensor ...\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.6053e+04,\n",
      "          3.8473e+04, 3.8421e+04],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.9310e+05,\n",
      "          3.2960e+05, 2.3426e+05],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.1042e+02,\n",
      "          9.1592e+02, 1.0107e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 4.8070e+00,\n",
      "          4.3470e+00, 4.9200e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0900e+01,\n",
      "          2.1000e+01, 2.0164e+01],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 6.5808e+06,\n",
      "          6.7954e+06, 8.0105e+06],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]]])\n",
      "Quarterly\n",
      "Processing dataframes ...\n",
      "Creating ts tensor ...\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.4659e+03,\n",
      "          9.3033e+03, 1.6747e+04],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.2507e+04,\n",
      "          8.3106e+04, 9.6931e+04],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.1576e+04,\n",
      "          3.2400e+04, 2.2951e+04],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.1681e+05,\n",
      "          1.2693e+05, 5.2806e+04],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.9044e+04,\n",
      "          2.7696e+04, 1.3727e+04],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 7.5206e+04,\n",
      "          6.8684e+04, 3.5228e+04],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]]])\n",
      "Monthly\n",
      "Processing dataframes ...\n",
      "Creating ts tensor ...\n",
      "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.0765e+03,\n",
      "          3.4026e+03, 5.9858e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.4167e+04,\n",
      "          2.9644e+04, 3.3120e+04],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.3840e+03,\n",
      "          1.8510e+03, 2.1220e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.9200e+02,\n",
      "          6.1600e+02, 5.9000e+02],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.2550e+03,\n",
      "          1.2060e+03, 1.3130e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.4240e+03,\n",
      "          1.9630e+03, 2.6470e+03],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "for group in TourismInfo.groups:\n",
    "    print(group)\n",
    "    tourism_dataset = Tourism.load(directory='data', group=group)\n",
    "    print(tourism_dataset.ts_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in TourismInfo.class_groups:\n",
    "    train_data = Tourism.load(directory='data', group=group.name, training=True, return_tensor=False).Y\n",
    "    valid_data = Tourism.load(directory='data', group=group.name, training=False, return_tensor=False).Y   \n",
    "    train_end_dates = train_data.groupby('unique_id').ds.max()\n",
    "    valid_start_dates = valid_data.groupby('unique_id').ds.min()\n",
    "    all_dates = train_end_dates.to_frame('end').join(valid_start_dates.rename('start'))\n",
    "    \n",
    "    assert (all_dates['end'] + to_offset(group.freq) == all_dates['start']).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
