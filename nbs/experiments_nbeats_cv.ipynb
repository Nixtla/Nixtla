{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experiments.nbeats.cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBEATS CV\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from itertools import product\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Iterable, Union\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nixtla.models.nbeats import Nbeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CrossValidationNbeats:\n",
    "    \n",
    "    def __init__(self, directory: Union[Path, str], \n",
    "                 grid: Dict[str, Iterable], \n",
    "                 ensemble_grid: Dict[str, Iterable],\n",
    "                 loader: Callable, \n",
    "                 gpu_id: int):\n",
    "        self.directory = Path(str(directory))\n",
    "        self.grid = grid\n",
    "        self.ensemble_grid = ensemble_grid\n",
    "        self.loader = loader\n",
    "        self.gpu_id = gpu_id\n",
    "        \n",
    "        self.params = _parameter_grid(grid)\n",
    "        self.ensemble_params = _parameter_grid(ensemble_grid)\n",
    "        \n",
    "        self.directory.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    def fit(self, ts_dataset):\n",
    "        ensemble_dir = [f'{param}={value}' for param, value in self.ensemble_grid.items()]\n",
    "        ensemble_dir = self.directory / '_'.join(ensemble_dir)\n",
    "        ensemble_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for _, row_params in self.params.iterrows():\n",
    "            hparams_grid = row_params.to_dict()\n",
    "            \n",
    "            forecast_file = [f'{param}={value}' for param, value in hparams_grid.items()]\n",
    "            forecast_file = '_'.join(forecast_file) + '.p'\n",
    "            forecast_file = ensemble_dir / forecast_file\n",
    "            \n",
    "            forecasts = []\n",
    "            for idx_ensemble, row_ensemble in tqdm(self.ensemble_params.iterrows()):\n",
    "                hparams_ensemble = row_ensemble.to_dict()\n",
    "                hparams = {**hparams_grid, **hparams_ensemble}\n",
    "\n",
    "                ts_loader = self.loader(ts_dataset=ts_dataset,\n",
    "                                        offset=hparams['offset'],\n",
    "                                        window_sampling_limit=hparams['window_sampling_limit_multiplier'] * hparams['output_size'],\n",
    "                                        input_size=hparams['input_size_multiplier'] * hparams['output_size'],\n",
    "                                        output_size=hparams['output_size'],\n",
    "                                        idx_to_sample_freq=1,\n",
    "                                        batch_size=hparams['batch_size'],\n",
    "                                        model='nbeats',\n",
    "                                        train_loader=True)\n",
    "\n",
    "                model = Nbeats(input_size_multiplier=hparams['input_size_multiplier'],\n",
    "                               output_size=hparams['output_size'],\n",
    "                               shared_weights=hparams['shared_weights'],\n",
    "                               stack_types=hparams['stack_types'],\n",
    "                               n_blocks=hparams['n_blocks'],\n",
    "                               n_layers=hparams['n_layers'],\n",
    "                               n_hidden=hparams['n_hidden'],\n",
    "                               n_harmonics=hparams['n_harmonics'],\n",
    "                               n_polynomials=hparams['n_polynomials'],\n",
    "                               learning_rate=hparams['learning_rate'],\n",
    "                               lr_decay=hparams['lr_decay'],\n",
    "                               n_lr_decay_steps=hparams['n_lr_decay_steps'],\n",
    "                               n_iterations=hparams['n_iterations'],\n",
    "                               loss=hparams['loss'],\n",
    "                               frequency=hparams['frequency'],\n",
    "                               seasonality=hparams['seasonality'],\n",
    "                               random_seed=hparams['random_seed'])\n",
    "                model.fit(ts_loader, eval_steps=1000, verbose=False)\n",
    "                \n",
    "                y_hat = model.predict(ts_loader)\n",
    "                y_hat.rename({'y_hat': f'y_hat_{idx_ensemble}'}, axis=1, inplace=True)\n",
    "                \n",
    "                forecasts.append(y_hat.set_index(['unique_id', 'ds']))\n",
    "                \n",
    "            forecasts = pd.concat(forecasts, 1)\n",
    "            forecasts['y_hat'] = forecasts.median(1)\n",
    "            forecasts = forecasts.reset_index()\n",
    "            \n",
    "            return forecasts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporti\n",
    "def _parameter_grid(grid):\n",
    "    specs_list = list(product(*list(grid.values())))\n",
    "    model_specs_df = pd.DataFrame(specs_list, columns=list(grid.keys()))\n",
    "    \n",
    "    return model_specs_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
