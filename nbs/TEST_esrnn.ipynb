{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit ('nixtla': conda)",
   "metadata": {
    "interpreter": {
     "hash": "52b0028e7074a0058398558ea661882eddbb489e66a28504cc0449d2f54d6290"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch as t\n",
    "import copy\n",
    "from fastcore.foundation import patch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nixtla.data.tsdataset import TimeSeriesDataset\n",
    "from nixtla.data.tsloader_general import TimeSeriesLoader as TimeSeriesLoaderGeneral\n",
    "\n",
    "from nixtla.models.esrnn.esrnn import ESRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing dataframes ...\nCreating ts tensor ...\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  unique_id                  ds      y\n",
       "0        NP 2013-01-01 00:00:00  31.05\n",
       "1        NP 2013-01-01 01:00:00  30.47\n",
       "2        NP 2013-01-01 02:00:00  28.92\n",
       "3        NP 2013-01-01 03:00:00  27.88\n",
       "4        NP 2013-01-01 04:00:00  26.96"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique_id</th>\n      <th>ds</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NP</td>\n      <td>2013-01-01 00:00:00</td>\n      <td>31.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NP</td>\n      <td>2013-01-01 01:00:00</td>\n      <td>30.47</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NP</td>\n      <td>2013-01-01 02:00:00</td>\n      <td>28.92</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NP</td>\n      <td>2013-01-01 03:00:00</td>\n      <td>27.88</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NP</td>\n      <td>2013-01-01 04:00:00</td>\n      <td>26.96</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from nixtla.data.datasets.epf import EPF, EPFInfo\n",
    "Y_df, X_df = EPF.load(directory='data', group=EPFInfo.groups[0])\n",
    "train_outsample_mask = np.ones(len(Y_df))\n",
    "train_outsample_mask[-365 * 24:] = 0\n",
    "sum(train_outsample_mask)\n",
    "epf_dataset = TimeSeriesDataset(Y_df=Y_df, S_df=None, X_df=X_df, ts_train_mask=train_outsample_mask)\n",
    "Y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = TimeSeriesLoaderGeneral(ts_dataset=epf_dataset,\n",
    "                                    model='esrnn',\n",
    "                                    offset=24,\n",
    "                                    window_sampling_limit= 90*1*24, #365*4*24\n",
    "                                    input_size=7*24,\n",
    "                                    output_size=24,\n",
    "                                    idx_to_sample_freq=1,\n",
    "                                    batch_size=1,\n",
    "                                    is_train_loader=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "esrnn = ESRNN(input_size=7*24,\n",
    "              output_size=24,\n",
    "              max_epochs=5,\n",
    "              freq_of_test=-1,\n",
    "              learning_rate=1e-3,\n",
    "              lr_scheduler_step_size=9,\n",
    "              lr_decay=0.9,\n",
    "              per_series_lr_multip=1.0,\n",
    "              gradient_eps=1e-8,\n",
    "              gradient_clipping_threshold=20,\n",
    "              rnn_weight_decay=0,\n",
    "              noise_std=0.001,\n",
    "              level_variability_penalty=200,\n",
    "              testing_percentile=50,\n",
    "              training_percentile=50,\n",
    "              cell_type='LSTM',\n",
    "              state_hsize=40,\n",
    "              dilations=[[1, 2], [4, 8]],\n",
    "              add_nl_layer=False,\n",
    "              seasonality=[24],\n",
    "              random_seed=1,\n",
    "              device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esrnn.fit(train_ts_loader=train_loader, eval_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = esrnn.predict(ts_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_plot = Y_df['y'][-168:]\n",
    "y_hat_plot = y_hat['y_hat']\n",
    "plt.plot(range(len(y_plot)), y_plot)\n",
    "plt.plot(range(len(y_plot), len(y_plot)+len(y_hat_plot)), y_hat_plot)"
   ]
  },
  {
   "source": [
    "# TOURISM WITH RANDOM STATIC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nixtla.data.datasets.tourism import Tourism, TourismInfo\n",
    "group = TourismInfo.groups[0]\n",
    "print(\"TourismInfo.groups[0]\", group)\n",
    "Y_df, _ = Tourism.load(directory='data', group=group)\n",
    "\n",
    "S_df = Y_df.copy()\n",
    "S_df = S_df.drop_duplicates(subset='unique_id').reset_index(drop=True)\n",
    "S_df = S_df.drop(columns=['ds','y'])\n",
    "S_df['static1'] = np.random.randint(low=0, high=10, size=len(S_df))\n",
    "S_df['static2'] = np.random.randint(low=0, high=10, size=len(S_df))\n",
    "S_df['static3'] = np.random.randint(low=0, high=10, size=len(S_df))\n",
    "S_df['static4'] = np.random.randint(low=0, high=10, size=len(S_df))\n",
    "S_df['static5'] = np.random.randint(low=0, high=10, size=len(S_df))\n",
    "S_df['static6'] = np.random.randint(low=0, high=10, size=len(S_df))\n",
    "S_df['static7'] = np.random.randint(low=0, high=10, size=len(S_df))\n",
    "S_df['static8'] = np.random.randint(low=0, high=10, size=len(S_df))\n",
    "S_df['static9'] = np.random.randint(low=0, high=10, size=len(S_df))\n",
    "S_df['static10'] = np.random.randint(low=0, high=10, size=len(S_df))\n",
    "S_df['static11'] = np.random.randint(low=0, high=10, size=len(S_df))\n",
    "S_df['static12'] = np.random.randint(low=0, high=10, size=len(S_df))\n",
    "S_df['static13'] = np.random.randint(low=0, high=10, size=len(S_df))\n",
    "S_df['static14'] = np.random.randint(low=0, high=10, size=len(S_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourism_dataset = TimeSeriesDataset(Y_df=Y_df, S_df=S_df, X_df=None, ts_train_mask=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = TimeSeriesLoaderGeneral(ts_dataset=tourism_dataset,\n",
    "                                            model='esrnn',\n",
    "                                            offset=4,\n",
    "                                            window_sampling_limit=20*4, \n",
    "                                            input_size=1*4,\n",
    "                                            output_size=4,\n",
    "                                            idx_to_sample_freq=1,\n",
    "                                            batch_size= 32,\n",
    "                                            n_series_per_batch=32,\n",
    "                                            is_train_loader=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esrnn = ESRNN(input_size=1*4,\n",
    "              output_size=4,\n",
    "              max_epochs=5,\n",
    "              freq_of_test=-1,\n",
    "              learning_rate=1e-3,\n",
    "              lr_scheduler_step_size=9,\n",
    "              lr_decay=0.9,\n",
    "              per_series_lr_multip=1.0,\n",
    "              gradient_eps=1e-8,\n",
    "              gradient_clipping_threshold=20,\n",
    "              rnn_weight_decay=0,\n",
    "              noise_std=0.001,\n",
    "              level_variability_penalty=200,\n",
    "              testing_percentile=50,\n",
    "              training_percentile=50,\n",
    "              cell_type='LSTM',\n",
    "              state_hsize=40,\n",
    "              dilations=[[1, 2], [4, 8]],\n",
    "              add_nl_layer=False,\n",
    "              seasonality=[],\n",
    "              random_seed=1,\n",
    "              device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esrnn.fit(train_ts_loader=train_loader, eval_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = esrnn.predict(ts_loader=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_plot = Y_df[Y_df['unique_id']=='Y1']['y']\n",
    "y_hat_plot = y_hat[y_hat['unique_id']=='Y1']['y_hat']\n",
    "plt.plot(range(len(y_plot)), y_plot)\n",
    "plt.plot(range(len(y_plot), len(y_plot)+len(y_hat_plot)), y_hat_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = Y_df.groupby('unique_id').tail(4).reset_index(drop=True)\n",
    "np.mean(np.abs(y_test['y']-y_hat['y_hat'])/np.abs(y_test['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}