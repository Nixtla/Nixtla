{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.datasets.epf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPF dataset\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from dataclasses import dataclass\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "\n",
    "from nixtla.data.datasets.utils import download_file, Info, TimeSeriesDataclass\n",
    "from nixtla.data.ts_dataset import TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "SOURCE_URL = 'https://sandbox.zenodo.org/api/files/da5b2c6f-8418-4550-a7d0-7f2497b40f1b/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tourism meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class NP:\n",
    "    test_date: str = '2016-12-27'\n",
    "    name: str = 'NP'\n",
    "\n",
    "@dataclass\n",
    "class PJM:\n",
    "    test_date: str = '2016-12-27'\n",
    "    name: str = 'PJM'\n",
    "\n",
    "@dataclass\n",
    "class BE:\n",
    "    test_date: str = '2015-01-04'\n",
    "    name: str = 'BE'\n",
    "\n",
    "@dataclass\n",
    "class FR:\n",
    "    test_date: str = '2015-01-04'\n",
    "    name: str = 'FR'\n",
    "\n",
    "@dataclass\n",
    "class DE:\n",
    "    test_date: str = '2016-01-04'\n",
    "    name: str = 'DE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "EPFInfo = Info(groups=('NP', 'PJM', 'BE', 'FR', 'DE'),\n",
    "               class_groups=(NP, PJM, BE, FR, DE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EPF:\n",
    "\n",
    "    #@staticmethod\n",
    "    def load(directory: str,\n",
    "             group: str,\n",
    "             training: bool = True,\n",
    "             days_in_test: int = 728,\n",
    "             return_tensor: bool = True): # -> Union[TimeSeriesDataset, TimeSeriesDataclass]\n",
    "        \"\"\"\n",
    "        Downloads and loads EPF data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'NP', 'PJM', 'BE', 'FR', 'DE'.\n",
    "        training: bool\n",
    "            Wheter return training or testing data. Default True.\n",
    "        days_in_test: int\n",
    "            Number of days to consider in test.\n",
    "            Only used when training=True.\n",
    "        return_tensor: bool\n",
    "            Wheter return TimeSeriesDataset (tensors, True) or\n",
    "            TimeSeriesDataclass (dataframes)\n",
    "        \"\"\"\n",
    "        path = Path(directory) / 'epf' / 'datasets'\n",
    "\n",
    "        EPF.download(directory)\n",
    "\n",
    "        class_group = EPFInfo.get_group(group)\n",
    "\n",
    "        file = path / f'{group}.csv'\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        df.columns = ['ds', 'y'] + \\\n",
    "                     [f'Exogenous{i}' for i in range(1, len(df.columns) - 1)]\n",
    "\n",
    "        df['unique_id'] = group\n",
    "        df['ds'] = pd.to_datetime(df['ds'])\n",
    "        df['week_day'] = df['ds'].dt.dayofweek\n",
    "\n",
    "        dummies = pd.get_dummies(df['week_day'], prefix='day')\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "        dummies_cols = [col for col in df \\\n",
    "                        if (col.startswith('day') or col.startswith('hour_'))]\n",
    "\n",
    "        if training:\n",
    "            df = df.query('ds < @class_group.test_date')\n",
    "        else:\n",
    "            last_date_test = pd.to_datetime(class_group.test_date) + \\\n",
    "                             timedelta(days=days_in_test)\n",
    "            df = df.query('ds >= @class_group.test_date')\n",
    "\n",
    "        Y = df.filter(items=['unique_id', 'ds', 'y'])\n",
    "        X = df.filter(items=['unique_id', 'ds', 'Exogenous1', 'Exogenous2', 'week_day'] + \\\n",
    "                      dummies_cols)\n",
    "        \n",
    "    #def get_data(self):\n",
    "        return Y, X\n",
    "        # if return_tensor:\n",
    "        #     return TimeSeriesDataset(y_df=Y, X_s_df=None, X_t_df=X, ts_train_mask=ts_train_mask)\n",
    "        # else:\n",
    "        #     return TimeSeriesDataclass(Y=Y, S=None, X=X, group=group)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_groups(directory: str,\n",
    "                    groups: List[str] = ['BE', 'FR'],\n",
    "                    training: bool = True,\n",
    "                    days_in_test: int = 728,\n",
    "                    return_tensor: bool = True) -> Union[TimeSeriesDataset, TimeSeriesDataclass]:\n",
    "        \"\"\"\n",
    "        Downloads and loads panel of EPF data\n",
    "        according of groups.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        groups: List[str]\n",
    "            Group names.\n",
    "            Allowed groups: 'NP', 'PJM', 'BE', 'FR', 'DE'.\n",
    "        training: bool\n",
    "            Wheter return training or testing data. Default True.\n",
    "        days_in_test: int\n",
    "            Number of days to consider in test.\n",
    "            Only used when training=True.\n",
    "        return_tensor: bool\n",
    "            Wheter return TimeSeriesDataset (tensors, True) or\n",
    "            TimeSeriesDataclass (dataframes)\n",
    "        \"\"\"\n",
    "        Y = []\n",
    "        X = []\n",
    "        for group in groups:\n",
    "            data = EPF.load(directory, group,\n",
    "                            training, days_in_test,\n",
    "                            return_tensor=False)\n",
    "            Y.append(data.Y)\n",
    "            X.append(data.X)\n",
    "        Y = pd.concat(Y).sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "        X = pd.concat(X).sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "\n",
    "        S = Y[['unique_id']].drop_duplicates().reset_index(drop=True)\n",
    "        dummies = pd.get_dummies(S['unique_id'], prefix='static')\n",
    "        S = pd.concat([S, dummies], axis=1)\n",
    "        \n",
    "        if return_tensor:\n",
    "            return TimeSeriesDataset(y_df=Y, X_s_df=None, X_t_df=X)\n",
    "        else:\n",
    "            return TimeSeriesDataclass(Y=Y, S=S, X=X, group=groups)\n",
    "\n",
    "    @staticmethod\n",
    "    def download(directory: str) -> None:\n",
    "        \"\"\"Downloads EPF Dataset.\"\"\"\n",
    "        path = Path(directory) / 'epf' / 'datasets'\n",
    "        if not path.exists():\n",
    "            for group in EPFInfo.groups:\n",
    "                download_file(path, SOURCE_URL + f'{group}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load specific group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pjm = EPF.load('data', group='PJM')\n",
    "pjm_test = EPF.load('data', group='PJM', training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('TS tensor: \\n', pjm.ts_tensor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('TS tensor test: \\n', pjm_test.ts_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load set of groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['PJM', 'NP', 'FR', 'BE', 'DE']\n",
    "pjm = EPF.load_groups('data', groups=groups)\n",
    "pjm_test = EPF.load_groups('data', groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TS tensor: \\n', pjm.ts_tensor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TS tensor test: \\n', pjm_test.ts_tensor) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('nixtla': conda)",
   "metadata": {
    "interpreter": {
     "hash": "97c68c0f618c4f787b1e02bfee278e48d25b62407cb335aab5258cedc4db4ced"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}