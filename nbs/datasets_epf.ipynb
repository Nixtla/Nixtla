{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.datasets.epf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPF dataset\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from dataclasses import dataclass\n",
    "from datetime import timedelta\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.frequencies import to_offset\n",
    "\n",
    "from nixtla.data.datasets.utils import download_file, Info, TimeSeriesDataclass\n",
    "from nixtla.data.ts_dataset import TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "SOURCE_URL = 'https://sandbox.zenodo.org/api/files/da5b2c6f-8418-4550-a7d0-7f2497b40f1b/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tourism meta information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dataclass\n",
    "class NP:\n",
    "    test_date: str = '2016-12-27'\n",
    "    name: str = 'NP'\n",
    "\n",
    "@dataclass\n",
    "class PJM:\n",
    "    test_date: str = '2016-12-27'\n",
    "    name: str = 'PJM'\n",
    "\n",
    "@dataclass\n",
    "class BE:\n",
    "    test_date: str = '2015-01-04'\n",
    "    name: str = 'BE'\n",
    "\n",
    "@dataclass\n",
    "class FR:\n",
    "    test_date: str = '2015-01-04'\n",
    "    name: str = 'FR'\n",
    "\n",
    "@dataclass\n",
    "class DE:\n",
    "    test_date: str = '2016-01-04'\n",
    "    name: str = 'DE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "EPFInfo = Info(groups=('NP', 'PJM', 'BE', 'FR', 'DE'),\n",
    "               class_groups=(NP, PJM, BE, FR, DE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EPF:\n",
    "\n",
    "    #@staticmethod\n",
    "    def load(directory: str,\n",
    "             group: str,\n",
    "             training: bool = True,\n",
    "             days_in_test: int = 728,\n",
    "             ts_train_mask = None, #TODO: hint\n",
    "             return_tensor: bool = True): # -> Union[TimeSeriesDataset, TimeSeriesDataclass]\n",
    "        \"\"\"\n",
    "        Downloads and loads EPF data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        group: str\n",
    "            Group name.\n",
    "            Allowed groups: 'NP', 'PJM', 'BE', 'FR', 'DE'.\n",
    "        training: bool\n",
    "            Wheter return training or testing data. Default True.\n",
    "        days_in_test: int\n",
    "            Number of days to consider in test.\n",
    "            Only used when training=True.\n",
    "        return_tensor: bool\n",
    "            Wheter return TimeSeriesDataset (tensors, True) or\n",
    "            TimeSeriesDataclass (dataframes)\n",
    "        \"\"\"\n",
    "        path = Path(directory) / 'epf' / 'datasets'\n",
    "\n",
    "        EPF.download(directory)\n",
    "\n",
    "        class_group = EPFInfo.get_group(group)\n",
    "\n",
    "        file = path / f'{group}.csv'\n",
    "\n",
    "        df = pd.read_csv(file)\n",
    "\n",
    "        df.columns = ['ds', 'y'] + \\\n",
    "                     [f'Exogenous{i}' for i in range(1, len(df.columns) - 1)]\n",
    "\n",
    "        df['unique_id'] = group\n",
    "        df['ds'] = pd.to_datetime(df['ds'])\n",
    "        df['week_day'] = df['ds'].dt.dayofweek\n",
    "\n",
    "        dummies = pd.get_dummies(df['week_day'], prefix='day')\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "        dummies_cols = [col for col in df \\\n",
    "                        if (col.startswith('day') or col.startswith('hour_'))]\n",
    "\n",
    "        if training:\n",
    "            df = df.query('ds < @class_group.test_date')\n",
    "        else:\n",
    "            last_date_test = pd.to_datetime(class_group.test_date) + \\\n",
    "                             timedelta(days=days_in_test)\n",
    "            df = df.query('ds >= @class_group.test_date')\n",
    "\n",
    "        Y = df.filter(items=['unique_id', 'ds', 'y'])\n",
    "        X = df.filter(items=['unique_id', 'ds', 'Exogenous1', 'Exogenous2'] + \\\n",
    "                      dummies_cols)\n",
    "        \n",
    "    #def get_data(self):\n",
    "        return Y, X\n",
    "        # if return_tensor:\n",
    "        #     return TimeSeriesDataset(y_df=Y, X_s_df=None, X_t_df=X, ts_train_mask=ts_train_mask)\n",
    "        # else:\n",
    "        #     return TimeSeriesDataclass(Y=Y, S=None, X=X, group=group)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_groups(directory: str,\n",
    "                    groups: List[str] = ['BE', 'FR'],\n",
    "                    training: bool = True,\n",
    "                    days_in_test: int = 728,\n",
    "                    return_tensor: bool = True) -> Union[TimeSeriesDataset, TimeSeriesDataclass]:\n",
    "        \"\"\"\n",
    "        Downloads and loads panel of EPF data\n",
    "        according of groups.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        directory: str\n",
    "            Directory where data will be downloaded.\n",
    "        groups: List[str]\n",
    "            Group names.\n",
    "            Allowed groups: 'NP', 'PJM', 'BE', 'FR', 'DE'.\n",
    "        training: bool\n",
    "            Wheter return training or testing data. Default True.\n",
    "        days_in_test: int\n",
    "            Number of days to consider in test.\n",
    "            Only used when training=True.\n",
    "        return_tensor: bool\n",
    "            Wheter return TimeSeriesDataset (tensors, True) or\n",
    "            TimeSeriesDataclass (dataframes)\n",
    "        \"\"\"\n",
    "        Y = []\n",
    "        X = []\n",
    "        for group in groups:\n",
    "            data = EPF.load(directory, group,\n",
    "                            training, days_in_test,\n",
    "                            return_tensor=False)\n",
    "            Y.append(data.Y)\n",
    "            X.append(data.X)\n",
    "        Y = pd.concat(Y).sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "        X = pd.concat(X).sort_values(['unique_id', 'ds']).reset_index(drop=True)\n",
    "\n",
    "        S = Y[['unique_id']].drop_duplicates().reset_index(drop=True)\n",
    "        dummies = pd.get_dummies(S['unique_id'], prefix='static')\n",
    "        S = pd.concat([S, dummies], axis=1)\n",
    "        \n",
    "        if return_tensor:\n",
    "            return TimeSeriesDataset(y_df=Y, X_s_df=None, X_t_df=X)\n",
    "        else:\n",
    "            return TimeSeriesDataclass(Y=Y, S=S, X=X, group=groups)\n",
    "\n",
    "    @staticmethod\n",
    "    def download(directory: str) -> None:\n",
    "        \"\"\"Downloads EPF Dataset.\"\"\"\n",
    "        path = Path(directory) / 'epf' / 'datasets'\n",
    "        if not path.exists():\n",
    "            for group in EPFInfo.groups:\n",
    "                download_file(path, SOURCE_URL + f'{group}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load specific group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataframes ...\n",
      "Creating ts tensor ...\n",
      "Processing dataframes ...\n",
      "Creating ts tensor ...\n"
     ]
    }
   ],
   "source": [
    "pjm = EPF.load('data', group='PJM')\n",
    "pjm_test = EPF.load('data', group='PJM', training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS tensor: \n",
      " tensor([[[2.5464e+01, 2.3555e+01, 2.2122e+01,  ..., 2.4525e+01,\n",
      "          2.2835e+01, 2.0455e+01],\n",
      "         [8.5049e+04, 8.2128e+04, 8.0729e+04,  ..., 9.3346e+04,\n",
      "          8.7603e+04, 8.1626e+04],\n",
      "         [1.1509e+04, 1.0942e+04, 1.0639e+04,  ..., 1.2129e+04,\n",
      "          1.1642e+04, 1.0924e+04],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "print('TS tensor: \\n', pjm.ts_tensor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS tensor test: \n",
      " tensor([[[1.9113e+01, 1.8043e+01, 1.7587e+01,  ..., 2.6406e+01,\n",
      "          2.4647e+01, 2.3980e+01],\n",
      "         [7.4616e+04, 7.1821e+04, 7.0353e+04,  ..., 9.2923e+04,\n",
      "          9.0970e+04, 8.8037e+04],\n",
      "         [1.0214e+04, 9.7020e+03, 9.4310e+03,  ..., 1.0963e+04,\n",
      "          1.0802e+04, 1.0419e+04],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "print('TS tensor test: \\n', pjm_test.ts_tensor) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load set of groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataframes ...\n",
      "Creating ts tensor ...\n",
      "Processing dataframes ...\n",
      "Creating ts tensor ...\n"
     ]
    }
   ],
   "source": [
    "groups = ['PJM', 'NP', 'FR', 'BE', 'DE']\n",
    "pjm = EPF.load_groups('data', groups=groups)\n",
    "pjm_test = EPF.load_groups('data', groups=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS tensor: \n",
      " tensor([[[3.2540e+01, 2.1550e+01, 1.5710e+01,  ..., 4.2440e+01,\n",
      "          4.2030e+01, 4.0910e+01],\n",
      "         [6.3065e+04, 6.2715e+04, 6.1952e+04,  ..., 7.2883e+04,\n",
      "          7.2926e+04, 7.3070e+04],\n",
      "         [6.3000e+04, 5.8800e+04, 5.8500e+04,  ..., 6.4515e+04,\n",
      "          6.2554e+04, 6.7342e+04],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[3.4970e+01, 3.3430e+01, 3.2740e+01,  ..., 2.2110e+01,\n",
      "          2.0910e+01, 1.4430e+01],\n",
      "         [2.0720e+03, 1.9298e+03, 1.8560e+03,  ..., 1.4118e+03,\n",
      "          1.4292e+03, 1.4318e+03],\n",
      "         [1.6382e+04, 1.5410e+04, 1.5595e+04,  ..., 1.8490e+04,\n",
      "          1.8718e+04, 1.7559e+04],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[3.2542e+01, 2.1549e+01, 1.5711e+01,  ..., 4.2440e+01,\n",
      "          4.2030e+01, 4.0910e+01],\n",
      "         [6.3065e+04, 6.2715e+04, 6.1952e+04,  ..., 7.2883e+04,\n",
      "          7.2926e+04, 7.3070e+04],\n",
      "         [6.3000e+04, 5.8800e+04, 5.8500e+04,  ..., 6.4515e+04,\n",
      "          6.2554e+04, 6.7342e+04],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[3.1050e+01, 3.0470e+01, 2.8920e+01,  ..., 2.6820e+01,\n",
      "          2.6650e+01, 2.5680e+01],\n",
      "         [4.2497e+04, 4.1463e+04, 4.0812e+04,  ..., 4.5471e+04,\n",
      "          4.4386e+04, 4.3017e+04],\n",
      "         [2.7980e+03, 2.4170e+03, 2.0360e+03,  ..., 2.1290e+03,\n",
      "          1.8270e+03, 1.6890e+03],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[2.5464e+01, 2.3555e+01, 2.2122e+01,  ..., 2.4525e+01,\n",
      "          2.2835e+01, 2.0455e+01],\n",
      "         [8.5049e+04, 8.2128e+04, 8.0729e+04,  ..., 9.3346e+04,\n",
      "          8.7603e+04, 8.1626e+04],\n",
      "         [1.1509e+04, 1.0942e+04, 1.0639e+04,  ..., 1.2129e+04,\n",
      "          1.1642e+04, 1.0924e+04],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "print('TS tensor: \\n', pjm.ts_tensor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS tensor test: \n",
      " tensor([[[3.2540e+01, 2.1550e+01, 1.5710e+01,  ..., 4.2440e+01,\n",
      "          4.2030e+01, 4.0910e+01],\n",
      "         [6.3065e+04, 6.2715e+04, 6.1952e+04,  ..., 7.2883e+04,\n",
      "          7.2926e+04, 7.3070e+04],\n",
      "         [6.3000e+04, 5.8800e+04, 5.8500e+04,  ..., 6.4515e+04,\n",
      "          6.2554e+04, 6.7342e+04],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[3.4970e+01, 3.3430e+01, 3.2740e+01,  ..., 2.2110e+01,\n",
      "          2.0910e+01, 1.4430e+01],\n",
      "         [2.0720e+03, 1.9298e+03, 1.8560e+03,  ..., 1.4118e+03,\n",
      "          1.4292e+03, 1.4318e+03],\n",
      "         [1.6382e+04, 1.5410e+04, 1.5595e+04,  ..., 1.8490e+04,\n",
      "          1.8718e+04, 1.7559e+04],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[3.2542e+01, 2.1549e+01, 1.5711e+01,  ..., 4.2440e+01,\n",
      "          4.2030e+01, 4.0910e+01],\n",
      "         [6.3065e+04, 6.2715e+04, 6.1952e+04,  ..., 7.2883e+04,\n",
      "          7.2926e+04, 7.3070e+04],\n",
      "         [6.3000e+04, 5.8800e+04, 5.8500e+04,  ..., 6.4515e+04,\n",
      "          6.2554e+04, 6.7342e+04],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[3.1050e+01, 3.0470e+01, 2.8920e+01,  ..., 2.6820e+01,\n",
      "          2.6650e+01, 2.5680e+01],\n",
      "         [4.2497e+04, 4.1463e+04, 4.0812e+04,  ..., 4.5471e+04,\n",
      "          4.4386e+04, 4.3017e+04],\n",
      "         [2.7980e+03, 2.4170e+03, 2.0360e+03,  ..., 2.1290e+03,\n",
      "          1.8270e+03, 1.6890e+03],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]],\n",
      "\n",
      "        [[2.5464e+01, 2.3555e+01, 2.2122e+01,  ..., 2.4525e+01,\n",
      "          2.2835e+01, 2.0455e+01],\n",
      "         [8.5049e+04, 8.2128e+04, 8.0729e+04,  ..., 9.3346e+04,\n",
      "          8.7603e+04, 8.1626e+04],\n",
      "         [1.1509e+04, 1.0942e+04, 1.0639e+04,  ..., 1.2129e+04,\n",
      "          1.1642e+04, 1.0924e+04],\n",
      "         ...,\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "          0.0000e+00, 0.0000e+00],\n",
      "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
      "          1.0000e+00, 1.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "print('TS tensor test: \\n', pjm_test.ts_tensor) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}