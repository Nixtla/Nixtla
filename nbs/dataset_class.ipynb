{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data.ts_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeSeriesDataset class\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch as t\n",
    "\n",
    "from fastcore.foundation import patch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 y_df,\n",
    "                 X_t_df = None,\n",
    "                 X_s_df = None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        assert type(y_df) == pd.core.frame.DataFrame\n",
    "        assert all([(col in y_df) for col in ['unique_id', 'ds', 'y']])\n",
    "        if X_t_df is not None:\n",
    "            assert type(X_t_df) == pd.core.frame.DataFrame\n",
    "            assert all([(col in X_t_df) for col in ['unique_id', 'ds']])\n",
    "\n",
    "        print('Processing dataframes ...')\n",
    "        ts_data, static_data, self.meta_data = self._df_to_lists(y_df=y_df, X_s_df=X_s_df, X_t_df=X_t_df)\n",
    "\n",
    "        # Attributes\n",
    "        self.n_series = len(ts_data)\n",
    "        self.max_len = max([len(ts['y']) for ts in ts_data])\n",
    "        self.n_channels = len(ts_data[0].values())\n",
    "        self.frequency = pd.infer_freq(y_df.head()['ds']) #TODO: improve, can die with head\n",
    "\n",
    "        self.n_x_t, self.n_s_t = 0, 0\n",
    "        if X_t_df is not None:\n",
    "            self.n_x_t = X_t_df.shape[1]-2 # 2 for unique_id and ds\n",
    "        if X_s_df is not None:\n",
    "            self.n_s_t = X_s_df.shape[1]-1 # 1 for unique_id\n",
    "\n",
    "        print('Creating ts tensor ...')\n",
    "        self.ts_tensor, self.static_data, self.len_series = self._create_tensor(ts_data, static_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def _df_to_lists(self:TimeSeriesDataset, y_df, X_s_df, X_t_df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    unique_ids = y_df['unique_id'].unique()\n",
    "\n",
    "    if X_t_df is not None:\n",
    "        X_t_vars = [col for col in X_t_df.columns if col not in ['unique_id','ds']]\n",
    "    else:\n",
    "        X_t_vars = []\n",
    "\n",
    "    if X_s_df is not None:\n",
    "        X_s_vars = [col for col in X_s_df.columns if col not in ['unique_id']]\n",
    "    else:\n",
    "        X_s_vars = []\n",
    "\n",
    "    ts_data = []\n",
    "    static_data = []\n",
    "    meta_data = []\n",
    "    for i, u_id in enumerate(unique_ids):\n",
    "        top_row = np.asscalar(y_df['unique_id'].searchsorted(u_id, 'left'))\n",
    "        bottom_row = np.asscalar(y_df['unique_id'].searchsorted(u_id, 'right'))\n",
    "        serie = y_df[top_row:bottom_row]['y'].values\n",
    "        last_ds_i = y_df[top_row:bottom_row]['ds'].max()\n",
    "        \n",
    "        # Y values\n",
    "        ts_data_i = {'y': serie}\n",
    "        # X_t values\n",
    "        for X_t_var in X_t_vars:\n",
    "            serie =  X_t_df[top_row:bottom_row][X_t_var].values\n",
    "            ts_data_i[X_t_var] = serie\n",
    "        ts_data.append(ts_data_i)\n",
    "\n",
    "        # Static data\n",
    "        s_data_i = defaultdict(list)\n",
    "        for X_s_var in X_s_vars:\n",
    "            s_data_i[X_s_var] = X_s_df.loc[X_s_df['unique_id']==u_id, X_s_var].values\n",
    "        static_data.append(s_data_i)\n",
    "\n",
    "        # Metadata\n",
    "        meta_data_i = {'unique_id': u_id,\n",
    "                        'last_ds': last_ds_i}\n",
    "        meta_data.append(meta_data_i)\n",
    "\n",
    "    return ts_data, static_data, meta_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def _create_tensor(self:TimeSeriesDataset, ts_data, static_data):\n",
    "    \"\"\"\n",
    "    ts_tensor: n_series x n_channels x max_len\n",
    "    \"\"\"\n",
    "    ts_tensor = np.zeros((self.n_series, self.n_channels + 1, self.max_len)) # + 1 for the mask of ones\n",
    "    static_tensor = np.zeros((self.n_series, len(static_data[0])))\n",
    "\n",
    "    len_series = []\n",
    "    for idx in range(self.n_series):\n",
    "        ts_idx = np.array(list(ts_data[idx].values()))\n",
    "        ts_tensor[idx, :-1, -ts_idx.shape[1]:] = ts_idx\n",
    "        ts_tensor[idx, -1, -ts_idx.shape[1]:] = 1 # TODO: sacar esto\n",
    "        static_tensor[idx, :] = list(static_data[idx].values())\n",
    "        len_series.append(ts_idx.shape[1])\n",
    "    \n",
    "    # TODO: mover a sampler\n",
    "    ts_tensor = t.Tensor(ts_tensor)\n",
    "    static_tensor = t.Tensor(static_tensor)\n",
    "\n",
    "    return ts_tensor, static_tensor, np.array(len_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def get_meta_data_var(self:TimeSeriesDataset, var):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    var_values = [x[var] for x in self.meta_data]\n",
    "    return var_values\n",
    "\n",
    "@patch\n",
    "def get_static_data(self:TimeSeriesDataset):\n",
    "    return self.static_data\n",
    "\n",
    "@patch\n",
    "def get_filtered_tensor(self:TimeSeriesDataset, offset, output_size, window_sampling_limit):\n",
    "    \"\"\"\n",
    "    Comment here\n",
    "    \"\"\"\n",
    "    last_ds = self.max_len - offset + output_size\n",
    "    first_ds = max(last_ds - window_sampling_limit - output_size, 0)\n",
    "    filtered_tensor = self.ts_tensor[:, :, first_ds:last_ds]\n",
    "    right_padding = max(last_ds - self.max_len, 0) #To padd with zeros if there is \"nothing\" to the right\n",
    "    return filtered_tensor, right_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
