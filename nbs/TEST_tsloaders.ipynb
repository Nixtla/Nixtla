{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('nixtla': conda)",
   "metadata": {
    "interpreter": {
     "hash": "97c68c0f618c4f787b1e02bfee278e48d25b62407cb335aab5258cedc4db4ced"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch as t\n",
    "import copy\n",
    "from fastcore.foundation import patch\n",
    "from nixtla.data.tsdataset import TimeSeriesDataset\n",
    "from nixtla.data.tsloader_fast import TimeSeriesLoader as TimeSeriesLoaderFast\n",
    "from nixtla.data.tsloader_pinche import TimeSeriesLoader as TimeSeriesLoaderPinche\n",
    "from nixtla.data.tsloader_general import TimeSeriesLoader as TimeSeriesLoaderGeneral\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing dataframes ...\nCreating ts tensor ...\nX_df.shape (34944, 11)\nY_df.shape (34944, 3)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  unique_id                  ds      y\n",
       "0        NP 2013-01-01 00:00:00  31.05\n",
       "1        NP 2013-01-01 01:00:00  30.47\n",
       "2        NP 2013-01-01 02:00:00  28.92\n",
       "3        NP 2013-01-01 03:00:00  27.88\n",
       "4        NP 2013-01-01 04:00:00  26.96"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique_id</th>\n      <th>ds</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NP</td>\n      <td>2013-01-01 00:00:00</td>\n      <td>31.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NP</td>\n      <td>2013-01-01 01:00:00</td>\n      <td>30.47</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NP</td>\n      <td>2013-01-01 02:00:00</td>\n      <td>28.92</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NP</td>\n      <td>2013-01-01 03:00:00</td>\n      <td>27.88</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NP</td>\n      <td>2013-01-01 04:00:00</td>\n      <td>26.96</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from nixtla.data.datasets.epf import EPF, EPFInfo\n",
    "Y_df, X_df = EPF.load(directory='data', group=EPFInfo.groups[0])\n",
    "train_outsample_mask = np.ones(len(Y_df))\n",
    "train_outsample_mask[-365 * 24:] = 0\n",
    "sum(train_outsample_mask)\n",
    "epf_dataset = TimeSeriesDataset(Y_df=Y_df, S_df=None, X_df=X_df, ts_train_mask=train_outsample_mask)\n",
    "print(\"X_df.shape\", X_df.shape)\n",
    "print(\"Y_df.shape\", Y_df.shape)\n",
    "Y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TourismInfo.groups[2] Monthly\n",
      "Processing dataframes ...\n",
      "Creating ts tensor ...\n",
      "Y_df.shape (109280, 3)\n"
     ]
    }
   ],
   "source": [
    "from nixtla.data.datasets.tourism import Tourism, TourismInfo\n",
    "\n",
    "group = TourismInfo.groups[2]\n",
    "print(\"TourismInfo.groups[2]\", group)\n",
    "Y_df, _ = Tourism.load(directory='data', group=group)\n",
    "\n",
    "# Creating outliers to check leakages\n",
    "ds = np.sort(Y_df['ds'].unique())\n",
    "ts_train_mask = np.ones(333) # hardcodeado a serie más larga\n",
    "ts_train_mask[-10:] = 0\n",
    "outlier = Y_df.groupby('unique_id').tail(10).reset_index(drop=True)\n",
    "outlier['y'] = [10**(x+8) for x in range(10)] * len(np.unique(Y_df.unique_id))\n",
    "outlier.columns = ['unique_id', 'ds', 'y_val']\n",
    "Y_df = Y_df.merge(outlier, how='left', on=['unique_id', 'ds'])\n",
    "Y_df['y_val'] = Y_df['y_val'].fillna(0)\n",
    "Y_df['y'] = Y_df['y'] + Y_df['y_val']\n",
    "del Y_df['y_val']\n",
    "\n",
    "tourism_dataset = TimeSeriesDataset(Y_df=Y_df, S_df=None, X_df=None, ts_train_mask=ts_train_mask)\n",
    "\n",
    "print(\"Y_df.shape\", Y_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_loader_general = TimeSeriesLoaderGeneral(ts_dataset=tourism_dataset,\n",
    "                                            model='nbeats',\n",
    "                                            offset=0,\n",
    "                                            window_sampling_limit=200*4, \n",
    "                                            input_size=3*4,\n",
    "                                            output_size=4,\n",
    "                                            idx_to_sample_freq=1,\n",
    "                                            batch_size= 2048,\n",
    "                                            n_series_per_batch=32,\n",
    "                                            is_train_loader=True)\n",
    "\n",
    "ts_loader_pinche = TimeSeriesLoaderPinche(ts_dataset=tourism_dataset,\n",
    "                                          model='nbeats',\n",
    "                                          offset=0,\n",
    "                                          window_sampling_limit=200*4, \n",
    "                                          input_size=3*4,\n",
    "                                          output_size=4,\n",
    "                                          idx_to_sample_freq=1,\n",
    "                                          batch_size= 2048,\n",
    "                                          is_train_loader=True)\n",
    "\n",
    "ts_loader_fast = TimeSeriesLoaderFast(ts_dataset=tourism_dataset,\n",
    "                                      model='nbeats',\n",
    "                                      offset=0,\n",
    "                                      window_sampling_limit=200*4, \n",
    "                                      input_size=3*4,\n",
    "                                      output_size=4,\n",
    "                                      idx_to_sample_freq=1,\n",
    "                                      batch_size= 2048,\n",
    "                                      is_train_loader=True)\n",
    "\n",
    "# ts_loader_general = TimeSeriesLoaderGeneral(ts_dataset=epf_dataset,\n",
    "#                                             model='nbeats',\n",
    "#                                             offset=0,\n",
    "#                                             window_sampling_limit=365*4*24, \n",
    "#                                             input_size=3*24,\n",
    "#                                             output_size=24,\n",
    "#                                             idx_to_sample_freq=1,\n",
    "#                                             batch_size= 2048,\n",
    "#                                             n_series_per_batch=1,\n",
    "#                                             is_train_loader=True)\n",
    "\n",
    "# # TODO: Investigar porqué el pinche escala de 0.13 a 4 segundos con exogenas EAI puede no tener la culpa\n",
    "# ts_loader_pinche = TimeSeriesLoaderPinche(ts_dataset=epf_dataset,\n",
    "#                                         model='nbeats',\n",
    "#                                         offset=0,\n",
    "#                                         window_sampling_limit=365*4*24, \n",
    "#                                         input_size=3*24,\n",
    "#                                         output_size=24,\n",
    "#                                         idx_to_sample_freq=1,\n",
    "#                                         batch_size= 2048,\n",
    "#                                         is_train_loader=True)\n",
    "\n",
    "# ts_loader_fast = TimeSeriesLoaderFast(ts_dataset=epf_dataset,\n",
    "#                                         model='nbeats',\n",
    "#                                         offset=0,\n",
    "#                                         window_sampling_limit=365*4*24, \n",
    "#                                         input_size=3*24,\n",
    "#                                         output_size=24,\n",
    "#                                         idx_to_sample_freq=1,\n",
    "#                                         batch_size= 2048,\n",
    "#                                         is_train_loader=True)"
   ]
  },
  {
   "source": [
    "## COMPARING BATCH TIMES AND CHECKING MODEL INPUT SHAPES\n",
    "## CHECKING VALIDATION MASK AND LEAKAGE PROTECTIONS"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DataloaderGeneral batch time: 0.026996135711669922\ninsample_y.shape torch.Size([2048, 12])\ninsample_x.shape torch.Size([2048, 0, 12])\noutsample_y.shape torch.Size([2048, 4])\noutsample_x.shape torch.Size([2048, 0, 4])\nt.max(insample_y) tensor(118350.)\nt.max(outsample_y) tensor(118350.)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dataloader = iter(ts_loader_general)\n",
    "batch = next(dataloader)\n",
    "insample_y = batch['insample_y']\n",
    "insample_x = batch['insample_x']\n",
    "insample_mask = batch['insample_mask']\n",
    "outsample_x = batch['outsample_x']\n",
    "outsample_y = batch['outsample_y']\n",
    "outsample_mask = batch['outsample_mask']\n",
    "print(\"DataloaderGeneral batch time:\", time.time()-start)\n",
    "print(\"insample_y.shape\", insample_y.shape)\n",
    "print(\"insample_x.shape\", insample_x.shape)\n",
    "print(\"outsample_y.shape\", outsample_y.shape)\n",
    "print(\"outsample_x.shape\", outsample_x.shape)\n",
    "print(\"t.max(insample_y)\", t.max(insample_y))\n",
    "print(\"t.max(outsample_y)\", t.max(outsample_y * outsample_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DataloaderPinche batch time: 0.1765608787536621\ninsample_y.shape torch.Size([2048, 12])\ninsample_x.shape torch.Size([2048, 0, 12])\noutsample_y.shape torch.Size([2048, 4])\noutsample_x.shape torch.Size([2048, 0, 4])\nt.max(insample_y) tensor(601161.)\nt.max(outsample_y) tensor(486600.)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dataloader = iter(ts_loader_pinche)\n",
    "batch = next(dataloader)\n",
    "insample_y = batch['insample_y']\n",
    "insample_x = batch['insample_x']\n",
    "insample_mask = batch['insample_mask']\n",
    "outsample_x = batch['outsample_x']\n",
    "outsample_y = batch['outsample_y']\n",
    "outsample_mask = batch['outsample_mask']\n",
    "print(\"DataloaderPinche batch time:\", time.time()-start)\n",
    "print(\"insample_y.shape\", insample_y.shape)\n",
    "print(\"insample_x.shape\", insample_x.shape)\n",
    "print(\"outsample_y.shape\", outsample_y.shape)\n",
    "print(\"outsample_x.shape\", outsample_x.shape)\n",
    "print(\"t.max(insample_y)\", t.max(insample_y))\n",
    "print(\"t.max(outsample_y)\", t.max(outsample_y * outsample_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DataloaderFast batch time: 0.0003039836883544922\ninsample_y.shape torch.Size([2048, 12])\ninsample_x.shape torch.Size([2048, 0, 12])\noutsample_y.shape torch.Size([2048, 4])\noutsample_x.shape torch.Size([2048, 0, 4])\nt.max(insample_y) tensor(509100.)\nt.max(outsample_y) tensor(526800.)\n"
     ]
    }
   ],
   "source": [
    "dataloader = iter(ts_loader_fast)\n",
    "batch = next(dataloader)\n",
    "start = time.time()\n",
    "insample_y = batch['insample_y']\n",
    "insample_x = batch['insample_x']\n",
    "insample_mask = batch['insample_mask']\n",
    "outsample_x = batch['outsample_x']\n",
    "outsample_y = batch['outsample_y']\n",
    "outsample_mask = batch['outsample_mask']\n",
    "print(\"DataloaderFast batch time:\", time.time()-start)\n",
    "print(\"insample_y.shape\", insample_y.shape)\n",
    "print(\"insample_x.shape\", insample_x.shape)\n",
    "print(\"outsample_y.shape\", outsample_y.shape)\n",
    "print(\"outsample_x.shape\", outsample_x.shape)\n",
    "print(\"t.max(insample_y)\", t.max(insample_y))\n",
    "print(\"t.max(outsample_y)\", t.max(outsample_y * outsample_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_loader_fast.ts_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_loader_fast.ts_windows[20000:20010]"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}