{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit ('nixtla': conda)",
   "metadata": {
    "interpreter": {
     "hash": "52b0028e7074a0058398558ea661882eddbb489e66a28504cc0449d2f54d6290"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch as t\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from fastcore.foundation import patch\n",
    "from nixtla.data.tsdataset import TimeSeriesDataset\n",
    "from nixtla.data.tsloader_fast import TimeSeriesLoader as TimeSeriesLoaderFast\n",
    "from nixtla.data.tsloader_pinche import TimeSeriesLoader as TimeSeriesLoaderPinche\n",
    "from nixtla.data.tsloader_general import TimeSeriesLoader as TimeSeriesLoaderGeneral\n",
    "\n",
    "from nixtla.models.tcn.tcn import TCN"
   ]
  },
  {
   "source": [
    "# NP"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing dataframes ...\nCreating ts tensor ...\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  unique_id                  ds      y\n",
       "0        NP 2013-01-01 00:00:00  31.05\n",
       "1        NP 2013-01-01 01:00:00  30.47\n",
       "2        NP 2013-01-01 02:00:00  28.92\n",
       "3        NP 2013-01-01 03:00:00  27.88\n",
       "4        NP 2013-01-01 04:00:00  26.96"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique_id</th>\n      <th>ds</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NP</td>\n      <td>2013-01-01 00:00:00</td>\n      <td>31.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NP</td>\n      <td>2013-01-01 01:00:00</td>\n      <td>30.47</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NP</td>\n      <td>2013-01-01 02:00:00</td>\n      <td>28.92</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NP</td>\n      <td>2013-01-01 03:00:00</td>\n      <td>27.88</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NP</td>\n      <td>2013-01-01 04:00:00</td>\n      <td>26.96</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from nixtla.data.datasets.epf import EPF, EPFInfo\n",
    "Y_df, X_df = EPF.load(directory='data', group=EPFInfo.groups[0])\n",
    "train_outsample_mask = np.ones(len(Y_df))\n",
    "train_outsample_mask[-365 * 24:] = 0\n",
    "sum(train_outsample_mask)\n",
    "epf_dataset = TimeSeriesDataset(Y_df=Y_df, S_df=None, X_df=X_df, ts_train_mask=train_outsample_mask)\n",
    "# print('X: time series features, of shape (#series,#times,#features): \\t' + str(X.shape))\n",
    "# print('Y: target series (in X), of shape (#series,#times): \\t \\t' + str(Y.shape))\n",
    "# print('S: static features, of shape (#series,#features): \\t \\t' + str(S.shape))\n",
    "Y_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = TimeSeriesLoaderGeneral(ts_dataset=epf_dataset,\n",
    "                                    model='tcn',\n",
    "                                    offset=24,\n",
    "                                    window_sampling_limit=365*4*24, \n",
    "                                    input_size=7*24,\n",
    "                                    output_size=24,\n",
    "                                    idx_to_sample_freq=1,\n",
    "                                    batch_size=1024,\n",
    "                                    is_train_loader=True)\n",
    "\n",
    "val_loader = TimeSeriesLoaderGeneral(ts_dataset=epf_dataset,\n",
    "                                  model='tcn',\n",
    "                                  offset=24,\n",
    "                                  window_sampling_limit=365*4*24, \n",
    "                                  input_size=7*24,\n",
    "                                  output_size=24,\n",
    "                                  idx_to_sample_freq=1,\n",
    "                                  batch_size=1024,\n",
    "                                  is_train_loader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcn = TCN(input_size_multiplier=7,\n",
    "          output_size=24,\n",
    "          n_channels = [10,10,1],\n",
    "          kernel_size=3,\n",
    "          initialization='lecun_normal',\n",
    "          learning_rate=0.001,\n",
    "          lr_decay=0.5,\n",
    "          n_lr_decay_steps=3,\n",
    "          weight_decay=0,\n",
    "          l1_inputs=0,\n",
    "          dropout_prob=0.1,\n",
    "          max_epochs=10,\n",
    "          early_stopping=100,\n",
    "          loss='ME',\n",
    "          frequency='Y',\n",
    "          random_seed=1,\n",
    "          seasonality=4,\n",
    "          device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "============================== Start fitting ==============================\nNumber of exogenous variables: 11\nNumber of epochs: 10\ninsample_y.shape torch.Size([1024, 11, 168])\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (24) must match the size of tensor b (168) at non-singleton dimension 2",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-58e56993ea74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ts_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nixtla/lib/python3.7/site-packages/nixtla/models/tcn/tcn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_ts_loader, val_ts_loader, max_epochs, verbose, eval_epochs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 training_loss = training_loss_fn(x=insample_y, freq=self.seasonality, forecast=forecast,\n\u001b[0;32m--> 253\u001b[0;31m                                                 target=outsample_y, mask=outsample_mask)\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nixtla/lib/python3.7/site-packages/nixtla/models/tcn/tcn.py\u001b[0m in \u001b[0;36mloss\u001b[0;34m(x, freq, forecast, target, mask)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforecast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MAPE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mMAPELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforecast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_l1_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MASE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nixtla/lib/python3.7/site-packages/nixtla/losses/pytorch.py\u001b[0m in \u001b[0;36mMAPELoss\u001b[0;34m(y, y_hat, mask)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \"\"\"\n\u001b[1;32m     48\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivide_no_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mmape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mmape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (24) must match the size of tensor b (168) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "tcn.fit(train_ts_loader=train_loader, eval_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}