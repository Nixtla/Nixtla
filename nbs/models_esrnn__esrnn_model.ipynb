{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.esrnn.esrnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "\n",
    "from nixtla.models.components.drnn import DRNN\n",
    "# from nixtla.models.components.tcn import _TemporalConvNet as TCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#TODO: rnn con canales\n",
    "#TODO: notacion de todo, windows_y_insample, step_size vs freq\n",
    "class _ES(nn.Module):\n",
    "    def __init__(self, n_series: int, input_size: int, output_size: int,\n",
    "                 output_size_m: int,\n",
    "                 n_t: int, n_s: int, seasonality: list, noise_std: float, device: str):\n",
    "        super(_ES, self).__init__()\n",
    "\n",
    "        self.n_series = n_series\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.output_size_m = output_size_m\n",
    "        self.n_t = n_t\n",
    "        self.n_s = n_s\n",
    "        self.seasonality = seasonality\n",
    "        assert len(self.seasonality) in [0, 1, 2]\n",
    "\n",
    "        self.noise_std = noise_std\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "    def gaussian_noise(self, Y: t.Tensor, std: float=0.2):\n",
    "        size = Y.size()\n",
    "        noise = t.autograd.Variable(Y.data.new(size).normal_(0, std))\n",
    "        return Y + noise\n",
    "\n",
    "    def compute_levels_seasons(self, Y: t.Tensor, idxs: t.Tensor):\n",
    "        pass\n",
    "\n",
    "    def normalize(self, Y: t.Tensor, level: t.Tensor, seasonalities: t.Tensor, start: int, end: int):\n",
    "        pass\n",
    "\n",
    "    def predict(self, trend: t.Tensor, levels: t.Tensor, seasonalities: t.Tensor):\n",
    "        pass\n",
    "\n",
    "    def forward(self, S: t.Tensor, Y: t.Tensor, X: t.Tensor, idxs: t.Tensor, step_size: int):\n",
    "        # parse attributes\n",
    "        input_size = self.input_size\n",
    "        output_size = self.output_size\n",
    "        n_t = self.n_t\n",
    "        n_s = self.n_s\n",
    "        context_size = input_size + (input_size+output_size)*n_t + n_s\n",
    "        noise_std = self.noise_std\n",
    "        seasonality = self.seasonality\n",
    "        batch_size = len(idxs)\n",
    "\n",
    "        n_series, n_time = Y.shape\n",
    "\n",
    "        # Explicacion: windows_end es el idx delultimo inicio de windows. Como se necesitan windows completas con input\n",
    "        # + output, se pierden (input_size+output_size-1) windows del len total de la serie.\n",
    "        windows_end = n_time - input_size - output_size + 1\n",
    "        windows_range = range(0, windows_end, step_size)\n",
    "        n_windows = len(windows_range)\n",
    "\n",
    "        assert n_windows>0\n",
    "\n",
    "        # Initialize windows, levels and seasonalities\n",
    "        levels, seasonalities = self.compute_levels_seasons(Y=Y, idxs=idxs)\n",
    "        windows_y_insample = t.zeros((n_windows, batch_size, context_size),\n",
    "                                          device=self.device)\n",
    "        windows_y_outsample = t.zeros((n_windows, batch_size, output_size),\n",
    "                                           device=self.device)\n",
    "\n",
    "        for i, window in enumerate(windows_range):\n",
    "            # Windows yhat\n",
    "            y_insample_start = window\n",
    "            y_insample_end = input_size + window\n",
    "\n",
    "            # Y_hat deseasonalization and normalization\n",
    "            window_y_insample = self.normalize(Y=Y[:, y_insample_start:y_insample_end],\n",
    "                                               level=levels[:, [y_insample_end-1]],\n",
    "                                               seasonalities=seasonalities,\n",
    "                                               start=y_insample_start, end=y_insample_end) #TODO: improve this inputs\n",
    "\n",
    "            if self.training:\n",
    "                window_y_insample = self.gaussian_noise(window_y_insample, std=noise_std)\n",
    "\n",
    "            if n_t > 0:\n",
    "                window_x_t = X[:, :, y_insample_start:(y_insample_end+output_size)]\n",
    "                window_x_t = window_x_t.reshape(batch_size, -1)\n",
    "                window_y_insample = t.cat((window_y_insample, window_x_t), 1)\n",
    "\n",
    "            # Concatenate S static variables matrix\n",
    "            if n_s > 0:\n",
    "                window_y_insample = t.cat((window_y_insample, S), 1)\n",
    "\n",
    "            windows_y_insample[i, :, :] += window_y_insample\n",
    "\n",
    "            # Windows_y_outsample\n",
    "            y_outsample_start = y_insample_end\n",
    "            y_outsample_end = y_outsample_start + output_size\n",
    "            window_y_outsample = Y[:, y_outsample_start:y_outsample_end]\n",
    "            # If training, normalize outsample for loss on normalized data\n",
    "            if self.training:\n",
    "                # Y deseasonalization and normalization\n",
    "                window_y_outsample = self.normalize(Y=window_y_outsample,\n",
    "                                                    level=levels[:, [y_outsample_start]],\n",
    "                                                    seasonalities=seasonalities,\n",
    "                                                    start=y_outsample_start, end=y_outsample_end) #TODO: improve this inputs\n",
    "            windows_y_outsample[i, :, :] += window_y_outsample\n",
    "\n",
    "        return windows_y_insample, windows_y_outsample, levels, seasonalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _ESI(_ES):\n",
    "    def __init__(self, n_series: int, input_size: int, output_size: int,\n",
    "                 output_size_m: int,\n",
    "                 n_t: int, n_s: int, seasonality: list, noise_std: float, device: str):\n",
    "        super(_ESI, self).__init__(n_series, input_size, output_size, \n",
    "                                   output_size_m,\n",
    "                                   n_t, n_s, seasonality, noise_std, device)\n",
    "        self.W = t.nn.Parameter(t.randn(1))\n",
    "        self.W.requires_grad = False\n",
    "\n",
    "    def compute_levels_seasons(self, Y: t.Tensor, idxs: t.Tensor):\n",
    "        levels = t.ones(Y.shape)\n",
    "        seasonalities = None\n",
    "        return levels, None\n",
    "    \n",
    "    def normalize(self, Y: t.Tensor, level: t.Tensor, seasonalities: t.Tensor, \n",
    "                  start: int, end: int):\n",
    "        return Y\n",
    "\n",
    "    def predict(self, trends: t.Tensor, levels: t.Tensor, seasonalities: t.Tensor,\n",
    "                step_size: int):\n",
    "        return trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _MedianResidual(_ES):\n",
    "    def __init__(self, n_series: int, input_size: int, output_size: int, \n",
    "                 output_size_m: int,\n",
    "                 n_t: int, n_s: int, seasonality: list, noise_std: float, device: str):\n",
    "        super(_MedianResidual, self).__init__(n_series, input_size, output_size, output_size_m,\n",
    "                                   n_t, n_s, seasonality, noise_std, device)\n",
    "        self.W = t.nn.Parameter(t.randn(1))\n",
    "        self.W.requires_grad = False\n",
    "\n",
    "    def compute_levels_seasons(self, Y: t.Tensor, idxs: t.Tensor):\n",
    "        \"\"\"\n",
    "        Computes levels and seasons\n",
    "        \"\"\"\n",
    "        y_transformed, _ = Y.median(1)\n",
    "        y_transformed = y_transformed.reshape(-1, 1)\n",
    "        levels = y_transformed.repeat(1, Y.shape[1])\n",
    "        seasonalities = None\n",
    "        \n",
    "        return levels, None\n",
    "    \n",
    "    def normalize(self, Y: t.Tensor, level: t.Tensor, \n",
    "                  seasonalities: t.Tensor, \n",
    "                  start: int, end: int):\n",
    "        \n",
    "        return Y - level\n",
    "\n",
    "    def predict(self, trends: t.Tensor, levels: t.Tensor, \n",
    "                seasonalities: t.Tensor, step_size: int):\n",
    "        levels = levels[:, (self.input_size-1):-self.output_size]\n",
    "        levels = levels[:, ::step_size]\n",
    "        levels = levels.unsqueeze(2)\n",
    "\n",
    "        return trends + levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _ESM(_ES):\n",
    "    def __init__(self, n_series: int, input_size: int, output_size: int,\n",
    "                 output_size_m: int,\n",
    "                 n_t: int, n_s: int, seasonality: list, noise_std: float, device: str):\n",
    "        super(_ESM, self).__init__(n_series, input_size, output_size, \n",
    "                                   output_size_m, \n",
    "                                   n_t, n_s, seasonality, noise_std, device)\n",
    "        # Level and Seasonality Smoothing parameters\n",
    "        # 1 level, S seasonalities, S init_seas\n",
    "        embeds_size = 1 + len(self.seasonality) + sum(self.seasonality)\n",
    "        init_embeds = t.ones((self.n_series, embeds_size)) * 0.5\n",
    "        self.embeds = nn.Embedding(self.n_series, embeds_size)\n",
    "        self.embeds.weight.data.copy_(init_embeds)\n",
    "        self.seasonality = t.LongTensor(self.seasonality)\n",
    "\n",
    "    def compute_levels_seasons(self, Y: t.Tensor, idxs: t.Tensor):\n",
    "        \"\"\"\n",
    "        Computes levels and seasons\n",
    "        \"\"\"\n",
    "        # Lookup parameters per serie\n",
    "        #seasonality = self.seasonality\n",
    "        embeds = self.embeds(idxs)\n",
    "        lev_sms = t.sigmoid(embeds[:, 0])\n",
    "\n",
    "        # Initialize seasonalities\n",
    "        seas_prod = t.ones(len(Y[:,0])).to(Y.device)\n",
    "        seasonalities1 = []\n",
    "        seasonalities2 = []\n",
    "        seas_sms1 = t.ones(1).to(Y.device)\n",
    "        seas_sms2 = t.ones(1).to(Y.device)\n",
    "\n",
    "        if len(self.seasonality)>0:\n",
    "            seas_sms1 = t.sigmoid(embeds[:, 1])\n",
    "            init_seas1 = t.exp(embeds[:, 2:(2+self.seasonality[0])]).unbind(1)\n",
    "            assert len(init_seas1) == self.seasonality[0]\n",
    "\n",
    "            for i in range(len(init_seas1)):\n",
    "                seasonalities1 += [init_seas1[i]]\n",
    "            seasonalities1 += [init_seas1[0]]\n",
    "            seas_prod = seas_prod * init_seas1[0]\n",
    "\n",
    "        if len(self.seasonality)==2:\n",
    "            seas_sms2 = t.sigmoid(embeds[:, 2+self.seasonality[0]])\n",
    "            init_seas2 = t.exp(embeds[:, 3+self.seasonality[0]:]).unbind(1)\n",
    "            assert len(init_seas2) == self.seasonality[1]\n",
    "\n",
    "            for i in range(len(init_seas2)):\n",
    "                seasonalities2 += [init_seas2[i]]\n",
    "            seasonalities2 += [init_seas2[0]]\n",
    "            seas_prod = seas_prod * init_seas2[0]\n",
    "\n",
    "        # Initialize levels\n",
    "        levels = []\n",
    "        levels += [Y[:,0]/seas_prod]\n",
    "\n",
    "        # Recursive seasonalities and levels\n",
    "        ys = Y.unbind(1)\n",
    "        n_time = len(ys)\n",
    "        for t_idx in range(1, n_time):\n",
    "            seas_prod_t = t.ones(len(Y[:,t_idx])).to(Y.device)\n",
    "            if len(self.seasonality)>0:\n",
    "                seas_prod_t = seas_prod_t * seasonalities1[t_idx]\n",
    "            if len(self.seasonality)==2:\n",
    "                seas_prod_t = seas_prod_t * seasonalities2[t_idx]\n",
    "\n",
    "            newlev = lev_sms * (ys[t_idx] / seas_prod_t) + (1-lev_sms) * levels[t_idx-1]\n",
    "            levels += [newlev]\n",
    "\n",
    "            if len(self.seasonality)==1:\n",
    "                newseason1 = seas_sms1 * (ys[t_idx] / newlev) + (1-seas_sms1) * seasonalities1[t_idx]\n",
    "                seasonalities1 += [newseason1]\n",
    "\n",
    "            if len(self.seasonality)==2:\n",
    "                newseason1 = seas_sms1 * (ys[t_idx] / (newlev * seasonalities2[t_idx])) + \\\n",
    "                                         (1-seas_sms1) * seasonalities1[t_idx]\n",
    "                seasonalities1 += [newseason1]\n",
    "                newseason2 = seas_sms2 * (ys[t_idx] / (newlev * seasonalities1[t_idx])) + \\\n",
    "                                         (1-seas_sms2) * seasonalities2[t_idx]\n",
    "                seasonalities2 += [newseason2]\n",
    "\n",
    "        levels = t.stack(levels).transpose(1,0)\n",
    "\n",
    "        seasonalities = []\n",
    "\n",
    "        if len(self.seasonality)>0:\n",
    "            seasonalities += [t.stack(seasonalities1).transpose(1,0)]\n",
    "\n",
    "        if len(self.seasonality)==2:\n",
    "            seasonalities += [t.stack(seasonalities2).transpose(1,0)]\n",
    "\n",
    "        return levels, seasonalities\n",
    "\n",
    "    def normalize(self, Y: t.Tensor, level: t.Tensor, seasonalities: t.Tensor, \n",
    "                  start: int, end: int):\n",
    "        # Deseasonalization and normalization\n",
    "        y_n = Y / level\n",
    "        for s in range(len(self.seasonality)):\n",
    "            y_n /= seasonalities[s][:, start:end]\n",
    "        y_n = t.log(y_n)\n",
    "        return y_n\n",
    "\n",
    "    def predict(self, trends: t.Tensor, levels: t.Tensor, seasonalities: t.Tensor, step_size: int):\n",
    "\n",
    "        # First trend uses last value of first y_insample of length self.input_size.\n",
    "        # Last self.output_size levels are not used (leakeage!!!)\n",
    "        levels = levels[:, (self.input_size-1):-self.output_size]\n",
    "        levels = levels[:, ::step_size]\n",
    "        levels = levels.unsqueeze(2)\n",
    "\n",
    "        # Seasonalities are unfolded, because each element of trends must be multiplied\n",
    "        # by the corresponding seasonality.\n",
    "        for i in range(len(seasonalities)):\n",
    "            seasonalities[i] = seasonalities[i][:, self.input_size : -self.seasonality[i]]\n",
    "            seasonalities[i] = seasonalities[i].unfold(dimension=-1, size=self.output_size, step=step_size)\n",
    "\n",
    "        # Denormalize\n",
    "        trends = t.exp(trends)\n",
    "        # Deseasonalization and normalization (inverse)\n",
    "        y_hat = trends * levels\n",
    "        for s in range(len(self.seasonality)):\n",
    "            seas = seasonalities[s]\n",
    "            y_hat *= t.vstack([seas.T for _ in range(self.output_size_m)]).T\n",
    "\n",
    "        return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _RNN(nn.Module):\n",
    "    def __init__(self, input_size: int, output_size: int,\n",
    "                 output_size_m: int,\n",
    "                 n_t: int, n_s: int, cell_type: str, dilations: list, state_hsize: int, add_nl_layer: bool):\n",
    "        super(_RNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.output_size_m = output_size_m\n",
    "        self.n_t = n_t\n",
    "        self.n_s = n_s\n",
    "\n",
    "        self.cell_type = cell_type\n",
    "        self.dilations = dilations\n",
    "        self.state_hsize = state_hsize\n",
    "        self.add_nl_layer = add_nl_layer\n",
    "        self.layers = len(dilations)\n",
    "\n",
    "        layers = []\n",
    "        for grp_num in range(len(self.dilations)):\n",
    "            if grp_num == 0:\n",
    "                input_size = self.input_size + (self.input_size + self.output_size)*self.n_t + self.n_s\n",
    "            else:\n",
    "                input_size = self.state_hsize\n",
    "            layer = DRNN(input_size,\n",
    "                         self.state_hsize,\n",
    "                         n_layers=len(self.dilations[grp_num]),\n",
    "                         dilations=self.dilations[grp_num],\n",
    "                         cell_type=self.cell_type)\n",
    "            layers.append(layer)\n",
    "\n",
    "        self.rnn_stack = nn.Sequential(*layers)\n",
    "\n",
    "        if self.add_nl_layer:\n",
    "            self.MLPW  = nn.Linear(self.state_hsize, self.state_hsize)\n",
    "\n",
    "        self.adapterW  = nn.Linear(self.state_hsize, self.output_size * self.output_size_m)\n",
    "\n",
    "    def forward(self, input_data: t.Tensor):\n",
    "        for layer_num in range(len(self.rnn_stack)):\n",
    "            residual = input_data\n",
    "            output, _ = self.rnn_stack[layer_num](input_data)\n",
    "            if layer_num > 0:\n",
    "                output += residual\n",
    "            input_data = output\n",
    "\n",
    "        if self.add_nl_layer:\n",
    "            input_data = self.MLPW(input_data)\n",
    "            input_data = t.tanh(input_data)\n",
    "\n",
    "        input_data = self.adapterW(input_data)\n",
    "        \n",
    "        return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _ESRNN(nn.Module):\n",
    "    def __init__(self, n_series, input_size, output_size, \n",
    "                 output_size_m, n_t, n_s,\n",
    "                 es_component, seasonality, noise_std, cell_type,\n",
    "                 dilations, state_hsize, add_nl_layer, device):\n",
    "        super(_ESRNN, self).__init__()\n",
    "        allowed_componets = ['multiplicative', 'identity', 'median_residual']\n",
    "        assert es_component in allowed_componets, f'es_component {es_component} not valid.'\n",
    "        self.es_component = es_component\n",
    "\n",
    "        if es_component == 'multiplicative':\n",
    "            self.es = _ESM(n_series=n_series, input_size=input_size, output_size=output_size,\n",
    "                           output_size_m=output_size_m, n_t=n_t, n_s=n_s, \n",
    "                           seasonality=seasonality, noise_std=noise_std,\n",
    "                           device=device).to(device)\n",
    "        elif es_component == 'identity':\n",
    "            self.es = _ESI(n_series=n_series, input_size=input_size, output_size=output_size,\n",
    "                           output_size_m=output_size_m, n_t=n_t, n_s=n_s, \n",
    "                           seasonality=seasonality, noise_std=noise_std,\n",
    "                           device=device).to(device)\n",
    "        elif es_component == 'median_residual':\n",
    "            self.es = _MedianResidual(n_series=n_series, input_size=input_size, output_size=output_size,\n",
    "                                      output_size_m=output_size_m, n_t=n_t, n_s=n_s, \n",
    "                                      seasonality=seasonality, noise_std=noise_std,\n",
    "                                      device=device).to(device)\n",
    "            \n",
    "        self.rnn = _RNN(input_size=input_size, output_size=output_size,\n",
    "                        output_size_m=output_size_m,\n",
    "                        n_t=n_t, n_s=n_s,\n",
    "                        cell_type=cell_type, dilations=dilations, \n",
    "                        state_hsize=state_hsize,\n",
    "                        add_nl_layer=add_nl_layer).to(device)\n",
    "\n",
    "    def forward(self, S: t.Tensor, Y: t.Tensor, X: t.Tensor, idxs: t.Tensor, step_size: int):\n",
    "        # Multiplicative model protection\n",
    "        if self.es_component == 'multiplicative':\n",
    "            assert t.min(Y)>0, 'Check your Y data, multiplicative model only deals with Y>0.'\n",
    "        \n",
    "        # ES Forward\n",
    "        windows_y_insample, windows_y_outsample, levels, seasonalities = self.es(S=S,Y=Y,X=X,idxs=idxs,\n",
    "                                                                                 step_size=step_size)\n",
    "        # RNN Forward\n",
    "        windows_y_hat = self.rnn(windows_y_insample)\n",
    "        \n",
    "        if self.rnn.output_size_m > 1:\n",
    "            n_w, n_ts, _ = windows_y_insample.shape\n",
    "            windows_y_hat = windows_y_hat.view(n_w, n_ts, -1, self.rnn.output_size_m)\n",
    "\n",
    "        return windows_y_outsample, windows_y_hat, levels\n",
    "\n",
    "    def predict(self, S: t.Tensor, Y: t.Tensor, X: t.Tensor, idxs: t.Tensor, step_size: int):\n",
    "        # ES Forward\n",
    "        windows_y_insample, windows_y_outsample, levels, seasonalities = self.es(S=S, Y=Y, X=X, idxs=idxs,\n",
    "                                                                                 step_size=step_size)\n",
    "        # RNN Forward\n",
    "        trends = self.rnn(windows_y_insample)\n",
    "\n",
    "        # (n_windows, batch_size, input_size) -> (batch_size, n_windows, input_size)\n",
    "        trends = trends.permute(1,0,2)\n",
    "        windows_y_outsample = windows_y_outsample.permute(1,0,2)\n",
    "\n",
    "        y_hat = self.es.predict(trends, levels, seasonalities, step_size)\n",
    "        \n",
    "        if self.rnn.output_size_m > 1:\n",
    "            n_ts, n_w, _ = windows_y_outsample.shape\n",
    "            y_hat = y_hat.view(n_ts, n_w, -1, self.rnn.output_size_m)\n",
    "\n",
    "        return windows_y_outsample, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
