{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp experiments.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import time\n",
    "import os\n",
    "# Limit number of threads in numpy and others to avoid throttling\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"2\" # export OMP_NUM_THREADS=4\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"2\" # export OPENBLAS_NUM_THREADS=4 \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"3\" # export MKL_NUM_THREADS=6\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"2\" # export VECLIB_MAXIMUM_THREADS=4\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"3\" # export NUMEXPR_NUM_THREADS=6\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import pickle\n",
    "import glob\n",
    "import itertools\n",
    "import random\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "from nixtla.data.scalers import Scaler\n",
    "from nixtla.data.tsdataset import TimeSeriesDataset\n",
    "from nixtla.data.tsloader_general import TimeSeriesLoader\n",
    "\n",
    "# Models\n",
    "from nixtla.models.nbeats.nbeats import Nbeats\n",
    "from nixtla.models.esrnn.esrnn import ESRNN\n",
    "from nixtla.models.tcn.tcn import TCN\n",
    "from nixtla.models.esrnn.rnn import RNN\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_default_mask_df(Y_df, ds_in_test, is_test):\n",
    "    # Creates outsample_mask\n",
    "    # train 1 validation 0\n",
    "    last_df = Y_df.copy()[['unique_id', 'ds']]\n",
    "    last_df.sort_values(by=['unique_id', 'ds'], inplace=True, ascending=False)\n",
    "    last_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    last_df = last_df.groupby('unique_id').head(ds_in_test)\n",
    "    last_df['sample_mask'] = 0\n",
    "\n",
    "    last_df = last_df[['unique_id', 'ds', 'sample_mask']]\n",
    "\n",
    "    mask_df = Y_df.merge(last_df, on=['unique_id', 'ds'], how='left')\n",
    "    mask_df['sample_mask'] = mask_df['sample_mask'].fillna(1)\n",
    "\n",
    "    mask_df = mask_df[['unique_id', 'ds', 'sample_mask']]\n",
    "    mask_df.sort_values(by=['unique_id', 'ds'], inplace=True)\n",
    "    mask_df['available_mask'] = 1\n",
    "\n",
    "    assert len(mask_df)==len(Y_df), \\\n",
    "        f'The mask_df length {len(mask_df)} is not equal to Y_df length {len(Y_df)}'\n",
    "\n",
    "    if is_test:\n",
    "        mask_df['sample_mask'] = 1 - mask_df['sample_mask']\n",
    "\n",
    "    return mask_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def scale_data(Y_df, X_df, mask_df, normalizer_y, normalizer_x):\n",
    "    y_shift = None\n",
    "    y_scale = None\n",
    "\n",
    "    # mask = mask.astype(int)\n",
    "    mask = mask_df['available_mask'].values * mask_df['sample_mask'].values\n",
    "    \n",
    "    if normalizer_y is not None:\n",
    "        scaler_y = Scaler(normalizer=normalizer_y)\n",
    "        Y_df['y'] = scaler_y.scale(x=Y_df['y'].values, mask=mask)\n",
    "    else:\n",
    "        scaler_y = None\n",
    "\n",
    "    if normalizer_x is not None:\n",
    "        X_cols = [col for col in X_df.columns if col not in ['unique_id','ds']]\n",
    "        for col in X_cols:\n",
    "            scaler_x = Scaler(normalizer=normalizer_x)\n",
    "            X_df[col] = scaler_x.scale(x=X_df[col].values, mask=mask)\n",
    "\n",
    "    return Y_df, X_df, scaler_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def train_val_split(len_series, offset, window_sampling_limit, n_val_weeks, ds_per_day):\n",
    "    last_ds = len_series - offset\n",
    "    first_ds = max(last_ds - window_sampling_limit, 0)\n",
    "\n",
    "    last_day = int(last_ds/ds_per_day)\n",
    "    first_day = int(first_ds/ds_per_day)\n",
    "\n",
    "    days = set(range(first_day, last_day)) # All days, to later get train days\n",
    "    # Sample weeks from here, -7 to avoid sampling from last week\n",
    "    # To not sample first week and have inputs\n",
    "    sampling_days = set(range(first_day + 7, last_day - 7))\n",
    "    validation_days = set({}) # Val days set\n",
    "    \n",
    "    # For loop for n of weeks in validation\n",
    "    for i in range(n_val_weeks):\n",
    "        # Sample random day, init of week\n",
    "        init_day = random.sample(sampling_days, 1)[0]\n",
    "        # Select days of sampled init of week\n",
    "        sampled_days = list(range(init_day, min(init_day+7, last_day)))\n",
    "        # Add days to validation days\n",
    "        validation_days.update(sampled_days)\n",
    "        # Remove days from sampling_days, including overlapping resulting previous week\n",
    "        days_to_remove = set(range(init_day-6, min(init_day+7, last_day)))\n",
    "        sampling_days = sampling_days.difference(days_to_remove)\n",
    "\n",
    "    train_days = days.difference(validation_days)\n",
    "\n",
    "    train_days = sorted(list(train_days))\n",
    "    validation_days = sorted(list(validation_days))\n",
    "\n",
    "    train_idx = []\n",
    "    for day in train_days:\n",
    "        hours_idx = range(day*ds_per_day,(day+1)*ds_per_day)\n",
    "        train_idx += hours_idx\n",
    "\n",
    "    val_idx = []\n",
    "    for day in validation_days:\n",
    "        hours_idx = range(day*ds_per_day,(day+1)*ds_per_day)\n",
    "        val_idx += hours_idx\n",
    "\n",
    "    assert all([idx < last_ds for idx in val_idx]), 'Leakage!!!!'\n",
    "    \n",
    "    return train_idx, val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_datasets(mc, Y_df, X_df, S_df, ds_in_test, shuffle_outsample, offset):\n",
    "    #TODO: offset not implemented\n",
    "    #TODO: shuffle_outsample\n",
    "\n",
    "    # n_timestamps_pred defines number of hours ahead to predict\n",
    "    # offset defines the shift of the data to simulate rolling window\n",
    "    # assert offset % n_timestamps_pred == 0, 'Avoid overlap of predictions, redefine n_timestamps_pred or offset' <-- restriccion poco general\n",
    "\n",
    "    #------------------------------------- Available and Validation Mask ------------------------------------#\n",
    "    # mask: 1 last_n_timestamps, 0 timestamps until last_n_timestamps\n",
    "    train_mask_df = get_default_mask_df(Y_df=Y_df, ds_in_test=ds_in_test, is_test=False)\n",
    "    outsample_mask_df = get_default_mask_df(Y_df=Y_df, ds_in_test=ds_in_test, is_test=True)\n",
    "\n",
    "    #---------------------------------------------- Scale Data ----------------------------------------------#\n",
    "    # Scale data # TODO: write sample_mask conditional/groupby(['unique_id]) scaling\n",
    "    Y_df, X_df, scaler_y = scale_data(Y_df=Y_df, X_df=X_df, mask_df=train_mask_df,\n",
    "                                      normalizer_y=mc['normalizer_y'], normalizer_x=mc['normalizer_x'])\n",
    "\n",
    "    #----------------------------------------- Declare Dataset and Loaders ----------------------------------#\n",
    "    train_ts_dataset = TimeSeriesDataset(Y_df=Y_df, X_df=X_df, S_df=S_df, mask_df=train_mask_df, verbose=True)\n",
    "    if ds_in_test == 0:\n",
    "        outsample_ts_dataset = None\n",
    "    else:\n",
    "        outsample_ts_dataset = TimeSeriesDataset(Y_df=Y_df, X_df=X_df, S_df=S_df, \n",
    "                                                 mask_df=outsample_mask_df, verbose=True)\n",
    "\n",
    "    return train_ts_dataset, outsample_ts_dataset, scaler_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def instantiate_loaders(mc, train_ts_dataset, outsample_ts_dataset):\n",
    "    train_ts_loader = TimeSeriesLoader(ts_dataset=train_ts_dataset,\n",
    "                                       model=mc['model'],\n",
    "                                       offset=0,\n",
    "                                       window_sampling_limit=int(mc['window_sampling_limit']),\n",
    "                                       input_size=int(mc['input_size_multiplier']*mc['output_size']),\n",
    "                                       output_size=int(mc['output_size']),\n",
    "                                       idx_to_sample_freq=int(mc['idx_to_sample_freq']),\n",
    "                                       batch_size=int(mc['batch_size']),\n",
    "                                       complete_inputs=mc['complete_inputs'],\n",
    "                                       n_series_per_batch=mc['n_series_per_batch'],\n",
    "                                       complete_sample=mc['complete_sample'],\n",
    "                                       shuffle=True)\n",
    "\n",
    "    if outsample_ts_dataset is not None:\n",
    "        val_ts_loader = TimeSeriesLoader(ts_dataset=outsample_ts_dataset,\n",
    "                                        model=mc['model'],\n",
    "                                        offset=0,\n",
    "                                        window_sampling_limit=int(mc['window_sampling_limit']),\n",
    "                                        input_size=int(mc['input_size_multiplier']*mc['output_size']),\n",
    "                                        output_size=int(mc['output_size']),\n",
    "                                        idx_to_sample_freq=mc['val_idx_to_sample_freq'],\n",
    "                                        batch_size=int(mc['batch_size']),\n",
    "                                        complete_inputs=mc['complete_inputs'],\n",
    "                                        n_series_per_batch=mc['n_series_per_batch'],\n",
    "                                        complete_sample=mc['complete_sample'],\n",
    "                                        shuffle=False)\n",
    "    else:\n",
    "        val_ts_loader = None\n",
    "\n",
    "    return train_ts_loader, val_ts_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def instantiate_nbeats(mc):\n",
    "    mc['n_hidden_list'] = len(mc['stack_types']) * [ mc['n_layers'][0]*[mc['n_hidden']] ]\n",
    "    model = Nbeats(input_size_multiplier=mc['input_size_multiplier'],\n",
    "                   output_size=int(mc['output_size']),\n",
    "                   shared_weights=mc['shared_weights'],\n",
    "                   initialization=mc['initialization'],\n",
    "                   activation=mc['activation'],\n",
    "                   stack_types=mc['stack_types'],\n",
    "                   n_blocks=mc['n_blocks'],\n",
    "                   n_layers=mc['n_layers'],\n",
    "                   n_hidden=mc['n_hidden_list'],\n",
    "                   n_harmonics=int(mc['n_harmonics']),\n",
    "                   n_polynomials=int(mc['n_polynomials']),\n",
    "                   x_s_n_hidden=int(mc['x_s_n_hidden']),\n",
    "                   exogenous_n_channels=int(mc['exogenous_n_channels']),\n",
    "                   batch_normalization = mc['batch_normalization'],\n",
    "                   dropout_prob_theta=mc['dropout_prob_theta'],\n",
    "                   dropout_prob_exogenous=mc['dropout_prob_exogenous'],\n",
    "                   learning_rate=float(mc['learning_rate']),\n",
    "                   lr_decay=float(mc['lr_decay']),\n",
    "                   n_lr_decay_steps=float(mc['n_lr_decay_steps']),\n",
    "                   weight_decay=mc['weight_decay'],\n",
    "                   l1_theta=mc['l1_theta'],\n",
    "                   n_iterations=int(mc['n_iterations']),\n",
    "                   early_stopping=int(mc['early_stopping']),\n",
    "                   loss=mc['loss'],\n",
    "                   loss_hypar=float(mc['loss_hypar']),\n",
    "                   val_loss=mc['val_loss'],\n",
    "                   frequency=mc['frequency'],\n",
    "                   seasonality=int(mc['seasonality']),\n",
    "                   random_seed=int(mc['random_seed']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def instantiate_esrnn(mc):    \n",
    "    model = ESRNN(input_size=int(mc['input_size_multiplier']*mc['output_size']),\n",
    "                  output_size=int(mc['output_size']),\n",
    "                  max_epochs=int(mc['max_epochs']),\n",
    "                  learning_rate=mc['learning_rate'],\n",
    "                  lr_scheduler_step_size=int(mc['lr_scheduler_step_size']),\n",
    "                  lr_decay=mc['lr_decay'],\n",
    "                  per_series_lr_multip=mc['per_series_lr_multip'],\n",
    "                  gradient_eps=mc['gradient_eps'],\n",
    "                  gradient_clipping_threshold=mc['gradient_clipping_threshold'],\n",
    "                  rnn_weight_decay=mc['rnn_weight_decay'],\n",
    "                  noise_std=mc['noise_std'],\n",
    "                  level_variability_penalty=mc['level_variability_penalty'],\n",
    "                  testing_percentile=mc['testing_percentile'],\n",
    "                  training_percentile=mc['training_percentile'],\n",
    "                  es_component=mc['es_component'],\n",
    "                  cell_type=mc['cell_type'],\n",
    "                  state_hsize=int(mc['state_hsize']),\n",
    "                  dilations=mc['dilations'],\n",
    "                  add_nl_layer=mc['add_nl_layer'],\n",
    "                  loss=mc['loss'],\n",
    "                  seasonality=mc['seasonality'],\n",
    "                  random_seed=int(mc['random_seed']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def instantiate_rnn(mc):\n",
    "    model = RNN(input_size=int(mc['input_size_multiplier']*mc['output_size']),\n",
    "                output_size=int(mc['output_size']),\n",
    "                max_epochs=int(mc['max_epochs']),\n",
    "                learning_rate=mc['learning_rate'],\n",
    "                lr_scheduler_step_size=int(mc['lr_scheduler_step_size']),\n",
    "                lr_decay=mc['lr_decay'],\n",
    "                gradient_eps=mc['gradient_eps'],\n",
    "                gradient_clipping_threshold=mc['gradient_clipping_threshold'],\n",
    "                rnn_weight_decay=mc['rnn_weight_decay'],\n",
    "                noise_std=mc['noise_std'],\n",
    "                testing_percentile=mc['testing_percentile'],\n",
    "                training_percentile=mc['training_percentile'],\n",
    "                cell_type=mc['cell_type'],\n",
    "                state_hsize=int(mc['state_hsize']),\n",
    "                dilations=mc['dilations'],\n",
    "                add_nl_layer=mc['add_nl_layer'],\n",
    "                loss=mc['loss'],\n",
    "                random_seed=int(mc['random_seed']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def instantiate_tcn(mc):\n",
    "    model = TCN(output_size=int(mc['output_size']),\n",
    "                n_channels=mc['n_channels'],\n",
    "                kernel_size=int(mc['kernel_size']),\n",
    "                initialization=mc['initialization'],\n",
    "                learning_rate=mc['learning_rate'],\n",
    "                lr_decay=mc['lr_decay'],\n",
    "                n_lr_decay_steps=mc['n_lr_decay_steps'],\n",
    "                weight_decay=mc['weight_decay'],\n",
    "                dropout_prob=mc['dropout_prob'],\n",
    "                n_iterations=int(mc['n_iterations']),\n",
    "                early_stopping=int(mc['early_stopping']),\n",
    "                loss=mc['loss'],\n",
    "                val_loss=mc['val_loss'],\n",
    "                frequency=mc['frequency'],\n",
    "                random_seed=int(mc['random_seed']),\n",
    "                seasonality=mc['seasonality'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def instantiate_model(mc):\n",
    "    MODEL_DICT = {'nbeats': instantiate_nbeats,\n",
    "                  'esrnn': instantiate_esrnn,\n",
    "                  'rnn': instantiate_rnn,\n",
    "                  'tcn': instantiate_tcn}\n",
    "    return MODEL_DICT[mc['model']](mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def model_fit_predict(mc, Y_df, X_df, S_df, ds_in_test, expected_fcds, shuffle_outsample):\n",
    "    #TODO: rolling forecast\n",
    "    #TODO: expected_fcds\n",
    "    \n",
    "    Y_df = Y_df.copy()\n",
    "    if X_df is not None:\n",
    "        X_df = X_df.copy()\n",
    "    if S_df is not None:\n",
    "        S_df = S_df.copy()\n",
    "\n",
    "    #----------------------------------------------- Datasets -----------------------------------------------#\n",
    "    train_ts_dataset, outsample_ts_dataset, scaler_y = create_datasets(mc=mc, Y_df=Y_df, X_df=X_df,\n",
    "                                                                       S_df=S_df,\n",
    "                                                                       ds_in_test=ds_in_test,\n",
    "                                                                       shuffle_outsample=shuffle_outsample,\n",
    "                                                                       offset=0)\n",
    "\n",
    "    #--------------------------------------- Instantiate, fit, predict ---------------------------------------#\n",
    "    train_ts_loader, val_ts_loader = instantiate_loaders(mc=mc, train_ts_dataset=train_ts_dataset,\n",
    "                                                         outsample_ts_dataset=outsample_ts_dataset)\n",
    "    model = instantiate_model(mc=mc)\n",
    "\n",
    "    # Val loader not implemented during training for ESRNN and RNN\n",
    "    if mc['model'] in ['nbeats', 'tcn']:\n",
    "        model.fit(train_ts_loader=train_ts_loader, val_ts_loader=val_ts_loader, verbose=True,\n",
    "                    eval_freq=mc['eval_freq'])\n",
    "        y_true, y_hat, mask = model.predict(ts_loader=val_ts_loader, return_decomposition=False)\n",
    "\n",
    "    elif mc['model'] in ['esrnn', 'rnn']:\n",
    "        model.fit(train_ts_loader=train_ts_loader, verbose=True, eval_freq=mc['eval_freq'])\n",
    "        y_true, y_hat, mask = model.predict(ts_loader=val_ts_loader, n_fcds=expected_fcds, eval_mode=True)\n",
    "\n",
    "    print(\"y_true.shape (#n_series, #n_fcds, #lt) \", y_true.shape)\n",
    "    print(\"y_hat.shape (#n_series, #n_fcds, #lt) \", y_hat.shape)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    assert y_true.shape[1] == expected_fcds, 'Error in fcds per serie.'\n",
    "    assert y_hat.shape[1] == expected_fcds, 'Error in fcds per serie.'\n",
    "    \n",
    "    meta_data = val_ts_loader.ts_dataset.meta_data\n",
    "\n",
    "    return y_true, y_hat, mask, meta_data, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def evaluate_model(mc, loss_function, Y_df, X_df, S_df, ds_in_test, expected_fcds, shuffle_outsample):\n",
    "    \n",
    "    # Some asserts due to work in progress\n",
    "    assert mc['normalizer_y'] is None, 'Scaling Y not iplemented (inverse Y missing for loss)'\n",
    "\n",
    "    n_series = Y_df['unique_id'].nunique()\n",
    "    if n_series > 1:\n",
    "        assert mc['normalizer_x'] is None, 'Data scaling not implemented with multiple time series'\n",
    "    assert shuffle_outsample == False, 'Shuffle outsample not implemented'\n",
    "\n",
    "    assert ds_in_test % mc['val_idx_to_sample_freq']==0, 'outsample size should be multiple of val_idx_to_sample_freq'\n",
    "\n",
    "    # Make predictions\n",
    "    start = time.time()\n",
    "    y_true, y_hat, mask, meta_data, model = model_fit_predict(mc=mc, Y_df=Y_df, X_df=X_df, \n",
    "                                                              S_df=S_df, ds_in_test=ds_in_test,\n",
    "                                                              expected_fcds=expected_fcds,\n",
    "                                                              shuffle_outsample=shuffle_outsample)\n",
    "    run_time = time.time() - start\n",
    "\n",
    "    # Evaluate predictions\n",
    "    loss = loss_function(y=y_true, y_hat=y_hat, weights=mask)\n",
    "\n",
    "    result =  {'loss': loss,\n",
    "               'mc': mc,\n",
    "               'y_true': y_true,\n",
    "               'y_hat': y_hat,\n",
    "               'trajectories': model.trajectories,\n",
    "               'run_time': run_time,\n",
    "               'status': STATUS_OK}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def hyperopt_tunning(space, hyperopt_iters, loss_function, Y_df, X_df, S_df, ds_in_test, expected_fcds,\n",
    "                     shuffle_outsample, save_trials=False):\n",
    "    trials = Trials()\n",
    "    fmin_objective = partial(evaluate_model, loss_function=loss_function, Y_df=Y_df, X_df=X_df, S_df=S_df,\n",
    "                             ds_in_test=ds_in_test,\n",
    "                             expected_fcds=expected_fcds,\n",
    "                             shuffle_outsample=shuffle_outsample)\n",
    "\n",
    "    fmin(fmin_objective, space=space, algo=tpe.suggest, max_evals=hyperopt_iters, trials=trials, verbose=True)\n",
    "\n",
    "    return trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nixtla.losses.numpy import mae, mape, smape, rmse, pinball_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space= {# Architecture parameters\n",
    "        'model':'nbeats',\n",
    "        'input_size_multiplier': hp.choice('input_size_multiplier', [7]),\n",
    "        'output_size': hp.choice('output_size', [24]),\n",
    "        'shared_weights': hp.choice('shared_weights', [False]),\n",
    "        'activation': hp.choice('activation', ['selu']),\n",
    "        'initialization':  hp.choice('initialization', ['glorot_normal','he_normal']),\n",
    "        'stack_types': hp.choice('stack_types', [2*['identity'],\n",
    "                                                    1*['identity']+1*['exogenous_tcn'],\n",
    "                                                    1*['exogenous_tcn']+1*['identity'] ]),\n",
    "        'n_blocks': hp.choice('n_blocks', [ [1, 1] ]),\n",
    "        'n_layers': hp.choice('n_layers', [ [2, 2] ]),\n",
    "        'n_hidden': hp.choice('n_hidden', [ 364 ]),\n",
    "        'n_harmonics': hp.choice('n_harmonics', [1]),\n",
    "        'n_polynomials': hp.choice('n_polynomials', [2]),\n",
    "        'exogenous_n_channels': hp.quniform('exogenous_n_channels', 1, 10, 1),\n",
    "        'x_s_n_hidden': hp.choice('x_s_n_hidden', [0]),\n",
    "        # Regularization and optimization parameters\n",
    "        'batch_normalization': hp.choice('batch_normalization', [False]),\n",
    "        'dropout_prob_theta': hp.uniform('dropout_prob_theta', 0, 0.5),\n",
    "        'dropout_prob_exogenous': hp.uniform('dropout_prob_exogenous', 0, 0.5),\n",
    "        'learning_rate': hp.loguniform('learning_rate', np.log(5e-4), np.log(0.001)),\n",
    "        'lr_decay': hp.uniform('lr_decay', 0.3, 0.5),\n",
    "        'n_lr_decay_steps': hp.choice('n_lr_decay_steps', [3]),\n",
    "        'weight_decay': hp.loguniform('weight_decay', np.log(5e-5), np.log(5e-3)),\n",
    "        'n_iterations': hp.choice('n_iterations', [100]), #[args.max_epochs]),\n",
    "        'early_stopping': hp.choice('early_stopping', [16]),\n",
    "        'eval_freq': hp.choice('eval_freq', [50]),\n",
    "        'n_val_weeks': hp.choice('n_val_weeks', [52*2]),\n",
    "        'loss': hp.choice('loss', ['MAE']),\n",
    "        'loss_hypar': hp.choice('loss_hypar', [0.5]),                \n",
    "        'val_loss': hp.choice('val_loss', ['MAE']), #[args.val_loss]),\n",
    "        'l1_theta': hp.choice('l1_theta', [0]),\n",
    "        # Data parameters\n",
    "        'normalizer_y': hp.choice('normalizer_y', [None]),\n",
    "        'normalizer_x': hp.choice('normalizer_x', ['median']),\n",
    "        'window_sampling_limit': hp.choice('window_sampling_limit', [100_000]),\n",
    "        'complete_inputs': hp.choice('complete_inputs', [False]),\n",
    "        'complete_sample': hp.choice('complete_sample', [False]),                \n",
    "        'frequency': hp.choice('frequency', ['H']),\n",
    "        'seasonality': hp.choice('seasonality', [24]),      \n",
    "        'idx_to_sample_freq': hp.choice('idx_to_sample_freq', [24]),\n",
    "        'val_idx_to_sample_freq': hp.choice('val_idx_to_sample_freq', [24]),\n",
    "        'batch_size': hp.choice('batch_size', [256]),\n",
    "        'n_series_per_batch': hp.choice('n_series_per_batch', [1]),\n",
    "        'random_seed': hp.quniform('random_seed', 10, 20, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = {'model':'nbeats',\n",
    "      # Architecture parameters\n",
    "      'input_size_multiplier': 7,\n",
    "      'output_size': 24,\n",
    "      'shared_weights': False,\n",
    "      'activation': 'selu',\n",
    "      'initialization': 'he_normal',\n",
    "      'stack_types': ['exogenous_tcn']+1*['identity'],\n",
    "      'n_blocks': [1, 1],\n",
    "      'n_layers': [2, 2],\n",
    "      'n_hidden': 364,\n",
    "      'n_polynomials': 2,\n",
    "      'n_harmonics': 1,\n",
    "      'exogenous_n_channels': 3,\n",
    "      'x_s_n_hidden': 0,\n",
    "      # Regularization and optimization parameters\n",
    "      'batch_normalization': False,\n",
    "      'dropout_prob_theta': 0.2,\n",
    "      'dropout_prob_exogenous': 0.2,\n",
    "      'learning_rate': 0.0005, #0.002,\n",
    "      'lr_decay': 0.64,\n",
    "      'n_lr_decay_steps': 3,\n",
    "      'weight_decay': 0.00015,\n",
    "      'n_iterations': 100,\n",
    "      'early_stopping': 8,\n",
    "      'eval_freq': 50,\n",
    "      'n_val_weeks': 52*2,\n",
    "      'loss': 'PINBALL',\n",
    "      'loss_hypar': 0.5, #0.49,\n",
    "      'val_loss': 'MAE',\n",
    "      'l1_theta': 0,\n",
    "      # Data parameters\n",
    "      'normalizer_y': None,\n",
    "      'normalizer_x': 'median',\n",
    "      'window_sampling_limit': 100_000,\n",
    "      'complete_inputs': False,\n",
    "      'complete_sample': False,\n",
    "      'frequency':'H',\n",
    "      'seasonality': 24,\n",
    "      'idx_to_sample_freq': 24,\n",
    "      'val_idx_to_sample_freq': 24,\n",
    "      'batch_size': 256,\n",
    "      'n_series_per_batch': 1,\n",
    "      'random_seed': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nixtla.data.datasets.epf import EPF, EPFInfo\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = ['NP']\n",
    "\n",
    "Y_df, X_df, S_df = EPF.load_groups(directory='../data', groups=dataset)\n",
    "\n",
    "plt.plot(Y_df.y.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Validation splits\n",
      "                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0.0         2018-12-18 2018-12-24 23:00:00\n",
      "          1.0         2013-01-01 2018-12-17 23:00:00\n",
      "Total data \t\t\t52416 time stamps\n",
      "Available percentage=100.0, \t52416 time stamps\n",
      "Insample  percentage=99.68, \t52248.0 time stamps\n",
      "Outsample percentage=0.32, \t168.0 time stamps\n",
      "\n",
      "\n",
      "Train Validation splits\n",
      "                              ds                    \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0.0         2013-01-01 2018-12-17 23:00:00\n",
      "          1.0         2018-12-18 2018-12-24 23:00:00\n",
      "Total data \t\t\t52416 time stamps\n",
      "Available percentage=100.0, \t52416 time stamps\n",
      "Insample  percentage=0.32, \t168.0 time stamps\n",
      "Outsample percentage=99.68, \t52248.0 time stamps\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "============================== Start fitting ==============================\n",
      "Step: 50, Time: 1.593, Insample PINBALL: 1.16853, Outsample MAE: 2.64359\n",
      "Step: 100, Time: 2.906, Insample PINBALL: 0.91871, Outsample MAE: 2.45845\n",
      "Step: 100, Time: 2.918, Insample PINBALL: 0.91871, Outsample MAE: 2.45845\n",
      "==============================  End fitting  ==============================\n",
      "\n",
      "\n",
      "y_true.shape (#n_series, #n_fcds, #lt)  (1, 7, 24)\n",
      "y_hat.shape (#n_series, #n_fcds, #lt)  (1, 7, 24)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 2.4584496,\n",
       " 'mc': {'model': 'nbeats',\n",
       "  'input_size_multiplier': 7,\n",
       "  'output_size': 24,\n",
       "  'shared_weights': False,\n",
       "  'activation': 'selu',\n",
       "  'initialization': 'he_normal',\n",
       "  'stack_types': ['exogenous_tcn', 'identity'],\n",
       "  'n_blocks': [1, 1],\n",
       "  'n_layers': [2, 2],\n",
       "  'n_hidden': 364,\n",
       "  'n_polynomials': 2,\n",
       "  'n_harmonics': 1,\n",
       "  'exogenous_n_channels': 3,\n",
       "  'x_s_n_hidden': 0,\n",
       "  'batch_normalization': False,\n",
       "  'dropout_prob_theta': 0.2,\n",
       "  'dropout_prob_exogenous': 0.2,\n",
       "  'learning_rate': 0.0005,\n",
       "  'lr_decay': 0.64,\n",
       "  'n_lr_decay_steps': 3,\n",
       "  'weight_decay': 0.00015,\n",
       "  'n_iterations': 100,\n",
       "  'early_stopping': 8,\n",
       "  'eval_freq': 50,\n",
       "  'n_val_weeks': 104,\n",
       "  'loss': 'PINBALL',\n",
       "  'loss_hypar': 0.5,\n",
       "  'val_loss': 'MAE',\n",
       "  'l1_theta': 0,\n",
       "  'normalizer_y': None,\n",
       "  'normalizer_x': 'median',\n",
       "  'window_sampling_limit': 100000,\n",
       "  'complete_inputs': False,\n",
       "  'complete_sample': False,\n",
       "  'frequency': 'H',\n",
       "  'seasonality': 24,\n",
       "  'idx_to_sample_freq': 24,\n",
       "  'val_idx_to_sample_freq': 24,\n",
       "  'batch_size': 256,\n",
       "  'n_series_per_batch': 1,\n",
       "  'random_seed': 10,\n",
       "  'n_hidden_list': [[364, 364], [364, 364]]},\n",
       " 'y_true': array([[[52.33, 51.02, 50.24, 49.42, 50.18, 52.89, 56.46, 71.25, 74.69,\n",
       "          72.06, 69.72, 67.63, 65.92, 66.08, 68.05, 69.94, 67.68, 65.96,\n",
       "          57.86, 55.12, 53.54, 52.55, 50.67, 48.69],\n",
       "         [49.55, 48.84, 48.18, 47.82, 48.65, 50.6 , 52.14, 54.25, 55.69,\n",
       "          55.27, 55.03, 55.32, 55.71, 55.68, 55.74, 56.31, 57.19, 56.71,\n",
       "          56.27, 55.2 , 54.34, 53.22, 51.67, 50.12],\n",
       "         [48.35, 48.08, 48.31, 47.36, 47.94, 50.62, 54.38, 57.84, 58.63,\n",
       "          57.53, 56.45, 56.31, 57.39, 57.21, 57.52, 57.81, 57.88, 57.2 ,\n",
       "          55.7 , 54.31, 52.25, 51.29, 50.  , 48.12],\n",
       "         [47.21, 46.42, 46.  , 46.12, 46.49, 49.97, 52.73, 55.65, 57.04,\n",
       "          57.13, 56.98, 56.04, 56.22, 55.78, 54.6 , 54.11, 54.25, 54.69,\n",
       "          54.21, 52.79, 52.05, 51.43, 50.07, 49.01],\n",
       "         [48.39, 47.72, 47.23, 46.6 , 46.94, 47.76, 48.41, 49.44, 50.29,\n",
       "          51.52, 52.56, 53.08, 52.99, 53.13, 52.93, 53.78, 55.04, 56.52,\n",
       "          57.07, 55.52, 53.05, 52.05, 51.09, 50.47],\n",
       "         [51.49, 50.83, 50.74, 50.14, 49.94, 50.46, 50.88, 51.37, 51.61,\n",
       "          52.22, 52.8 , 53.  , 53.11, 52.93, 52.93, 53.75, 55.99, 61.2 ,\n",
       "          61.2 , 57.42, 55.61, 53.99, 53.86, 52.32],\n",
       "         [51.09, 50.19, 48.98, 48.8 , 48.52, 49.8 , 50.05, 50.55, 52.33,\n",
       "          53.26, 53.14, 52.88, 53.03, 52.46, 52.44, 52.89, 53.26, 52.61,\n",
       "          51.28, 50.72, 49.86, 49.09, 49.02, 48.1 ]]], dtype=float32),\n",
       " 'y_hat': array([[[52.6044  , 51.991013, 52.064026, 51.684265, 52.459705,\n",
       "          54.163803, 58.15858 , 63.481514, 64.90835 , 63.446552,\n",
       "          62.6334  , 61.377365, 60.449863, 59.70226 , 59.278454,\n",
       "          59.968643, 60.36806 , 63.07062 , 62.263676, 59.88563 ,\n",
       "          57.6152  , 56.16086 , 54.419582, 52.347977],\n",
       "         [48.748512, 47.879684, 47.242077, 46.985443, 47.73363 ,\n",
       "          49.741367, 53.25952 , 58.28067 , 59.55043 , 58.722237,\n",
       "          58.124535, 56.871258, 56.297356, 55.784973, 55.35586 ,\n",
       "          55.97156 , 56.48526 , 58.58603 , 57.874043, 55.9602  ,\n",
       "          54.059036, 52.902493, 51.131863, 49.07437 ],\n",
       "         [50.496986, 49.664017, 49.38688 , 49.166786, 49.84528 ,\n",
       "          51.677315, 54.90398 , 58.967148, 59.483574, 59.090057,\n",
       "          58.62435 , 57.57142 , 56.986668, 56.329903, 56.131763,\n",
       "          56.67329 , 57.14411 , 59.087807, 58.26792 , 56.55292 ,\n",
       "          55.177574, 53.971798, 52.4641  , 50.869175],\n",
       "         [48.383324, 47.54959 , 47.629307, 47.250744, 48.07218 ,\n",
       "          49.60373 , 52.553753, 56.335598, 57.14523 , 56.103462,\n",
       "          55.615562, 54.689747, 53.8232  , 53.267345, 52.73877 ,\n",
       "          53.00882 , 53.90952 , 55.41579 , 54.858616, 53.115585,\n",
       "          51.802692, 51.173424, 49.976738, 48.397728],\n",
       "         [49.152973, 48.52775 , 48.15871 , 48.063988, 48.31959 ,\n",
       "          48.41511 , 49.58885 , 50.66266 , 51.355442, 52.283672,\n",
       "          52.368492, 52.22187 , 51.567017, 51.315224, 51.076263,\n",
       "          51.28726 , 52.35357 , 53.81866 , 53.51098 , 52.667004,\n",
       "          51.450695, 50.711685, 50.015213, 48.70076 ],\n",
       "         [50.33028 , 49.686977, 49.50124 , 49.281208, 49.50156 ,\n",
       "          49.702427, 51.068863, 52.322014, 52.873665, 53.394737,\n",
       "          53.484142, 53.688454, 52.84861 , 52.46266 , 52.46605 ,\n",
       "          52.931404, 53.876846, 55.565918, 55.29885 , 54.41801 ,\n",
       "          53.39577 , 52.570168, 51.99315 , 50.43498 ],\n",
       "         [52.776833, 52.01252 , 52.070656, 51.714977, 52.386692,\n",
       "          54.013973, 56.95339 , 60.807953, 61.63872 , 60.631138,\n",
       "          59.951347, 58.790596, 58.098732, 57.729023, 57.077328,\n",
       "          57.559   , 57.85454 , 59.540394, 59.318115, 57.52024 ,\n",
       "          56.169994, 55.2691  , 54.115448, 52.240395]]], dtype=float32),\n",
       " 'trajectories': {'iteration': [50, 100],\n",
       "  'train_loss': [1.1685256958007812, 0.918712854385376],\n",
       "  'val_loss': [2.6435857, 2.4584496]},\n",
       " 'run_time': 5.152025938034058,\n",
       " 'status': 'ok'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = evaluate_model(loss_function=mae, mc=mc, Y_df=Y_df, X_df=X_df, S_df=S_df, ds_in_test=7*24,\n",
    "                        expected_fcds=7, shuffle_outsample=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.009950 seconds\n",
      "INFO:hyperopt.tpe:TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Validation splits                              \n",
      "                              ds                     \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0.0         2016-12-27 2018-12-24 23:00:00\n",
      "          1.0         2013-01-01 2016-12-26 23:00:00\n",
      "Total data \t\t\t52416 time stamps                      \n",
      "Available percentage=100.0, \t52416 time stamps       \n",
      "Insample  percentage=66.67, \t34944.0 time stamps     \n",
      "Outsample percentage=33.33, \t17472.0 time stamps     \n",
      "Train Validation splits                              \n",
      "                              ds                     \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0.0         2013-01-01 2016-12-26 23:00:00\n",
      "          1.0         2016-12-27 2018-12-24 23:00:00\n",
      "Total data \t\t\t52416 time stamps                      \n",
      "Available percentage=100.0, \t52416 time stamps       \n",
      "Insample  percentage=33.33, \t17472.0 time stamps     \n",
      "Outsample percentage=66.67, \t34944.0 time stamps     \n",
      "============================== Start fitting ==============================\n",
      "Step: 50, Time: 1.262, Insample MAE: 2.14505, Outsample MAE: 2.24395\n",
      "Step: 100, Time: 2.562, Insample MAE: 1.57598, Outsample MAE: 2.10904\n",
      "Step: 100, Time: 2.581, Insample MAE: 1.57598, Outsample MAE: 2.10904\n",
      "==============================  End fitting  ==============================\n",
      "y_true.shape (#n_series, #n_fcds, #lt)               \n",
      "(1, 728, 24)                                         \n",
      "y_hat.shape (#n_series, #n_fcds, #lt)                \n",
      "(1, 728, 24)                                         \n",
      " 33%|      | 1/3 [00:02<00:05,  2.88s/trial, best loss: 2.1090352535247803]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.010448 seconds\n",
      "INFO:hyperopt.tpe:TPE using 1/1 trials with best loss 2.109035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Validation splits                                                        \n",
      "                              ds                                               \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0.0         2016-12-27 2018-12-24 23:00:00\n",
      "          1.0         2013-01-01 2016-12-26 23:00:00\n",
      "Total data \t\t\t52416 time stamps                                                \n",
      "Available percentage=100.0, \t52416 time stamps                                 \n",
      "Insample  percentage=66.67, \t34944.0 time stamps                               \n",
      "Outsample percentage=33.33, \t17472.0 time stamps                               \n",
      "Train Validation splits                                                        \n",
      "                              ds                                               \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0.0         2013-01-01 2016-12-26 23:00:00\n",
      "          1.0         2016-12-27 2018-12-24 23:00:00\n",
      "Total data \t\t\t52416 time stamps                                                \n",
      "Available percentage=100.0, \t52416 time stamps                                 \n",
      "Insample  percentage=33.33, \t17472.0 time stamps                               \n",
      "Outsample percentage=66.67, \t34944.0 time stamps                               \n",
      "============================== Start fitting ==============================    \n",
      "Step: 50, Time: 1.288, Insample MAE: 2.09179, Outsample MAE: 2.30470           \n",
      "Step: 100, Time: 2.567, Insample MAE: 1.56854, Outsample MAE: 2.16261          \n",
      "Step: 100, Time: 2.584, Insample MAE: 1.56854, Outsample MAE: 2.16261          \n",
      "==============================  End fitting  ==============================    \n",
      "y_true.shape (#n_series, #n_fcds, #lt)                                         \n",
      "(1, 728, 24)                                                                   \n",
      "y_hat.shape (#n_series, #n_fcds, #lt)                                          \n",
      "(1, 728, 24)                                                                   \n",
      " 67%|   | 2/3 [00:05<00:02,  2.89s/trial, best loss: 2.1090352535247803]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.010346 seconds\n",
      "INFO:hyperopt.tpe:TPE using 2/2 trials with best loss 2.109035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Validation splits                                                        \n",
      "                              ds                                               \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0.0         2016-12-27 2018-12-24 23:00:00\n",
      "          1.0         2013-01-01 2016-12-26 23:00:00\n",
      "Total data \t\t\t52416 time stamps                                                \n",
      "Available percentage=100.0, \t52416 time stamps                                 \n",
      "Insample  percentage=66.67, \t34944.0 time stamps                               \n",
      "Outsample percentage=33.33, \t17472.0 time stamps                               \n",
      "Train Validation splits                                                        \n",
      "                              ds                                               \n",
      "                             min                 max\n",
      "unique_id sample_mask                               \n",
      "NP        0.0         2013-01-01 2016-12-26 23:00:00\n",
      "          1.0         2016-12-27 2018-12-24 23:00:00\n",
      "Total data \t\t\t52416 time stamps                                                \n",
      "Available percentage=100.0, \t52416 time stamps                                 \n",
      "Insample  percentage=33.33, \t17472.0 time stamps                               \n",
      "Outsample percentage=66.67, \t34944.0 time stamps                               \n",
      "============================== Start fitting ==============================    \n",
      "Step: 50, Time: 1.298, Insample MAE: 1.95450, Outsample MAE: 2.31242           \n",
      "Step: 100, Time: 2.470, Insample MAE: 1.79829, Outsample MAE: 2.21255          \n",
      "Step: 100, Time: 2.488, Insample MAE: 1.79829, Outsample MAE: 2.21255          \n",
      "==============================  End fitting  ==============================    \n",
      "y_true.shape (#n_series, #n_fcds, #lt)                                         \n",
      "(1, 728, 24)                                                                   \n",
      "y_hat.shape (#n_series, #n_fcds, #lt)                                          \n",
      "(1, 728, 24)                                                                   \n",
      "100%|| 3/3 [00:08<00:00,  2.86s/trial, best loss: 2.1090352535247803]\n"
     ]
    }
   ],
   "source": [
    "trials = hyperopt_tunning(space=space, hyperopt_iters=3, loss_function=mae, Y_df=Y_df, X_df=X_df, S_df=S_df,\n",
    "                          ds_in_test=728*24, expected_fcds=728, shuffle_outsample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'state': 2,\n",
       "  'tid': 0,\n",
       "  'spec': None,\n",
       "  'result': {'loss': 2.1090352535247803,\n",
       "   'mc': {'activation': 'selu',\n",
       "    'batch_normalization': False,\n",
       "    'batch_size': 256,\n",
       "    'complete_inputs': False,\n",
       "    'complete_sample': False,\n",
       "    'dropout_prob_exogenous': 0.39855222459224665,\n",
       "    'dropout_prob_theta': 0.31257675761002873,\n",
       "    'early_stopping': 16,\n",
       "    'eval_freq': 50,\n",
       "    'exogenous_n_channels': 8.0,\n",
       "    'frequency': 'H',\n",
       "    'idx_to_sample_freq': 24,\n",
       "    'initialization': 'glorot_normal',\n",
       "    'input_size_multiplier': 7,\n",
       "    'l1_theta': 0,\n",
       "    'learning_rate': 0.0009481584850819662,\n",
       "    'loss': 'MAE',\n",
       "    'loss_hypar': 0.5,\n",
       "    'lr_decay': 0.42296909566330254,\n",
       "    'model': 'nbeats',\n",
       "    'n_blocks': (1, 1),\n",
       "    'n_harmonics': 1,\n",
       "    'n_hidden': 364,\n",
       "    'n_iterations': 100,\n",
       "    'n_layers': (2, 2),\n",
       "    'n_lr_decay_steps': 3,\n",
       "    'n_polynomials': 2,\n",
       "    'n_series_per_batch': 1,\n",
       "    'n_val_weeks': 104,\n",
       "    'normalizer_x': 'median',\n",
       "    'normalizer_y': None,\n",
       "    'output_size': 24,\n",
       "    'random_seed': 12.0,\n",
       "    'seasonality': 24,\n",
       "    'shared_weights': False,\n",
       "    'stack_types': ('identity', 'exogenous_tcn'),\n",
       "    'val_idx_to_sample_freq': 24,\n",
       "    'val_loss': 'MAE',\n",
       "    'weight_decay': 0.00034417280938200815,\n",
       "    'window_sampling_limit': 100000,\n",
       "    'x_s_n_hidden': 0,\n",
       "    'n_hidden_list': [[364, 364], [364, 364]]},\n",
       "   'y_true': array([[[24.08, 22.52, 20.13, ..., 28.37, 27.24, 25.73],\n",
       "           [26.45, 26.26, 26.24, ..., 30.65, 30.02, 29.37],\n",
       "           [29.26, 28.72, 28.29, ..., 30.01, 29.44, 28.76],\n",
       "           ...,\n",
       "           [48.39, 47.72, 47.23, ..., 52.05, 51.09, 50.47],\n",
       "           [51.49, 50.83, 50.74, ..., 53.99, 53.86, 52.32],\n",
       "           [51.09, 50.19, 48.98, ..., 49.09, 49.02, 48.1 ]]], dtype=float32),\n",
       "   'y_hat': array([[[25.45761 , 24.774536, 24.575064, ..., 27.94777 , 27.544935,\n",
       "            26.66758 ],\n",
       "           [25.58635 , 25.19694 , 24.811136, ..., 30.448666, 29.180763,\n",
       "            27.261547],\n",
       "           [28.90714 , 28.87173 , 28.393185, ..., 30.298903, 29.64627 ,\n",
       "            28.84135 ],\n",
       "           ...,\n",
       "           [49.27857 , 48.467083, 48.02083 , ..., 51.912067, 51.11186 ,\n",
       "            49.94359 ],\n",
       "           [51.225445, 50.16436 , 50.046627, ..., 53.5651  , 52.792572,\n",
       "            51.384205],\n",
       "           [54.07328 , 53.38898 , 52.76007 , ..., 53.17258 , 52.143246,\n",
       "            51.420265]]], dtype=float32),\n",
       "   'trajectories': {'iteration': [50, 100],\n",
       "    'train_loss': [2.145048141479492, 1.5759767293930054],\n",
       "    'val_loss': [2.243955, 2.1090353]},\n",
       "   'run_time': 2.8595709800720215,\n",
       "   'status': 'ok'},\n",
       "  'misc': {'tid': 0,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'activation': [0],\n",
       "    'batch_normalization': [0],\n",
       "    'batch_size': [0],\n",
       "    'complete_inputs': [0],\n",
       "    'complete_sample': [0],\n",
       "    'dropout_prob_exogenous': [0],\n",
       "    'dropout_prob_theta': [0],\n",
       "    'early_stopping': [0],\n",
       "    'eval_freq': [0],\n",
       "    'exogenous_n_channels': [0],\n",
       "    'frequency': [0],\n",
       "    'idx_to_sample_freq': [0],\n",
       "    'initialization': [0],\n",
       "    'input_size_multiplier': [0],\n",
       "    'l1_theta': [0],\n",
       "    'learning_rate': [0],\n",
       "    'loss': [0],\n",
       "    'loss_hypar': [0],\n",
       "    'lr_decay': [0],\n",
       "    'n_blocks': [0],\n",
       "    'n_harmonics': [0],\n",
       "    'n_hidden': [0],\n",
       "    'n_iterations': [0],\n",
       "    'n_layers': [0],\n",
       "    'n_lr_decay_steps': [0],\n",
       "    'n_polynomials': [0],\n",
       "    'n_series_per_batch': [0],\n",
       "    'n_val_weeks': [0],\n",
       "    'normalizer_x': [0],\n",
       "    'normalizer_y': [0],\n",
       "    'output_size': [0],\n",
       "    'random_seed': [0],\n",
       "    'seasonality': [0],\n",
       "    'shared_weights': [0],\n",
       "    'stack_types': [0],\n",
       "    'val_idx_to_sample_freq': [0],\n",
       "    'val_loss': [0],\n",
       "    'weight_decay': [0],\n",
       "    'window_sampling_limit': [0],\n",
       "    'x_s_n_hidden': [0]},\n",
       "   'vals': {'activation': [0],\n",
       "    'batch_normalization': [0],\n",
       "    'batch_size': [0],\n",
       "    'complete_inputs': [0],\n",
       "    'complete_sample': [0],\n",
       "    'dropout_prob_exogenous': [0.39855222459224665],\n",
       "    'dropout_prob_theta': [0.31257675761002873],\n",
       "    'early_stopping': [0],\n",
       "    'eval_freq': [0],\n",
       "    'exogenous_n_channels': [8.0],\n",
       "    'frequency': [0],\n",
       "    'idx_to_sample_freq': [0],\n",
       "    'initialization': [0],\n",
       "    'input_size_multiplier': [0],\n",
       "    'l1_theta': [0],\n",
       "    'learning_rate': [0.0009481584850819662],\n",
       "    'loss': [0],\n",
       "    'loss_hypar': [0],\n",
       "    'lr_decay': [0.42296909566330254],\n",
       "    'n_blocks': [0],\n",
       "    'n_harmonics': [0],\n",
       "    'n_hidden': [0],\n",
       "    'n_iterations': [0],\n",
       "    'n_layers': [0],\n",
       "    'n_lr_decay_steps': [0],\n",
       "    'n_polynomials': [0],\n",
       "    'n_series_per_batch': [0],\n",
       "    'n_val_weeks': [0],\n",
       "    'normalizer_x': [0],\n",
       "    'normalizer_y': [0],\n",
       "    'output_size': [0],\n",
       "    'random_seed': [12.0],\n",
       "    'seasonality': [0],\n",
       "    'shared_weights': [0],\n",
       "    'stack_types': [1],\n",
       "    'val_idx_to_sample_freq': [0],\n",
       "    'val_loss': [0],\n",
       "    'weight_decay': [0.00034417280938200815],\n",
       "    'window_sampling_limit': [0],\n",
       "    'x_s_n_hidden': [0]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2021, 3, 10, 20, 26, 47, 43000),\n",
       "  'refresh_time': datetime.datetime(2021, 3, 10, 20, 26, 49, 911000)},\n",
       " {'state': 2,\n",
       "  'tid': 1,\n",
       "  'spec': None,\n",
       "  'result': {'loss': 2.1626136302948,\n",
       "   'mc': {'activation': 'selu',\n",
       "    'batch_normalization': False,\n",
       "    'batch_size': 256,\n",
       "    'complete_inputs': False,\n",
       "    'complete_sample': False,\n",
       "    'dropout_prob_exogenous': 0.07928272318159507,\n",
       "    'dropout_prob_theta': 0.16946611264793504,\n",
       "    'early_stopping': 16,\n",
       "    'eval_freq': 50,\n",
       "    'exogenous_n_channels': 4.0,\n",
       "    'frequency': 'H',\n",
       "    'idx_to_sample_freq': 24,\n",
       "    'initialization': 'glorot_normal',\n",
       "    'input_size_multiplier': 7,\n",
       "    'l1_theta': 0,\n",
       "    'learning_rate': 0.0005101743923746086,\n",
       "    'loss': 'MAE',\n",
       "    'loss_hypar': 0.5,\n",
       "    'lr_decay': 0.4809224843423221,\n",
       "    'model': 'nbeats',\n",
       "    'n_blocks': (1, 1),\n",
       "    'n_harmonics': 1,\n",
       "    'n_hidden': 364,\n",
       "    'n_iterations': 100,\n",
       "    'n_layers': (2, 2),\n",
       "    'n_lr_decay_steps': 3,\n",
       "    'n_polynomials': 2,\n",
       "    'n_series_per_batch': 1,\n",
       "    'n_val_weeks': 104,\n",
       "    'normalizer_x': 'median',\n",
       "    'normalizer_y': None,\n",
       "    'output_size': 24,\n",
       "    'random_seed': 11.0,\n",
       "    'seasonality': 24,\n",
       "    'shared_weights': False,\n",
       "    'stack_types': ('identity', 'exogenous_tcn'),\n",
       "    'val_idx_to_sample_freq': 24,\n",
       "    'val_loss': 'MAE',\n",
       "    'weight_decay': 0.0005711238686149957,\n",
       "    'window_sampling_limit': 100000,\n",
       "    'x_s_n_hidden': 0,\n",
       "    'n_hidden_list': [[364, 364], [364, 364]]},\n",
       "   'y_true': array([[[24.08, 22.52, 20.13, ..., 28.37, 27.24, 25.73],\n",
       "           [26.45, 26.26, 26.24, ..., 30.65, 30.02, 29.37],\n",
       "           [29.26, 28.72, 28.29, ..., 30.01, 29.44, 28.76],\n",
       "           ...,\n",
       "           [48.39, 47.72, 47.23, ..., 52.05, 51.09, 50.47],\n",
       "           [51.49, 50.83, 50.74, ..., 53.99, 53.86, 52.32],\n",
       "           [51.09, 50.19, 48.98, ..., 49.09, 49.02, 48.1 ]]], dtype=float32),\n",
       "   'y_hat': array([[[25.700428, 25.079142, 24.205065, ..., 27.960693, 27.467272,\n",
       "            26.36878 ],\n",
       "           [26.163015, 25.260033, 25.172495, ..., 29.290796, 28.719456,\n",
       "            27.357595],\n",
       "           [29.405582, 28.773014, 28.42225 , ..., 30.673586, 30.169317,\n",
       "            29.208061],\n",
       "           ...,\n",
       "           [49.357655, 48.369812, 48.021957, ..., 51.757267, 51.153103,\n",
       "            50.085358],\n",
       "           [50.71163 , 48.95806 , 50.24946 , ..., 52.917694, 52.34991 ,\n",
       "            51.2899  ],\n",
       "           [53.36409 , 51.953674, 51.803837, ..., 55.158096, 53.5149  ,\n",
       "            51.98307 ]]], dtype=float32),\n",
       "   'trajectories': {'iteration': [50, 100],\n",
       "    'train_loss': [2.091794729232788, 1.5685380697250366],\n",
       "    'val_loss': [2.304705, 2.1626136]},\n",
       "   'run_time': 2.8668196201324463,\n",
       "   'status': 'ok'},\n",
       "  'misc': {'tid': 1,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'activation': [1],\n",
       "    'batch_normalization': [1],\n",
       "    'batch_size': [1],\n",
       "    'complete_inputs': [1],\n",
       "    'complete_sample': [1],\n",
       "    'dropout_prob_exogenous': [1],\n",
       "    'dropout_prob_theta': [1],\n",
       "    'early_stopping': [1],\n",
       "    'eval_freq': [1],\n",
       "    'exogenous_n_channels': [1],\n",
       "    'frequency': [1],\n",
       "    'idx_to_sample_freq': [1],\n",
       "    'initialization': [1],\n",
       "    'input_size_multiplier': [1],\n",
       "    'l1_theta': [1],\n",
       "    'learning_rate': [1],\n",
       "    'loss': [1],\n",
       "    'loss_hypar': [1],\n",
       "    'lr_decay': [1],\n",
       "    'n_blocks': [1],\n",
       "    'n_harmonics': [1],\n",
       "    'n_hidden': [1],\n",
       "    'n_iterations': [1],\n",
       "    'n_layers': [1],\n",
       "    'n_lr_decay_steps': [1],\n",
       "    'n_polynomials': [1],\n",
       "    'n_series_per_batch': [1],\n",
       "    'n_val_weeks': [1],\n",
       "    'normalizer_x': [1],\n",
       "    'normalizer_y': [1],\n",
       "    'output_size': [1],\n",
       "    'random_seed': [1],\n",
       "    'seasonality': [1],\n",
       "    'shared_weights': [1],\n",
       "    'stack_types': [1],\n",
       "    'val_idx_to_sample_freq': [1],\n",
       "    'val_loss': [1],\n",
       "    'weight_decay': [1],\n",
       "    'window_sampling_limit': [1],\n",
       "    'x_s_n_hidden': [1]},\n",
       "   'vals': {'activation': [0],\n",
       "    'batch_normalization': [0],\n",
       "    'batch_size': [0],\n",
       "    'complete_inputs': [0],\n",
       "    'complete_sample': [0],\n",
       "    'dropout_prob_exogenous': [0.07928272318159507],\n",
       "    'dropout_prob_theta': [0.16946611264793504],\n",
       "    'early_stopping': [0],\n",
       "    'eval_freq': [0],\n",
       "    'exogenous_n_channels': [4.0],\n",
       "    'frequency': [0],\n",
       "    'idx_to_sample_freq': [0],\n",
       "    'initialization': [0],\n",
       "    'input_size_multiplier': [0],\n",
       "    'l1_theta': [0],\n",
       "    'learning_rate': [0.0005101743923746086],\n",
       "    'loss': [0],\n",
       "    'loss_hypar': [0],\n",
       "    'lr_decay': [0.4809224843423221],\n",
       "    'n_blocks': [0],\n",
       "    'n_harmonics': [0],\n",
       "    'n_hidden': [0],\n",
       "    'n_iterations': [0],\n",
       "    'n_layers': [0],\n",
       "    'n_lr_decay_steps': [0],\n",
       "    'n_polynomials': [0],\n",
       "    'n_series_per_batch': [0],\n",
       "    'n_val_weeks': [0],\n",
       "    'normalizer_x': [0],\n",
       "    'normalizer_y': [0],\n",
       "    'output_size': [0],\n",
       "    'random_seed': [11.0],\n",
       "    'seasonality': [0],\n",
       "    'shared_weights': [0],\n",
       "    'stack_types': [1],\n",
       "    'val_idx_to_sample_freq': [0],\n",
       "    'val_loss': [0],\n",
       "    'weight_decay': [0.0005711238686149957],\n",
       "    'window_sampling_limit': [0],\n",
       "    'x_s_n_hidden': [0]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2021, 3, 10, 20, 26, 49, 928000),\n",
       "  'refresh_time': datetime.datetime(2021, 3, 10, 20, 26, 52, 803000)},\n",
       " {'state': 2,\n",
       "  'tid': 2,\n",
       "  'spec': None,\n",
       "  'result': {'loss': 2.2125489711761475,\n",
       "   'mc': {'activation': 'selu',\n",
       "    'batch_normalization': False,\n",
       "    'batch_size': 256,\n",
       "    'complete_inputs': False,\n",
       "    'complete_sample': False,\n",
       "    'dropout_prob_exogenous': 0.47460152810142975,\n",
       "    'dropout_prob_theta': 0.08083571074117674,\n",
       "    'early_stopping': 16,\n",
       "    'eval_freq': 50,\n",
       "    'exogenous_n_channels': 6.0,\n",
       "    'frequency': 'H',\n",
       "    'idx_to_sample_freq': 24,\n",
       "    'initialization': 'glorot_normal',\n",
       "    'input_size_multiplier': 7,\n",
       "    'l1_theta': 0,\n",
       "    'learning_rate': 0.000808760735227858,\n",
       "    'loss': 'MAE',\n",
       "    'loss_hypar': 0.5,\n",
       "    'lr_decay': 0.3888632291033679,\n",
       "    'model': 'nbeats',\n",
       "    'n_blocks': (1, 1),\n",
       "    'n_harmonics': 1,\n",
       "    'n_hidden': 364,\n",
       "    'n_iterations': 100,\n",
       "    'n_layers': (2, 2),\n",
       "    'n_lr_decay_steps': 3,\n",
       "    'n_polynomials': 2,\n",
       "    'n_series_per_batch': 1,\n",
       "    'n_val_weeks': 104,\n",
       "    'normalizer_x': 'median',\n",
       "    'normalizer_y': None,\n",
       "    'output_size': 24,\n",
       "    'random_seed': 14.0,\n",
       "    'seasonality': 24,\n",
       "    'shared_weights': False,\n",
       "    'stack_types': ('identity', 'exogenous_tcn'),\n",
       "    'val_idx_to_sample_freq': 24,\n",
       "    'val_loss': 'MAE',\n",
       "    'weight_decay': 0.003662106573734474,\n",
       "    'window_sampling_limit': 100000,\n",
       "    'x_s_n_hidden': 0,\n",
       "    'n_hidden_list': [[364, 364], [364, 364]]},\n",
       "   'y_true': array([[[24.08, 22.52, 20.13, ..., 28.37, 27.24, 25.73],\n",
       "           [26.45, 26.26, 26.24, ..., 30.65, 30.02, 29.37],\n",
       "           [29.26, 28.72, 28.29, ..., 30.01, 29.44, 28.76],\n",
       "           ...,\n",
       "           [48.39, 47.72, 47.23, ..., 52.05, 51.09, 50.47],\n",
       "           [51.49, 50.83, 50.74, ..., 53.99, 53.86, 52.32],\n",
       "           [51.09, 50.19, 48.98, ..., 49.09, 49.02, 48.1 ]]], dtype=float32),\n",
       "   'y_hat': array([[[25.936666, 25.608173, 24.69487 , ..., 28.172169, 27.711943,\n",
       "            26.546307],\n",
       "           [26.169123, 25.820889, 25.357214, ..., 29.844625, 29.12422 ,\n",
       "            27.69376 ],\n",
       "           [29.518242, 28.673445, 28.422207, ..., 30.83832 , 30.207775,\n",
       "            29.037611],\n",
       "           ...,\n",
       "           [50.00639 , 49.70723 , 48.68282 , ..., 52.301075, 51.72886 ,\n",
       "            50.819473],\n",
       "           [51.97569 , 50.794952, 50.809483, ..., 54.15977 , 53.51538 ,\n",
       "            52.286552],\n",
       "           [53.554356, 53.13308 , 52.42099 , ..., 54.801888, 53.955917,\n",
       "            52.3107  ]]], dtype=float32),\n",
       "   'trajectories': {'iteration': [50, 100],\n",
       "    'train_loss': [1.9545038938522339, 1.7982944250106812],\n",
       "    'val_loss': [2.3124177, 2.212549]},\n",
       "   'run_time': 2.7671051025390625,\n",
       "   'status': 'ok'},\n",
       "  'misc': {'tid': 2,\n",
       "   'cmd': ('domain_attachment', 'FMinIter_Domain'),\n",
       "   'workdir': None,\n",
       "   'idxs': {'activation': [2],\n",
       "    'batch_normalization': [2],\n",
       "    'batch_size': [2],\n",
       "    'complete_inputs': [2],\n",
       "    'complete_sample': [2],\n",
       "    'dropout_prob_exogenous': [2],\n",
       "    'dropout_prob_theta': [2],\n",
       "    'early_stopping': [2],\n",
       "    'eval_freq': [2],\n",
       "    'exogenous_n_channels': [2],\n",
       "    'frequency': [2],\n",
       "    'idx_to_sample_freq': [2],\n",
       "    'initialization': [2],\n",
       "    'input_size_multiplier': [2],\n",
       "    'l1_theta': [2],\n",
       "    'learning_rate': [2],\n",
       "    'loss': [2],\n",
       "    'loss_hypar': [2],\n",
       "    'lr_decay': [2],\n",
       "    'n_blocks': [2],\n",
       "    'n_harmonics': [2],\n",
       "    'n_hidden': [2],\n",
       "    'n_iterations': [2],\n",
       "    'n_layers': [2],\n",
       "    'n_lr_decay_steps': [2],\n",
       "    'n_polynomials': [2],\n",
       "    'n_series_per_batch': [2],\n",
       "    'n_val_weeks': [2],\n",
       "    'normalizer_x': [2],\n",
       "    'normalizer_y': [2],\n",
       "    'output_size': [2],\n",
       "    'random_seed': [2],\n",
       "    'seasonality': [2],\n",
       "    'shared_weights': [2],\n",
       "    'stack_types': [2],\n",
       "    'val_idx_to_sample_freq': [2],\n",
       "    'val_loss': [2],\n",
       "    'weight_decay': [2],\n",
       "    'window_sampling_limit': [2],\n",
       "    'x_s_n_hidden': [2]},\n",
       "   'vals': {'activation': [0],\n",
       "    'batch_normalization': [0],\n",
       "    'batch_size': [0],\n",
       "    'complete_inputs': [0],\n",
       "    'complete_sample': [0],\n",
       "    'dropout_prob_exogenous': [0.47460152810142975],\n",
       "    'dropout_prob_theta': [0.08083571074117674],\n",
       "    'early_stopping': [0],\n",
       "    'eval_freq': [0],\n",
       "    'exogenous_n_channels': [6.0],\n",
       "    'frequency': [0],\n",
       "    'idx_to_sample_freq': [0],\n",
       "    'initialization': [0],\n",
       "    'input_size_multiplier': [0],\n",
       "    'l1_theta': [0],\n",
       "    'learning_rate': [0.000808760735227858],\n",
       "    'loss': [0],\n",
       "    'loss_hypar': [0],\n",
       "    'lr_decay': [0.3888632291033679],\n",
       "    'n_blocks': [0],\n",
       "    'n_harmonics': [0],\n",
       "    'n_hidden': [0],\n",
       "    'n_iterations': [0],\n",
       "    'n_layers': [0],\n",
       "    'n_lr_decay_steps': [0],\n",
       "    'n_polynomials': [0],\n",
       "    'n_series_per_batch': [0],\n",
       "    'n_val_weeks': [0],\n",
       "    'normalizer_x': [0],\n",
       "    'normalizer_y': [0],\n",
       "    'output_size': [0],\n",
       "    'random_seed': [14.0],\n",
       "    'seasonality': [0],\n",
       "    'shared_weights': [0],\n",
       "    'stack_types': [1],\n",
       "    'val_idx_to_sample_freq': [0],\n",
       "    'val_loss': [0],\n",
       "    'weight_decay': [0.003662106573734474],\n",
       "    'window_sampling_limit': [0],\n",
       "    'x_s_n_hidden': [0]}},\n",
       "  'exp_key': None,\n",
       "  'owner': None,\n",
       "  'version': 0,\n",
       "  'book_time': datetime.datetime(2021, 3, 10, 20, 26, 52, 819000),\n",
       "  'refresh_time': datetime.datetime(2021, 3, 10, 20, 26, 55, 594000)}]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials.trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
