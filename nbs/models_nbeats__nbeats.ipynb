{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.nbeats.nbeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "\n",
    "import torch as t\n",
    "from torch import optim\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n",
    "from nixtla.models.nbeats.nbeats_model import NBeats, NBeatsBlock, IdentityBasis, TrendBasis, SeasonalityBasis\n",
    "from nixtla.models.nbeats.nbeats_model import ExogenousBasisInterpretable, ExogenousBasisWavenet, ExogenousBasisTCN\n",
    "from nixtla.losses.pytorch import MAPELoss, MASELoss, SMAPELoss, MSELoss, MAELoss, PinballLoss, QuadraticBarrierLoss\n",
    "from nixtla.losses.numpy import mae, mse, mape, smape, rmse, pinball_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def init_weights(module, initialization):\n",
    "    if type(module) == t.nn.Linear:\n",
    "        if initialization == 'orthogonal':\n",
    "            t.nn.init.orthogonal_(module.weight)\n",
    "        elif initialization == 'he_uniform':\n",
    "            t.nn.init.kaiming_uniform_(module.weight)\n",
    "        elif initialization == 'he_normal':\n",
    "            t.nn.init.kaiming_normal_(module.weight)\n",
    "        elif initialization == 'glorot_uniform':\n",
    "            t.nn.init.xavier_uniform_(module.weight)\n",
    "        elif initialization == 'glorot_normal':\n",
    "            t.nn.init.xavier_normal_(module.weight)\n",
    "        elif initialization == 'lecun_normal':\n",
    "            pass #t.nn.init.normal_(module.weight, 0.0, std=1/np.sqrt(module.weight.numel()))\n",
    "        else:\n",
    "            assert 1<0, f'Initialization {initialization} not found'\n",
    "\n",
    "class Nbeats(object):\n",
    "    \"\"\"\n",
    "    Future documentation\n",
    "    \"\"\"\n",
    "    SEASONALITY_BLOCK = 'seasonality'\n",
    "    TREND_BLOCK = 'trend'\n",
    "    IDENTITY_BLOCK = 'identity'\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_size_multiplier,\n",
    "                 output_size,\n",
    "                 shared_weights,\n",
    "                 activation,\n",
    "                 initialization,\n",
    "                 stack_types,\n",
    "                 n_blocks,\n",
    "                 n_layers,\n",
    "                 n_hidden,\n",
    "                 n_harmonics,\n",
    "                 n_polynomials,\n",
    "                 exogenous_n_channels,\n",
    "                 include_var_dict,\n",
    "                 t_cols,\n",
    "                 batch_normalization,\n",
    "                 dropout_prob_theta,\n",
    "                 dropout_prob_exogenous,\n",
    "                 x_s_n_hidden,\n",
    "                 learning_rate,\n",
    "                 lr_decay,\n",
    "                 n_lr_decay_steps,\n",
    "                 weight_decay,\n",
    "                 l1_theta,\n",
    "                 n_iterations,\n",
    "                 early_stopping,\n",
    "                 loss,\n",
    "                 loss_hypar,\n",
    "                 val_loss,\n",
    "                 frequency,\n",
    "                 random_seed,\n",
    "                 seasonality,\n",
    "                 device=None):\n",
    "        super(Nbeats, self).__init__()\n",
    "        \"\"\"\n",
    "        N-BEATS model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_size_multiplier: int\n",
    "            Multiplier to get insample size.\n",
    "            Insample size = input_size_multiplier * output_size\n",
    "        output_size: int\n",
    "            Forecast horizon.\n",
    "        shared_weights: bool\n",
    "            If True, repeats first block.\n",
    "        activation: str\n",
    "            Activation function.\n",
    "            An item from ['relu', 'softplus', 'tanh', 'selu', 'lrelu', 'prelu', 'sigmoid'].\n",
    "        initialization: str\n",
    "            Initialization function.\n",
    "            An item from ['orthogonal', 'he_uniform', 'glorot_uniform', 'glorot_normal', 'lecun_normal'].\n",
    "        stack_types: List[str]\n",
    "            List of stack types.\n",
    "            Subset from ['seasonality', 'trend', 'identity', 'exogenous', 'exogenous_tcn', 'exogenous_wavenet'].\n",
    "        n_blocks: List[int]\n",
    "            Number of blocks for each stack type.\n",
    "            Note that len(n_blocks) = len(stack_types).\n",
    "        n_layers: List[int]\n",
    "            Number of layers for each stack type.\n",
    "            Note that len(n_layers) = len(stack_types).\n",
    "        n_hidden: List[List[int]]\n",
    "            Structure of hidden layers for each stack type.\n",
    "            Each internal list should contain the number of units of each hidden layer.\n",
    "            Note that len(n_hidden) = len(stack_types).\n",
    "        n_harmonics: List[int]\n",
    "            Number of harmonic terms for each stack type.\n",
    "            Note that len(n_harmonics) = len(stack_types).\n",
    "        n_polynomials: List[int]\n",
    "            Number of polynomial terms for each stack type.\n",
    "            Note that len(n_polynomials) = len(stack_types).\n",
    "        exogenous_n_channels:\n",
    "            Exogenous channels for non-interpretable exogenous basis.\n",
    "        include_var_dict: Dict[str, List[int]]\n",
    "            Exogenous terms to add.\n",
    "        t_cols: List\n",
    "            Ordered list of ['y'] + X_cols + ['available_mask', 'sample_mask'].\n",
    "            Can be taken from the dataset.\n",
    "        batch_normalization: bool\n",
    "            Whether perform batch normalization. \n",
    "        dropout_prob_theta: float\n",
    "            Float between (0, 1).\n",
    "            Dropout for Nbeats basis.\n",
    "        dropout_prob_exogenous: float\n",
    "            Float between (0, 1).\n",
    "            Dropout for exogenous basis.\n",
    "        x_s_n_hidden: int\n",
    "            Number of encoded static features to calculate.\n",
    "        learning_rate: float\n",
    "            Learning rate between (0, 1).\n",
    "        lr_decay: float\n",
    "            Decreasing multiplier for the learning rate.\n",
    "        n_lr_decay_steps: int\n",
    "            Period for each lerning rate decay.\n",
    "        weight_decay: float\n",
    "            L2 penalty for optimizer.\n",
    "        l1_theta: float\n",
    "            L1 regularization for the loss function.\n",
    "        n_iterations: int\n",
    "            Number of training steps.\n",
    "        early_stopping: int\n",
    "            Early stopping interations.\n",
    "        loss: str\n",
    "            Loss to optimize.\n",
    "            An item from ['MAPE', 'MASE', 'SMAPE', 'MSE', 'MAE', 'PINBALL', 'PINBALL2'].\n",
    "        loss_hypar:\n",
    "            Hyperparameter for chosen loss.\n",
    "        val_loss:\n",
    "            Validation loss.\n",
    "            An item from ['MAPE', 'MASE', 'SMAPE', 'RMSE', 'MAE', 'PINBALL'].\n",
    "        frequency: str\n",
    "            Time series frequency.\n",
    "        random_seed: int\n",
    "            random_seed for pseudo random pytorch initializer and\n",
    "            numpy random generator.\n",
    "        seasonality: int\n",
    "            Time series seasonality.\n",
    "            Usually 7 for daily data, 12 for monthly data and 4 for weekly data.\n",
    "        device: Optional[str]\n",
    "            If None checks 'cuda' availability.\n",
    "            An item from ['cuda', 'cpu'].\n",
    "        \"\"\"\n",
    "\n",
    "        if activation == 'selu': initialization = 'lecun_normal'\n",
    "\n",
    "        #------------------------ Model Attributes ------------------------#\n",
    "        # Architecture parameters\n",
    "        self.input_size = int(input_size_multiplier*output_size)\n",
    "        self.output_size = output_size\n",
    "        self.shared_weights = shared_weights\n",
    "        self.activation = activation\n",
    "        self.initialization = initialization\n",
    "        self.stack_types = stack_types\n",
    "        self.n_blocks = n_blocks\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_harmonics = n_harmonics\n",
    "        self.n_polynomials = n_polynomials\n",
    "        self.exogenous_n_channels = exogenous_n_channels\n",
    "\n",
    "        # Regularization and optimization parameters\n",
    "        self.batch_normalization = batch_normalization\n",
    "        self.dropout_prob_theta = dropout_prob_theta\n",
    "        self.dropout_prob_exogenous = dropout_prob_exogenous\n",
    "        self.x_s_n_hidden = x_s_n_hidden\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lr_decay = lr_decay\n",
    "        self.n_lr_decay_steps = n_lr_decay_steps\n",
    "        self.weight_decay = weight_decay\n",
    "        self.n_iterations = n_iterations\n",
    "        self.early_stopping = early_stopping\n",
    "        self.loss = loss\n",
    "        self.loss_hypar = loss_hypar\n",
    "        self.val_loss = val_loss\n",
    "        self.l1_theta = l1_theta\n",
    "        self.l1_conv = 1e-3 # Not a hyperparameter\n",
    "        self.random_seed = random_seed\n",
    "\n",
    "        # Data parameters\n",
    "        self.frequency = frequency\n",
    "        self.seasonality = seasonality        \n",
    "        self.include_var_dict = include_var_dict\n",
    "        self.t_cols = t_cols\n",
    "        #self.scaler = scaler\n",
    "\n",
    "        if device is None:\n",
    "            device = 'cuda' if t.cuda.is_available() else 'cpu'\n",
    "        self.device = device\n",
    "\n",
    "        self._is_instantiated = False\n",
    "\n",
    "    def create_stack(self):\n",
    "        if self.include_var_dict is not None:\n",
    "            x_t_n_inputs = self.output_size * int(sum([len(x) for x in self.include_var_dict.values()]))\n",
    "            \n",
    "            # Correction because week_day only adds 1 no output_size\n",
    "            if len(self.include_var_dict['week_day'])>0:\n",
    "                x_t_n_inputs = x_t_n_inputs - self.output_size + 1 \n",
    "        else:\n",
    "            x_t_n_inputs = self.input_size\n",
    "        \n",
    "        #------------------------ Model Definition ------------------------#\n",
    "        block_list = []\n",
    "        self.blocks_regularizer = []\n",
    "        for i in range(len(self.stack_types)):\n",
    "            #print(f'| --  Stack {self.stack_types[i]} (#{i})')\n",
    "            for block_id in range(self.n_blocks[i]):\n",
    "                \n",
    "                # Batch norm only on first block\n",
    "                if (len(block_list)==0) and (self.batch_normalization):\n",
    "                    batch_normalization_block = True\n",
    "                else:\n",
    "                    batch_normalization_block = False\n",
    "                \n",
    "                # Dummy of regularizer in block. Override with 1 if exogenous_block\n",
    "                self.blocks_regularizer += [0]\n",
    "\n",
    "                # Shared weights\n",
    "                if self.shared_weights and block_id>0:\n",
    "                    nbeats_block = block_list[-1]\n",
    "                else:\n",
    "                    if self.stack_types[i] == 'seasonality':\n",
    "                        nbeats_block = NBeatsBlock(x_t_n_inputs = x_t_n_inputs,\n",
    "                                                   x_s_n_inputs = self.n_x_s,\n",
    "                                                   x_s_n_hidden= self.x_s_n_hidden,\n",
    "                                                   theta_n_dim=4 * int(\n",
    "                                                        np.ceil(self.n_harmonics / 2 * self.output_size) - (self.n_harmonics - 1)),\n",
    "                                                   basis=SeasonalityBasis(harmonics=self.n_harmonics,\n",
    "                                                                          backcast_size=self.input_size,\n",
    "                                                                          forecast_size=self.output_size),\n",
    "                                                   n_layers=self.n_layers[i],\n",
    "                                                   theta_n_hidden=self.n_hidden[i],\n",
    "                                                   include_var_dict=self.include_var_dict,\n",
    "                                                   t_cols=self.t_cols,\n",
    "                                                   batch_normalization=batch_normalization_block,\n",
    "                                                   dropout_prob=self.dropout_prob_theta,\n",
    "                                                   activation=self.activation)\n",
    "                    elif self.stack_types[i] == 'trend':\n",
    "                        nbeats_block = NBeatsBlock(x_t_n_inputs = x_t_n_inputs,\n",
    "                                                   x_s_n_inputs = self.n_x_s,\n",
    "                                                   x_s_n_hidden= self.x_s_n_hidden,\n",
    "                                                   theta_n_dim=2 * (self.n_polynomials + 1),\n",
    "                                                   basis=TrendBasis(degree_of_polynomial=self.n_polynomials,\n",
    "                                                                            backcast_size=self.input_size,\n",
    "                                                                            forecast_size=self.output_size),\n",
    "                                                   n_layers=self.n_layers[i],\n",
    "                                                   theta_n_hidden=self.n_hidden[i],\n",
    "                                                   include_var_dict=self.include_var_dict,\n",
    "                                                   t_cols=self.t_cols,\n",
    "                                                   batch_normalization=batch_normalization_block,\n",
    "                                                   dropout_prob=self.dropout_prob_theta,\n",
    "                                                   activation=self.activation)\n",
    "                    elif self.stack_types[i] == 'identity':\n",
    "                        nbeats_block = NBeatsBlock(x_t_n_inputs = x_t_n_inputs,\n",
    "                                                   x_s_n_inputs = self.n_x_s,\n",
    "                                                   x_s_n_hidden= self.x_s_n_hidden,\n",
    "                                                   theta_n_dim=self.input_size + self.output_size,\n",
    "                                                   basis=IdentityBasis(backcast_size=self.input_size,\n",
    "                                                                       forecast_size=self.output_size),\n",
    "                                                   n_layers=self.n_layers[i],\n",
    "                                                   theta_n_hidden=self.n_hidden[i],\n",
    "                                                   include_var_dict=self.include_var_dict,\n",
    "                                                   t_cols=self.t_cols,\n",
    "                                                   batch_normalization=batch_normalization_block,\n",
    "                                                   dropout_prob=self.dropout_prob_theta,\n",
    "                                                   activation=self.activation)\n",
    "                    elif self.stack_types[i] == 'exogenous':\n",
    "                        nbeats_block = NBeatsBlock(x_t_n_inputs = x_t_n_inputs,\n",
    "                                                   x_s_n_inputs = self.n_x_s,\n",
    "                                                   x_s_n_hidden= self.x_s_n_hidden,\n",
    "                                                   theta_n_dim=2*self.n_x_t,\n",
    "                                                   basis=ExogenousBasisInterpretable(),\n",
    "                                                   n_layers=self.n_layers[i],\n",
    "                                                   theta_n_hidden=self.n_hidden[i],\n",
    "                                                   include_var_dict=self.include_var_dict,\n",
    "                                                   t_cols=self.t_cols,\n",
    "                                                   batch_normalization=batch_normalization_block,\n",
    "                                                   dropout_prob=self.dropout_prob_theta,\n",
    "                                                   activation=self.activation)\n",
    "                    elif self.stack_types[i] == 'exogenous_tcn':\n",
    "                        nbeats_block = NBeatsBlock(x_t_n_inputs = x_t_n_inputs,\n",
    "                                                   x_s_n_inputs = self.n_x_s,\n",
    "                                                   x_s_n_hidden = self.x_s_n_hidden,\n",
    "                                                   theta_n_dim = 2*(self.exogenous_n_channels),\n",
    "                                                   basis= ExogenousBasisTCN(self.exogenous_n_channels, self.n_x_t),\n",
    "                                                   n_layers=self.n_layers[i],\n",
    "                                                   theta_n_hidden=self.n_hidden[i],\n",
    "                                                   include_var_dict=self.include_var_dict,\n",
    "                                                   t_cols=self.t_cols,\n",
    "                                                   batch_normalization=batch_normalization_block,\n",
    "                                                   dropout_prob=self.dropout_prob_theta,\n",
    "                                                   activation=self.activation)\n",
    "                    elif self.stack_types[i] == 'exogenous_wavenet':\n",
    "                        nbeats_block = NBeatsBlock(x_t_n_inputs = x_t_n_inputs,\n",
    "                                                   x_s_n_inputs = self.n_x_s,\n",
    "                                                   x_s_n_hidden= self.x_s_n_hidden,\n",
    "                                                   theta_n_dim=2*(self.exogenous_n_channels),\n",
    "                                                   basis=ExogenousBasisWavenet(self.exogenous_n_channels, self.n_x_t),\n",
    "                                                   n_layers=self.n_layers[i],\n",
    "                                                   theta_n_hidden=self.n_hidden[i],\n",
    "                                                   include_var_dict=self.include_var_dict,\n",
    "                                                   t_cols=self.t_cols,\n",
    "                                                   batch_normalization=batch_normalization_block,\n",
    "                                                   dropout_prob=self.dropout_prob_theta,\n",
    "                                                   activation=self.activation)\n",
    "                        self.blocks_regularizer[-1] = 1\n",
    "                    else:\n",
    "                        assert 1<0, f'Block type not found!'\n",
    "                # Select type of evaluation and apply it to all layers of block\n",
    "                init_function = partial(init_weights, initialization=self.initialization)                                             \n",
    "                nbeats_block.layers.apply(init_function)\n",
    "                #print(f'     | -- {nbeats_block}')\n",
    "                block_list.append(nbeats_block)\n",
    "        return block_list\n",
    "\n",
    "    def __loss_fn(self, loss_name: str):\n",
    "        def loss(x, loss_hypar, forecast, target, mask):\n",
    "            if loss_name == 'MAPE':\n",
    "                return MAPELoss(y=target, y_hat=forecast, mask=mask) + \\\n",
    "                       self.loss_l1_conv_layers() + self.loss_l1_theta()\n",
    "            elif loss_name == 'MASE':\n",
    "                return MASELoss(y=target, y_hat=forecast, y_insample=x, seasonality=loss_hypar, mask=mask) + \\\n",
    "                       self.loss_l1_conv_layers() + self.loss_l1_theta()\n",
    "            elif loss_name == 'SMAPE':\n",
    "                return SMAPELoss(y=target, y_hat=forecast, mask=mask) + \\\n",
    "                       self.loss_l1_conv_layers() + self.loss_l1_theta()\n",
    "            elif loss_name == 'MSE':\n",
    "                return MSELoss(y=target, y_hat=forecast, mask=mask) + \\\n",
    "                       self.loss_l1_conv_layers() + self.loss_l1_theta()\n",
    "            elif loss_name == 'MAE':\n",
    "                return MAELoss(y=target, y_hat=forecast, mask=mask) + \\\n",
    "                       self.loss_l1_conv_layers() + self.loss_l1_theta()\n",
    "            elif loss_name == 'PINBALL':\n",
    "                return PinballLoss(y=target, y_hat=forecast, mask=mask, tau=loss_hypar) + \\\n",
    "                       self.loss_l1_conv_layers() + self.loss_l1_theta()\n",
    "            elif loss_name == 'PINBALL2':\n",
    "                return PinballLoss(y=target, y_hat=forecast, mask=mask, tau=0.5) + \\\n",
    "                       self.loss_l1_conv_layers() + self.loss_l1_theta() + \\\n",
    "                       QuadraticBarrierLoss(z=(-forecast), tau=loss_hypar) # To induce forecast positivity\n",
    "            else:\n",
    "                raise Exception(f'Unknown loss function: {loss_name}')\n",
    "        return loss\n",
    "\n",
    "    def __val_loss_fn(self, loss_name='MAE'):\n",
    "        #TODO: mase not implemented\n",
    "        def loss(forecast, target, weights):\n",
    "            if loss_name == 'MAPE':\n",
    "                return mape(y=target, y_hat=forecast, weights=weights)\n",
    "            elif loss_name == 'SMAPE':\n",
    "                return smape(y=target, y_hat=forecast, weights=weights)\n",
    "            elif loss_name == 'MSE':\n",
    "                return mse(y=target, y_hat=forecast, weights=weights)\n",
    "            elif loss_name == 'RMSE':\n",
    "                return rmse(y=target, y_hat=forecast, weights=weights)\n",
    "            elif loss_name == 'MAE':\n",
    "                return mae(y=target, y_hat=forecast, weights=weights)\n",
    "            elif loss_name == 'PINBALL':\n",
    "                return pinball_loss(y=target, y_hat=forecast, weights=weights, tau=0.5)\n",
    "            else:\n",
    "                raise Exception(f'Unknown loss function: {loss_name}')\n",
    "        return loss\n",
    "    \n",
    "    def loss_l1_conv_layers(self):\n",
    "        loss_l1 = 0\n",
    "        for i, indicator in enumerate(self.blocks_regularizer):\n",
    "            if indicator:\n",
    "                loss_l1 += self.l1_conv * t.sum(t.abs(self.model.blocks[i].basis.weight))\n",
    "        return loss_l1\n",
    "    \n",
    "    def loss_l1_theta(self):\n",
    "        loss_l1 = 0\n",
    "        for block in self.model.blocks:\n",
    "            for layer in block.modules():\n",
    "                if isinstance(layer, t.nn.Linear):\n",
    "                    loss_l1 += self.l1_theta * layer.weight.abs().sum()\n",
    "        return loss_l1\n",
    "\n",
    "    def to_tensor(self, x: np.ndarray) -> t.Tensor:\n",
    "        tensor = t.as_tensor(x, dtype=t.float32).to(self.device)\n",
    "        return tensor\n",
    "\n",
    "    def fit(self, train_ts_loader, val_ts_loader=None, n_iterations=None, verbose=True, eval_steps=1):\n",
    "        # TODO: Indexes hardcoded, information duplicated in train and val datasets\n",
    "        assert (self.input_size)==train_ts_loader.input_size, \\\n",
    "            f'model input_size {self.input_size} data input_size {train_ts_loader.input_size}'\n",
    "\n",
    "        # Random Seeds (model initialization)\n",
    "        t.manual_seed(self.random_seed)\n",
    "        np.random.seed(self.random_seed)\n",
    "        random.seed(self.random_seed) #TODO: interaccion rara con window_sampling de validacion\n",
    "\n",
    "        # Attributes of ts_dataset\n",
    "        self.n_x_t, self.n_x_s = train_ts_loader.get_n_variables()\n",
    "\n",
    "        # Instantiate model\n",
    "        if not self._is_instantiated:\n",
    "            block_list = self.create_stack()\n",
    "            self.model = NBeats(t.nn.ModuleList(block_list)).to(self.device)\n",
    "            self._is_instantiated = True\n",
    "\n",
    "        # Overwrite n_iterations and train datasets\n",
    "        if n_iterations is None:\n",
    "            n_iterations = self.n_iterations\n",
    "\n",
    "        lr_decay_steps = n_iterations // self.n_lr_decay_steps\n",
    "        if lr_decay_steps == 0:\n",
    "            lr_decay_steps = 1\n",
    "\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=lr_decay_steps, gamma=self.lr_decay)\n",
    "        training_loss_fn = self.__loss_fn(self.loss)\n",
    "        validation_loss_fn = self.__val_loss_fn(self.val_loss) #Uses numpy losses\n",
    "\n",
    "        print('\\n')\n",
    "        print('='*30+' Start fitting '+'='*30)\n",
    "\n",
    "        #self.loss_dict = {} # Restart self.loss_dict\n",
    "        start = time.time()\n",
    "        self.trajectories = {'iteration':[],'train_loss':[], 'val_loss':[]}\n",
    "        self.final_insample_loss = None\n",
    "        self.final_outsample_loss = None\n",
    "        \n",
    "        # Training Loop\n",
    "        early_stopping_counter = 0\n",
    "        best_val_loss = np.inf\n",
    "        best_state_dict = copy.deepcopy(self.model.state_dict())\n",
    "        break_flag = False\n",
    "        iteration = 0\n",
    "        epoch = 0\n",
    "        while (iteration < n_iterations) and (not break_flag):\n",
    "            epoch +=1\n",
    "            for batch in iter(train_ts_loader):\n",
    "                iteration += 1\n",
    "                if (iteration > n_iterations) or (break_flag):\n",
    "                    continue\n",
    "\n",
    "                self.model.train()\n",
    "                # Parse batch\n",
    "                insample_y     = self.to_tensor(batch['insample_y'])\n",
    "                insample_x     = self.to_tensor(batch['insample_x'])\n",
    "                insample_mask  = self.to_tensor(batch['insample_mask'])\n",
    "                outsample_x    = self.to_tensor(batch['outsample_x'])\n",
    "                outsample_y    = self.to_tensor(batch['outsample_y'])\n",
    "                outsample_mask = self.to_tensor(batch['outsample_mask'])\n",
    "                s_matrix       = self.to_tensor(batch['s_matrix'])\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                forecast   = self.model(x_s=s_matrix, insample_y=insample_y, \n",
    "                                        insample_x_t=insample_x, outsample_x_t=outsample_x,\n",
    "                                        insample_mask=insample_mask)\n",
    "\n",
    "                training_loss = training_loss_fn(x=insample_y, loss_hypar=self.loss_hypar, forecast=forecast,\n",
    "                                                 target=outsample_y, mask=outsample_mask)\n",
    "\n",
    "                # Protection to exploding gradients\n",
    "                # if np.isnan(float(training_loss)):\n",
    "                #    break\n",
    "                if not np.isnan(float(training_loss)):\n",
    "                    training_loss.backward()\n",
    "                    t.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    early_stopping_counter = self.early_stopping\n",
    "\n",
    "                lr_scheduler.step()\n",
    "                if (iteration % eval_steps == 0):\n",
    "                    display_string = 'Step: {}, Time: {:03.3f}, Insample {}: {:.5f}'.format(iteration,\n",
    "                                                                                            time.time()-start,\n",
    "                                                                                            self.loss,\n",
    "                                                                                            training_loss.cpu().data.numpy())\n",
    "                    self.trajectories['iteration'].append(iteration)\n",
    "                    self.trajectories['train_loss'].append(np.float(training_loss.cpu().data.numpy()))\n",
    "\n",
    "                    if val_ts_loader is not None:\n",
    "                        loss = self.evaluate_performance(ts_loader=val_ts_loader, \n",
    "                                                         validation_loss_fn=validation_loss_fn)\n",
    "                        display_string += \", Outsample {}: {:.5f}\".format(self.val_loss, loss)\n",
    "                        self.trajectories['val_loss'].append(loss)\n",
    "\n",
    "                        if self.early_stopping:\n",
    "                            if loss < best_val_loss:\n",
    "                                # Save current model if improves outsample loss\n",
    "                                best_state_dict = copy.deepcopy(self.model.state_dict())\n",
    "                                best_insample_loss = training_loss.cpu().data.numpy()\n",
    "                                early_stopping_counter = 0\n",
    "                                best_val_loss = loss\n",
    "                            else:\n",
    "                                early_stopping_counter += 1\n",
    "                            if early_stopping_counter >= self.early_stopping:\n",
    "                                break_flag = True\n",
    "                    \n",
    "                    print(display_string)\n",
    "\n",
    "                    self.model.train()\n",
    "\n",
    "                if break_flag:\n",
    "                    print('\\n')\n",
    "                    print(19*'-',' Stopped training by early stopping', 19*'-')\n",
    "                    self.model.load_state_dict(best_state_dict)\n",
    "                    break\n",
    "\n",
    "        #End of fitting\n",
    "        if n_iterations >0:\n",
    "            # This is batch loss!\n",
    "            self.final_insample_loss = np.float(training_loss.cpu().data.numpy()) if not break_flag else best_insample_loss \n",
    "            string = 'Step: {}, Time: {:03.3f}, Insample {}: {:.5f}'.format(iteration,\n",
    "                                                                            time.time()-start,\n",
    "                                                                            self.loss,\n",
    "                                                                            self.final_insample_loss)\n",
    "            if val_ts_loader is not None:\n",
    "                self.final_outsample_loss = self.evaluate_performance(ts_loader=val_ts_loader, \n",
    "                                                                      validation_loss_fn=validation_loss_fn)\n",
    "                string += \", Outsample {}: {:.5f}\".format(self.val_loss, self.final_outsample_loss)\n",
    "            print(string)\n",
    "            print('='*30+'  End fitting  '+'='*30)\n",
    "            print('\\n')\n",
    "\n",
    "    def predict(self, ts_loader, X_test=None, eval_mode=False, return_decomposition=False):\n",
    "        self.model.eval()\n",
    "        assert not ts_loader.shuffle, 'ts_loader must have shuffle as False.'\n",
    "\n",
    "        forecasts = []\n",
    "        block_forecasts = []\n",
    "        outsample_ys = []\n",
    "        outsample_masks = []\n",
    "        with t.no_grad():\n",
    "            for batch in iter(ts_loader):\n",
    "                insample_y     = self.to_tensor(batch['insample_y'])\n",
    "                insample_x     = self.to_tensor(batch['insample_x'])\n",
    "                insample_mask  = self.to_tensor(batch['insample_mask'])\n",
    "                outsample_x    = self.to_tensor(batch['outsample_x'])\n",
    "                s_matrix       = self.to_tensor(batch['s_matrix'])\n",
    "\n",
    "                forecast, block_forecast = self.model(insample_y=insample_y, insample_x_t=insample_x,\n",
    "                                                      insample_mask=insample_mask, outsample_x_t=outsample_x,\n",
    "                                                      x_s=s_matrix, return_decomposition=True) # always return, then use or not\n",
    "                forecasts.append(forecast.cpu().data.numpy())\n",
    "                block_forecasts.append(block_forecast.cpu().data.numpy())\n",
    "                outsample_ys.append(batch['outsample_y'])\n",
    "                outsample_masks.append(batch['outsample_mask'])\n",
    "\n",
    "        forecasts = np.vstack(forecasts)\n",
    "        block_forecasts = np.vstack(block_forecasts)\n",
    "        outsample_ys = np.vstack(outsample_ys)\n",
    "        outsample_masks = np.vstack(outsample_masks)\n",
    "\n",
    "        self.model.train()\n",
    "        if eval_mode:\n",
    "            if return_decomposition:\n",
    "                return outsample_ys, forecasts, block_forecasts, outsample_masks\n",
    "            else:\n",
    "                return outsample_ys, forecasts, outsample_masks\n",
    "\n",
    "        # Pandas wrangling\n",
    "        frequency = ts_loader.get_frequency()\n",
    "        unique_ids = ts_loader.get_meta_data_col('unique_id')\n",
    "        last_ds = ts_loader.get_meta_data_col('last_ds') #TODO: ajustar of offset\n",
    "\n",
    "        # Predictions for panel\n",
    "        Y_hat_panel = pd.DataFrame(columns=['unique_id', 'ds'])\n",
    "        for i, unique_id in enumerate(unique_ids):\n",
    "            Y_hat_id = pd.DataFrame([unique_id]*self.output_size, columns=[\"unique_id\"])\n",
    "            ds = pd.date_range(start=last_ds[i], periods=self.output_size+1, freq=frequency)\n",
    "            Y_hat_id[\"ds\"] = ds[1:]\n",
    "            Y_hat_panel = Y_hat_panel.append(Y_hat_id, sort=False).reset_index(drop=True)\n",
    "\n",
    "        Y_hat_panel['y_hat'] = forecasts.flatten()\n",
    "\n",
    "        if X_test is not None:\n",
    "            Y_hat_panel = X_test.merge(Y_hat_panel, on=['unique_id', 'ds'], how='left')\n",
    "        \n",
    "        return Y_hat_panel\n",
    "\n",
    "    def evaluate_performance(self, ts_loader, validation_loss_fn):\n",
    "        self.model.eval()\n",
    "\n",
    "        target, forecast, outsample_mask = self.predict(ts_loader=ts_loader, eval_mode=True)\n",
    "\n",
    "        complete_loss = validation_loss_fn(target=target, forecast=forecast, weights=outsample_mask)\n",
    "\n",
    "        self.model.train()\n",
    "        return complete_loss\n",
    "\n",
    "    def save(self, model_dir, model_id, state_dict = None):\n",
    "    \n",
    "        if not os.path.exists(model_dir):\n",
    "            os.makedirs(model_dir)\n",
    "\n",
    "        if state_dict is None:\n",
    "            state_dict = self.model.state_dict()\n",
    "\n",
    "        model_file = os.path.join(model_dir, f\"model_{model_id}.model\")\n",
    "        print('Saving model to:\\n {}'.format(model_file)+'\\n')\n",
    "        t.save({'model_state_dict': state_dict}, model_file)\n",
    "\n",
    "    def load(self, model_dir, model_id):\n",
    "\n",
    "        model_file = os.path.join(model_dir, f\"model_{model_id}.model\")\n",
    "        path = Path(model_file)\n",
    "\n",
    "        assert path.is_file(), 'No model_*.model file found in this path!'\n",
    "\n",
    "        print('Loading model from:\\n {}'.format(model_file)+'\\n')\n",
    "\n",
    "        checkpoint = t.load(model_file, map_location=self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model.to(self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = {# Architecture parameters\n",
    "      'model': 'nbeats',\n",
    "      'input_size_multiplier': 7,\n",
    "      'output_size': 24,\n",
    "      'shared_weights': False,\n",
    "      'activation': 'selu',\n",
    "      'initialization': 'he_normal',\n",
    "      'stack_types': ['exogenous_tcn']+1*['identity'],\n",
    "      'n_blocks': [1, 1],\n",
    "      'n_layers': [2, 2],\n",
    "      'n_hidden': 364,\n",
    "      'n_polynomials': 2,\n",
    "      'n_harmonics': 1,\n",
    "      'exogenous_n_channels': 3,\n",
    "      'x_s_n_hidden': 0,\n",
    "      # Regularization and optimization parameters\n",
    "      'batch_normalization': False,\n",
    "      'dropout_prob_theta': 0.2,\n",
    "      'dropout_prob_exogenous': 0.2,\n",
    "      'learning_rate': 0.0005, #0.002,\n",
    "      'lr_decay': 0.64,\n",
    "      'n_lr_decay_steps': 3,\n",
    "      'weight_decay': 0.00015,\n",
    "      'n_iterations': 100,\n",
    "      'early_stopping': 8,\n",
    "      'eval_steps': 50,\n",
    "      'n_val_weeks': 52*2,\n",
    "      'loss': 'MAE',\n",
    "      'loss_hypar': 0.5, #0.49,\n",
    "      'val_loss': 'MAE',\n",
    "      'l1_theta': 0,\n",
    "      # Data parameters\n",
    "      'normalizer_y': None,\n",
    "      'normalizer_x': 'median',\n",
    "      'window_sampling_limit': 500_000,\n",
    "      'complete_inputs': False,\n",
    "      'frequency':'H',\n",
    "      'seasonality': 24,\n",
    "      'idx_to_sample_freq': 24,\n",
    "      'incl_pr1': True,\n",
    "      'incl_pr2': True,\n",
    "      'incl_pr3': True,\n",
    "      'incl_pr7': True,\n",
    "      'incl_ex1_0': True,\n",
    "      'incl_ex1_1': True,\n",
    "      'incl_ex1_7': True,\n",
    "      'incl_ex2_0': True,\n",
    "      'incl_ex2_1': True,\n",
    "      'incl_ex2_7': True,\n",
    "      'incl_day': True,\n",
    "      'batch_size': 256,\n",
    "      'random_seed': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nixtla.data.datasets.epf import EPF, EPFInfo\n",
    "from nixtla.experiments.utils import prepare_dataset, instantiate_nbeats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = ['NP']\n",
    "\n",
    "Y_df, X_df, S_df = EPF.load_groups(directory='../data', groups=dataset)\n",
    "\n",
    "plt.plot(Y_df.y.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc, train_ts_dataset, outsample_ts_dataset, scaler_y = prepare_dataset(mc, Y_df, X_df, S_df, 728*24, False, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts_loader, val_ts_loader, _ = instantiate_nbeats(mc, train_ts_dataset, outsample_ts_dataset, scaler_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Nbeats(input_size_multiplier=mc['input_size_multiplier'],\n",
    "                output_size=int(mc['output_size']),\n",
    "                shared_weights=mc['shared_weights'],\n",
    "                initialization=mc['initialization'],\n",
    "                activation=mc['activation'],\n",
    "                stack_types=mc['stack_types'],\n",
    "                n_blocks=mc['n_blocks'],\n",
    "                n_layers=mc['n_layers'],\n",
    "                n_hidden=mc['n_hidden'],\n",
    "                n_harmonics=int(mc['n_harmonics']),\n",
    "                n_polynomials=int(mc['n_polynomials']),\n",
    "                x_s_n_hidden=int(mc['x_s_n_hidden']),\n",
    "                exogenous_n_channels=int(mc['exogenous_n_channels']),\n",
    "                include_var_dict=mc['include_var_dict'],\n",
    "                t_cols=mc['t_cols'],\n",
    "                batch_normalization = mc['batch_normalization'],\n",
    "                dropout_prob_theta=mc['dropout_prob_theta'],\n",
    "                dropout_prob_exogenous=mc['dropout_prob_exogenous'],\n",
    "                learning_rate=float(mc['learning_rate']),\n",
    "                lr_decay=float(mc['lr_decay']),\n",
    "                n_lr_decay_steps=float(mc['n_lr_decay_steps']),\n",
    "                weight_decay=mc['weight_decay'],\n",
    "                l1_theta=mc['l1_theta'],\n",
    "                n_iterations=int(mc['n_iterations']),\n",
    "                early_stopping=int(mc['early_stopping']),\n",
    "                #scaler_y=scaler_y,\n",
    "                loss=mc['loss'],\n",
    "                loss_hypar=float(mc['loss_hypar']),\n",
    "                val_loss=mc['val_loss'],\n",
    "                frequency=mc['frequency'],\n",
    "                seasonality=int(mc['seasonality']),\n",
    "                random_seed=int(mc['random_seed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "============================== Start fitting ==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/federicogarza2/anaconda3/envs/nixtla/lib/python3.7/site-packages/ipykernel_launcher.py:478: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50, Time: 4.328, Insample MAE: 1.80093, Outsample MAE: 2.20582\n",
      "Step: 100, Time: 8.811, Insample MAE: 1.55490, Outsample MAE: 2.09442\n",
      "Step: 102, Time: 8.915, Insample MAE: 1.55490, Outsample MAE: 2.09442\n",
      "==============================  End fitting  ==============================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/federicogarza2/anaconda3/envs/nixtla/lib/python3.7/site-packages/ipykernel_launcher.py:511: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_ts_loader=train_ts_loader, val_ts_loader=val_ts_loader, eval_steps=mc['eval_steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_split, y_hat_split, y_hat_decomposed, mask_split = model.predict(ts_loader=val_ts_loader, eval_mode=True, return_decomposition=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fae61de6190>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hola = y_hat_decomposed[700]\n",
    "plt.plot(hola[0], label='exogenous')\n",
    "plt.plot(hola[1], label='identity')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
