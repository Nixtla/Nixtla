{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.esrnn.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESRNN utils data\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Batch():\n",
    "    def __init__(self, mc, y, last_ds, categories, idxs):\n",
    "        # Parse Model config\n",
    "        exogenous_size = mc.exogenous_size\n",
    "        device = mc.device\n",
    "\n",
    "        # y: time series values\n",
    "        n = len(y)\n",
    "        y = np.float32(y)\n",
    "        self.idxs = torch.LongTensor(idxs).to(device)\n",
    "        self.y = y\n",
    "        if (self.y.shape[1] > mc.max_series_length):\n",
    "            y = y[:, -mc.max_series_length:]\n",
    "        self.y = torch.tensor(y).float()\n",
    "\n",
    "        # last_ds: last time for prediction purposes\n",
    "        self.last_ds = last_ds\n",
    "\n",
    "        # categories: exogenous categoric data\n",
    "        if exogenous_size >0:\n",
    "            self.categories = np.zeros((len(idxs), exogenous_size))\n",
    "            cols_idx = np.array([mc.category_to_idx[category] for category in categories])\n",
    "            rows_idx = np.array(range(len(cols_idx)))\n",
    "            self.categories[rows_idx, cols_idx] = 1\n",
    "            self.categories = torch.from_numpy(self.categories).float()\n",
    "\n",
    "        self.y = self.y.to(device)\n",
    "        self.categories = self.categories.to(device)\n",
    "\n",
    "\n",
    "class Iterator(object):\n",
    "    \"\"\" Time Series Iterator.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mc: ModelConfig object\n",
    "        ModelConfig object with inherited hyperparameters:\n",
    "        batch_size, and exogenous_size, from the ESRNN\n",
    "        initialization.\n",
    "    X: array, shape (n_unique_id, 3)\n",
    "        Panel array with unique_id, last date stamp and\n",
    "        exogenous variable.\n",
    "    y: array, shape (n_unique_id, n_time)\n",
    "        Panel array in wide format with unique_id, last\n",
    "        date stamp and time series values.\n",
    "    Returns\n",
    "    ----------\n",
    "    self : object\n",
    "        Iterator method get_batch() returns a batch of time\n",
    "        series objects defined by the Batch class.\n",
    "    \"\"\"\n",
    "    def __init__(self, mc, X, y, weights=None):\n",
    "        if weights is not None:\n",
    "            assert len(weights)==len(X)\n",
    "            train_ids = np.where(weights==1)[0]\n",
    "            self.X = X[train_ids,:]\n",
    "            self.y = y[train_ids,:]\n",
    "        else:\n",
    "            self.X = X\n",
    "            self.y = y\n",
    "        assert len(X)==len(y)\n",
    "\n",
    "        # Parse Model config\n",
    "        self.mc = mc\n",
    "        self.batch_size = mc.batch_size\n",
    "\n",
    "        self.unique_idxs = np.unique(self.X[:, 0])\n",
    "        assert len(self.unique_idxs)==len(self.X)\n",
    "        self.n_series = len(self.unique_idxs)\n",
    "\n",
    "        #assert self.batch_size <= self.n_series\n",
    "\n",
    "        # Initialize batch iterator\n",
    "        self.b = 0\n",
    "        self.n_batches = int(np.ceil(self.n_series / self.batch_size))\n",
    "        shuffle = list(range(self.n_series))\n",
    "        self.sort_key = {'unique_id': [self.unique_idxs[i] for i in shuffle],\n",
    "                                         'sort_key': shuffle}\n",
    "\n",
    "    def update_batch_size(self, new_batch_size):\n",
    "        self.batch_size = new_batch_size\n",
    "        assert self.batch_size <= self.n_series\n",
    "        self.n_batches = int(np.ceil(self.n_series / self.batch_size))\n",
    "\n",
    "    def shuffle_dataset(self, random_seed=1):\n",
    "        \"\"\"Return the examples in the dataset in order, or shuffled.\"\"\"\n",
    "        # Random Seed\n",
    "        np.random.seed(random_seed)\n",
    "        self.random_seed = random_seed\n",
    "        shuffle = np.random.choice(self.n_series, self.n_series, replace=False)\n",
    "        self.X = self.X[shuffle]\n",
    "        self.y = self.y[shuffle]\n",
    "\n",
    "        old_sort_key = self.sort_key['sort_key']\n",
    "        old_unique_idxs = self.sort_key['unique_id']\n",
    "        self.sort_key = {'unique_id': [old_unique_idxs[i] for i in shuffle],\n",
    "                                         'sort_key': [old_sort_key[i] for i in shuffle]}\n",
    "\n",
    "    def get_trim_batch(self, unique_id):\n",
    "        if unique_id==None:\n",
    "            # Compute the indexes of the minibatch.\n",
    "            first = (self.b * self.batch_size)\n",
    "            last = min((first + self.batch_size), self.n_series)\n",
    "        else:\n",
    "            # Obtain unique_id index\n",
    "            assert unique_id in self.sort_key['unique_id'], \"unique_id, not fitted\"\n",
    "            first = self.sort_key['unique_id'].index(unique_id)\n",
    "            last = first+1\n",
    "\n",
    "        # Extract values for batch\n",
    "        unique_idxs = self.sort_key['unique_id'][first:last]\n",
    "        batch_idxs = self.sort_key['sort_key'][first:last]\n",
    "\n",
    "        batch_y = self.y[first:last]\n",
    "        batch_categories = self.X[first:last, 1]\n",
    "        batch_last_ds = self.X[first:last, 2]\n",
    "\n",
    "        len_series = np.count_nonzero(~np.isnan(batch_y), axis=1)\n",
    "        min_len = min(len_series)\n",
    "        last_numeric = (~np.isnan(batch_y)).cumsum(1).argmax(1)+1\n",
    "\n",
    "        # Trimming to match min_len\n",
    "        y_b = np.zeros((batch_y.shape[0], min_len))\n",
    "        for i in range(batch_y.shape[0]):\n",
    "            y_b[i] = batch_y[i,(last_numeric[i]-min_len):last_numeric[i]]\n",
    "        batch_y = y_b\n",
    "\n",
    "        assert not np.isnan(batch_y).any(), \\\n",
    "                     \"clean np.nan's from unique_idxs: {}\".format(unique_idxs)\n",
    "        assert batch_y.shape[0]==len(batch_idxs)==len(batch_last_ds)==len(batch_categories)\n",
    "        assert batch_y.shape[1]>=1\n",
    "\n",
    "        # Feed to Batch\n",
    "        batch = Batch(mc=self.mc, y=batch_y, last_ds=batch_last_ds,\n",
    "                                    categories=batch_categories, idxs=batch_idxs)\n",
    "        self.b = (self.b + 1) % self.n_batches\n",
    "        return batch\n",
    "\n",
    "    def get_batch(self, unique_id=None):\n",
    "        return self.get_trim_batch(unique_id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "\n",
    "    def __iter__(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "nixtla"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
