# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/dataloaders.ipynb (unless otherwise specified).

__all__ = ['uids_ts_from_df', 'NBeatsDataLoader']

# Cell
from typing import Collection, Dict, List, Optional, Sequence, Tuple

import numpy as np
import pandas as pd
import torch

from .datasets import Tourism

# Cell
def uids_ts_from_df(df: pd.DataFrame,
                    id_cols: Collection[str]) -> Tuple[Tuple[str],Tuple[np.ndarray]]:
    return zip(*((uid, serie.y.values) for uid, serie in df.groupby(id_cols, sort=False)))

# Internal Cell
def _nbeats_tensors_from_time_series(time_series: Sequence[np.ndarray],
                                     input_size: int,
                                     output_size: Optional[int] = None) -> Tuple[torch.Tensor,torch.Tensor]:
    n_series = len(time_series)
    if output_size is None:
        max_timesteps = input_size
    else:
        max_ts_length = max(time_serie.size for time_serie in time_series)
        max_timesteps = max(max_ts_length, input_size + output_size)
    series = torch.zeros((n_series, max_timesteps), dtype=torch.float32)
    mask = torch.zeros((n_series, max_timesteps), dtype=torch.float32)
    for i, time_serie in enumerate(time_series):
        idx = time_serie.size
        if output_size is None:
            idx = min(idx, input_size)
            input_arr = time_serie[-idx:]
        else:
            input_arr = time_serie
        series[i, -idx:] = torch.from_numpy(input_arr)
        mask[i, -idx:] = 1

    return series, mask

# Cell
class NBeatsDataLoader:

    def __init__(self,
                 time_series: Sequence[np.ndarray],
                 input_size: int,
                 output_size: Optional[int] = None,
                 batch_size: int = 1024,
                 shuffle: bool = False,
                 seed: int = 0):
        self.series, self.mask = _nbeats_tensors_from_time_series(time_series, input_size, output_size)
        self.input_size, self.output_size = input_size, output_size
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.rng = np.random.RandomState(seed)

    def __iter__(self):
        n_series, max_timesteps = self.series.shape
        time_indices = np.arange(max_timesteps)
        if self.shuffle:
            indices = self.rng.permutation(n_series)
        else:
            indices = np.arange(n_series)
        for i in range(0, n_series, self.batch_size):
            batch_indices = indices[i:i+self.batch_size].reshape(-1, 1)
            if self.output_size is not None:
                cut_points = self.rng.randint(self.input_size, max_timesteps-self.output_size+1, batch_indices.size)
                slices = [time_indices[cut_point-self.input_size : cut_point+self.output_size] for cut_point in cut_points]
                y = self.series[batch_indices, slices]
                mask = self.mask[batch_indices, slices]
                insample_y, outsample_y = y[:, :self.input_size], y[:, self.input_size:]
                insample_mask, outsample_mask = mask[:, :self.input_size], mask[:, self.input_size:]
                yield insample_y, insample_mask, outsample_y, outsample_mask
            else:
                y = self.series[i : i+self.batch_size]
                mask = self.mask[i : i+self.batch_size]
                yield y, mask